# coding: utf-8
"""
AGI_learning_until_understands.py
–ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –Ω–µ –Ω–∞—á–Ω—ë—Ç –æ—Ç–≤–µ—á–∞—Ç—å –∫–∞–∫ Qwen.
–¢–µ–ø–µ—Ä—å —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º seq2seq –æ–±—É—á–µ–Ω–∏–µ–º, —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä—ë–º –∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π.
"""
import os
import re
import random
import traceback
from collections import Counter, defaultdict
from datetime import datetime
from typing import Dict, List, Optional, Set, Tuple, Any
import numpy as np
import requests
import torch
import torch.nn as nn
import torch.nn.functional as F

try:
    from sentence_transformers import SentenceTransformer
    _HAS_ST_MODEL = True
except Exception:
    _HAS_ST_MODEL = False

# ======================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ======================
def clean_qwen_response(text: str) -> str:
    if not isinstance(text, str):
        return "–•–æ—Ä–æ—à–æ."
    text = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', text)
    text = re.sub(r'#{1,3}\s*', '', text)
    text = re.sub(r'>\s*', '', text)
    text = re.sub(r'\r\n', '\n', text)
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    text = re.sub(r'^[\*\.\!\?\:\-\‚Äì‚Äî\s]+', '', text)
    text = re.sub(r'[\*\.\!\?\:\-\‚Äì‚Äî\s]+$', '', text)
    words = text.split()
    if len(words) > 60:
        text = ' '.join(words[:60])
        if not text.endswith(('.', '!', '?')):
            text += '.'
    return text or "–•–æ—Ä–æ—à–æ."

def clean_for_similarity(text: str) -> str:
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    return re.sub(r'\s+', ' ', text).lower().strip()

# ======================
# –¢–ò–ü–´ –ú–´–®–õ–ï–ù–ò–Ø
# ======================
def detect_input_type(user_input: str) -> str:
    s = user_input.lower().strip()
    if re.search(r'\b(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π –¥–µ–Ω—å|–∫–∞–∫ –¥–µ–ª–∞|–ø–æ–∫–∞)\b', s):
        return "SOC"
    if re.search(r'\b(—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è|–∫–∞–∫–∞—è —Å—Ç–æ–ª–∏—Ü–∞|—Ñ–æ—Ä–º—É–ª–∞|–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\b', s):
        return "FCT"
    if re.search(r'\b(–ø–æ—á–µ–º—É|–∑–∞—á–µ–º|–æ—Ç—á–µ–≥–æ|–ø—Ä–∏—á–∏–Ω–∞)\b', s):
        return "CAU"
    if re.search(r'\b(–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å|–∫–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|—à–∞–≥|–∞–ª–≥–æ—Ä–∏—Ç–º)\b', s):
        return "PRC"
    if re.search(r'\b(–∫–∞–∫ —Ç—ã –¥—É–º–∞–µ—à—å|—Ç–≤–æ—ë –º–Ω–µ–Ω–∏–µ|–ª—É—á—à–µ –ª–∏|–Ω—Ä–∞–≤–∏—Ç—Å—è –ª–∏)\b', s):
        return "OPN"
    if re.search(r'\b(–ø—Ä–µ–¥—Å—Ç–∞–≤—å|–≤–æ–æ–±—Ä–∞–∑–∏|—Å–æ—á–∏–Ω–∏|–æ–ø–∏—à–∏ –∫–∞–∫|–º–µ—Ç–∞—Ñ–æ—Ä–∞)\b', s):
        return "CRT"
    if re.search(r'\b(–ø–æ—á–µ–º—É —Ç—ã|–∫–∞–∫ —Ç—ã –ø–æ–Ω—è–ª|—á—Ç–æ —Ç—ã –∏–º–µ–ª –≤ –≤–∏–¥—É|–æ–±—ä—è—Å–Ω–∏ —Å–≤–æ–π –æ—Ç–≤–µ—Ç)\b', s):
        return "MET"
    return "FCT"

INPUT_TYPE_TO_STAGES = {
    "SOC": ["social"],
    "FCT": ["fact", "meta"],
    "CAU": ["cause", "fact", "meta"],
    "PRC": ["procedure", "fact"],
    "OPN": ["opinion", "meta"],
    "CRT": ["creative", "metaphor", "meta"],
    "MET": ["meta", "fact"]
}

def get_allowed_stages(input_type: str) -> List[str]:
    return INPUT_TYPE_TO_STAGES.get(input_type, ["fact", "meta"])

# ======================
# –£–ü–†–ê–í–õ–ï–ù–ò–ï –°–õ–û–í–ê–†–Å–ú
# ======================
class VocabManager:
    def __init__(self):
        self.word2idx = {
            '<PAD>': 0,
            '<BOS>': 1,
            '<EOS>': 2,
            '<UNK>': 3,
        }
        self.idx2word = {v: k for k, v in self.word2idx.items()}
        self.next_id = 4

    def add_word(self, word: str) -> int:
        if word not in self.word2idx:
            self.word2idx[word] = self.next_id
            self.idx2word[self.next_id] = word
            self.next_id += 1
        return self.word2idx[word]

    def add_words(self, words: List[str]):
        for w in words:
            self.add_word(w)

    def tokenize(self, text: str) -> List[int]:
        words = clean_for_similarity(text).split()
        return [self.word2idx.get(w, self.word2idx['<UNK>']) for w in words]

    def decode(self, ids: List[int]) -> str:
        tokens = [self.idx2word.get(i, '<UNK>') for i in ids]
        return ' '.join(tokens).replace('<BOS>', '').replace('<EOS>', '').strip()

    @property
    def size(self):
        return len(self.word2idx)

# ======================
# –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ï–¢–¨ (–£–ü–†–û–©–Å–ù–ù–ê–Ø, –ù–û –†–ê–ë–û–ß–ê–Ø)
# ======================
class CognitiveNetwork(nn.Module):
    def __init__(self, vocab_size: int, emb_dim: int = 128, hidden_size: int = 256, device=None):
        super().__init__()
        self.device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))
        self.emb_dim = emb_dim
        self.hidden_size = hidden_size
        self.vocab_size = vocab_size

        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)
        self.encoder_rnn = nn.LSTM(emb_dim, hidden_size, batch_first=True)
        self.decoder_rnn = nn.LSTM(emb_dim, hidden_size, batch_first=True)
        self.output_proj = nn.Linear(hidden_size, vocab_size)

        self.to(self.device)

    def encode(self, input_ids: torch.Tensor):
        emb = self.embedding(input_ids)  # [B, T_in, E]
        _, (h, c) = self.encoder_rnn(emb)  # h, c: [1, B, H]
        return h, c

    def decode(self, target_ids: torch.Tensor, h: torch.Tensor, c: torch.Tensor):
        emb = self.embedding(target_ids)  # [B, T_out, E]
        output, _ = self.decoder_rnn(emb, (h, c))  # [B, T_out, H]
        logits = self.output_proj(output)  # [B, T_out, V]
        return logits

    def generate(self, input_ids: torch.Tensor, max_len: int = 30) -> List[int]:
        self.eval()
        with torch.no_grad():
            h, c = self.encode(input_ids)
            batch_size = input_ids.size(0)
            current_token = torch.full((batch_size, 1), 1, device=self.device)  # <BOS> = 1
            generated = []

            for _ in range(max_len):
                emb = self.embedding(current_token)  # [B, 1, E]
                output, (h, c) = self.decoder_rnn(emb, (h, c))  # [B, 1, H]
                logits = self.output_proj(output.squeeze(1))  # [B, V]
                probs = F.softmax(logits / 0.8, dim=-1)
                next_token = torch.multinomial(probs, 1)  # [B, 1]
                token_id = next_token.item()
                if token_id == 2:  # <EOS>
                    break
                generated.append(token_id)
                current_token = next_token

            return generated

# ======================
# –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –û–¶–ï–ù–ö–ê
# ======================
class SemanticEvaluator:
    def __init__(self):
        self.model = None
        if _HAS_ST_MODEL:
            try:
                self.model = SentenceTransformer('all-MiniLM-L6-v2')
            except:
                pass

    def similarity(self, a: str, b: str) -> float:
        if not a or not b:
            return 0.0
        if self.model is not None:
            emb = self.model.encode([a, b], normalize_embeddings=True)
            return float(np.dot(emb[0], emb[1]))
        a_clean = set(clean_for_similarity(a).split())
        b_clean = set(clean_for_similarity(b).split())
        if not a_clean or not b_clean:
            return 0.0
        return len(a_clean & b_clean) / len(a_clean | b_clean)

# ======================
# –£–ß–ò–¢–ï–õ–¨
# ======================
class Teacher:
    def __init__(self, api_url="http://localhost:1234/v1/chat/completions"):
        self.api_url = api_url
        self.evaluator = SemanticEvaluator()

    def ask_qwen(self, prompt: str) -> str:
        try:
            resp = requests.post(self.api_url, json={
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 100,
                "temperature": 0.5
            }, timeout=15)
            if resp.status_code == 200:
                return clean_qwen_response(resp.json()['choices'][0]['message']['content'])
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ Qwen API: {e}")
        return "–•–æ—Ä–æ—à–æ."

    def train_until_understands(
        self,
        model: CognitiveNetwork,
        vocab: VocabManager,
        user_input: str,
        max_attempts: int = 6,
        lr: float = 1e-3
    ) -> str:
        qwen_answer = self.ask_qwen(user_input)
        print(f"üë§: {user_input}")
        print(f"ü§ñ Qwen: {qwen_answer}")

        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ª–æ–≤–∞—Ä—å
        vocab.add_words(clean_for_similarity(user_input).split())
        vocab.add_words(clean_for_similarity(qwen_answer).split())

        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        input_tokens = vocab.tokenize(user_input)
        target_tokens = vocab.tokenize(qwen_answer)

        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        encoder_input = torch.tensor([input_tokens], device=model.device)  # [1, T_in]
        decoder_input = torch.tensor([[1] + target_tokens], device=model.device)  # <BOS> + –æ—Ç–≤–µ—Ç
        decoder_target = torch.tensor([target_tokens + [2]], device=model.device)  # –æ—Ç–≤–µ—Ç + <EOS>

        optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
        best_sim = -1.0
        best_response = ""

        for attempt in range(1, max_attempts + 1):
            model.train()
            optimizer.zero_grad()

            # –ö–æ–¥–∏—Ä—É–µ–º –≤—Ö–æ–¥
            h, c = model.encode(encoder_input)

            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Å teacher forcing
            logits = model.decode(decoder_input, h, c)  # [1, T_out, V]
            logits = logits.view(-1, model.vocab_size)  # [T_out, V]
            targets = decoder_target.view(-1)           # [T_out]

            loss = F.cross_entropy(logits, targets, ignore_index=0)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
            model.eval()
            with torch.no_grad():
                gen_ids = model.generate(encoder_input, max_len=30)
                brain_answer = vocab.decode(gen_ids)

            sim = self.evaluator.similarity(qwen_answer, brain_answer)
            print(f"  üîÅ –ü–æ–ø—ã—Ç–∫–∞ {attempt}: loss={loss.item():.4f}, —Å—Ö–æ–¥—Å—Ç–≤–æ = {sim:.3f}")

            if sim > best_sim:
                best_sim = sim
                best_response = brain_answer

            if sim >= 0.85:
                print("‚úÖ –ú–æ–¥–µ–ª—å –ø–æ–Ω—è–ª–∞!")
                return best_response

        print(f"‚ö†Ô∏è –ú–∞–∫—Å. –ø–æ–ø—ã—Ç–æ–∫. –õ—É—á—à–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {best_sim:.3f}")
        return best_response

# ======================
# MAIN
# ======================
def main():
    print("üß† –û–±—É—á–µ–Ω–∏–µ –¥–æ –ø–æ–ª–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è (—É–ª—É—á—à–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)")
    vocab = VocabManager()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = CognitiveNetwork(vocab_size=1000, emb_dim=128, hidden_size=256, device=device)
    teacher = Teacher()

    # –ü—Ä–µ–¥–∑–∞–ø–æ–ª–Ω–∏–º —Å–ª–æ–≤–∞—Ä—å –±–∞–∑–æ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    base_words = "–ø—Ä–∏–≤–µ—Ç —á—Ç–æ —Ç–∞–∫–æ–µ –ø–æ—á–µ–º—É –∫–∞–∫ –ø–æ–º–æ—á—å —Ö–æ—Ä–æ—à–æ —á–µ–º –¥–µ–Ω—å".split()
    vocab.add_words(base_words)

    while True:
        try:
            user_input = input("\nüë§ –í—ã: ").strip()
            if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
                break
            if not user_input:
                continue

            final_answer = teacher.train_until_understands(model, vocab, user_input)
            print(f"\nüí° –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: {final_answer}")

        except KeyboardInterrupt:
            print("\nüëã –ü–æ–∫–∞!")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            traceback.print_exc()

if __name__ == "__main__":
    main()
# coding: utf-8
"""
AGI24_Bot.py ‚Äî –ï–î–ò–ù–´–ô –§–ê–ô–õ: –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê + TELEGRAM –ë–û–¢
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Python 3.13
"""

import asyncio
import logging
from typing import Dict, Optional, List, Any, Set, Tuple
from datetime import datetime
import os
import sys
import sqlite3
import hashlib
import re
import json
import time
from pathlib import Path
from collections import defaultdict, deque
from contextlib import contextmanager

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∏–º–ø–æ—Ä—Ç—ã –¥–ª—è Telegram Bot API
try:
    import telegram
    from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
    from telegram.ext import (
        Application,
        ApplicationBuilder,
        CommandHandler,
        MessageHandler,
        CallbackQueryHandler,
        ContextTypes,
        filters
    )
    from telegram.error import TelegramError

    print("‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ python-telegram-bot –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ telegram: {e}")
    print("üì¶ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é: pip install python-telegram-bot")
    sys.exit(1)

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python
if sys.version_info >= (3, 13):
    print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –í–µ—Ä—Å–∏—è Python 3.13")
    print("üìå –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Python 3.10-3.12 –¥–ª—è –ø–æ–ª–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏")


# ================= –û–ë–™–ï–î–ò–ù–Å–ù–ù–ê–Ø –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =================

class Config:
    """–£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –∏ –±–æ—Ç–∞"""
    ROOT = Path("./cognitive_system_v30")
    ROOT.mkdir(exist_ok=True)
    DB_PATH = ROOT / "memory.db"
    OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
    MODEL = "nvidia/nemotron-3-nano-30b-a3b:free"
    TIMEOUT = 300
    MAX_TOKENS = 8000

    # –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    REFLECTION_INTERVAL = 3
    DEEP_THINKING_THRESHOLD = 0.7
    CONTEXT_WINDOW_SIZE = 10
    MEMORY_DECAY_RATE = 0.05

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –±–æ—Ç–∞
    MAX_MESSAGE_LENGTH = 4096
    MAX_RESPONSE_CHUNKS = 5
    TYPING_DELAY = 1.5
    REQUEST_TIMEOUT = 30

    @classmethod
    def get_api_key(cls):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ API –∫–ª—é—á–∞ OpenRouter"""
        key = os.getenv("OPENROUTER_API_KEY")
        if key:
            return key.strip()

        env_path = Path(".env")
        if env_path.exists():
            try:
                with open(env_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith("OPENROUTER_API_KEY="):
                            return line.split("=", 1)[1].strip(' "\'')
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è .env: {e}")

        print("\nüîë API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print("üìå –ü–æ–ª—É—á–∏—Ç–µ –∫–ª—é—á –Ω–∞: https://openrouter.ai/keys")
        key = input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à API –∫–ª—é—á OpenRouter: ").strip()

        if key:
            try:
                with open(".env", "a", encoding="utf-8") as f:
                    f.write(f'\nOPENROUTER_API_KEY="{key}"')
                print("‚úÖ –ö–ª—é—á —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª .env")
                return key
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–ª—é—á: {e}")
                return key

        raise ValueError("API –∫–ª—é—á OpenRouter –Ω–µ –Ω–∞–π–¥–µ–Ω")

    @classmethod
    def get_telegram_token(cls):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ Telegram –±–æ—Ç–∞"""
        token = os.getenv("TELEGRAM_BOT_TOKEN")
        if token:
            return token.strip()

        env_path = Path(".env")
        if env_path.exists():
            try:
                with open(env_path, "r", encoding="utf-8") as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith("TELEGRAM_BOT_TOKEN="):
                            return line.split("=", 1)[1].strip(' "\'')
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è .env: {e}")

        print("\nü§ñ –¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        print("üìå –°–æ–∑–¥–∞–π—Ç–µ –±–æ—Ç–∞ —á–µ—Ä–µ–∑ @BotFather –∏ –ø–æ–ª—É—á–∏—Ç–µ —Ç–æ–∫–µ–Ω")
        token = input("–í–≤–µ–¥–∏—Ç–µ —Ç–æ–∫–µ–Ω –≤–∞—à–µ–≥–æ Telegram –±–æ—Ç–∞: ").strip()

        if token:
            try:
                env_exists = Path(".env").exists()
                with open(".env", "a" if env_exists else "w", encoding="utf-8") as f:
                    if env_exists:
                        f.write("\n")
                    f.write(f'TELEGRAM_BOT_TOKEN="{token}"\n')
                print("‚úÖ –¢–æ–∫–µ–Ω —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª .env")
                return token
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–æ–∫–µ–Ω: {e}")
                return token

        raise ValueError("–¢–æ–∫–µ–Ω Telegram –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")


# ================= –£–¢–ò–õ–ò–¢–´ =================

def calculate_text_similarity(text1: str, text2: str) -> float:
    """–†–∞—Å—á—ë—Ç —Å—Ö–æ–∂–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤ —Å —É—á—ë—Ç–æ–º n-–≥—Ä–∞–º–º"""
    if not text1 or not text2:
        return 0.0

    def get_ngrams(text: str, n: int = 2) -> Set[str]:
        words = re.findall(r'\w+', text.lower())
        if len(words) < n:
            return set([' '.join(words)])
        return set(' '.join(words[i:i + n]) for i in range(len(words) - n + 1))

    words1 = set(re.findall(r'\w+', text1.lower()))
    words2 = set(re.findall(r'\w+', text2.lower()))

    if not words1 or not words2:
        return 0.0

    unigram_sim = len(words1.intersection(words2)) / max(len(words1), len(words2))

    bigrams1 = get_ngrams(text1, 2)
    bigrams2 = get_ngrams(text2, 2)

    if bigrams1 and bigrams2:
        bigram_sim = len(bigrams1.intersection(bigrams2)) / max(len(bigrams1), len(bigrams2), 1)
    else:
        bigram_sim = 0.0

    return 0.6 * unigram_sim + 0.4 * bigram_sim


def extract_semantic_features(text: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–µ–∫—Å—Ç–∞"""
    text_lower = text.lower()
    words = text.split()

    features = {
        'length': len(words),
        'complexity': len(set(text_lower.split())) / max(len(words), 1),
        'question_words': len(re.findall(r'\b(–∫–∞–∫|—á—Ç–æ|–ø–æ—á–µ–º—É|–∑–∞—á–µ–º|–∫–æ–≥–¥–∞|–≥–¥–µ|–∫—Ç–æ|—Å–∫–æ–ª—å–∫–æ)\b', text_lower)),
        'numbers': len(re.findall(r'\b\d+\b', text)),
        'emotions': len(re.findall(r'\b(—Ö–æ—Ä–æ—à–æ|–ø–ª–æ—Ö–æ|–æ—Ç–ª–∏—á–Ω–æ|—É–∂–∞—Å–Ω–æ|–∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ|—Å–∫—É—á–Ω–æ|—Ä–∞–¥|–≥—Ä—É—Å—Ç–Ω–æ)\b', text_lower)),
        'imperatives': len(re.findall(r'\b(—Å–¥–µ–ª–∞–π|—Å–æ–∑–¥–∞–π|–Ω–∞–π–¥–∏|–ø–æ–∫–∞–∂–∏|—Ä–∞—Å—Å–∫–∞–∂–∏|–æ–±—ä—è—Å–Ω–∏)\b', text_lower)),
        'has_question': '?' in text,
        'sentiment': analyze_sentiment(text)
    }
    return features


def analyze_sentiment(text: str) -> float:
    """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (-1 –¥–æ 1)"""
    positive = ['—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ', '–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ', '–∫–ª–∞—Å—Å–Ω–æ', '—Å—É–ø–µ—Ä', '—Ä–∞–¥', '—Å—á–∞—Å—Ç–ª–∏–≤']
    negative = ['–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–æ—Ç–≤—Ä–∞—Ç–∏—Ç–µ–ª—å–Ω–æ', '–∫–æ—à–º–∞—Ä', '–ø—Ä–æ–≤–∞–ª', '–≥—Ä—É—Å—Ç–Ω–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–∑–ª–æ–π']

    text_lower = text.lower()
    pos_count = sum(1 for word in positive if word in text_lower)
    neg_count = sum(1 for word in negative if word in text_lower)

    total = pos_count + neg_count
    if total == 0:
        return 0.0
    return (pos_count - neg_count) / total


# ================= –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ë–ê–ó–ê –î–ê–ù–ù–´–• =================

class EnhancedMemoryDB:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ —Å–≤—è–∑–µ–π"""

    def __init__(self, db_path: Path):
        self.db_path = db_path
        self._init_tables()

    @contextmanager
    def get_connection(self):
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
        finally:
            conn.close()

    def _init_tables(self):
        with self.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS interactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    user_input TEXT NOT NULL,
                    system_response TEXT NOT NULL,
                    context TEXT,
                    emotion TEXT DEFAULT 'neutral',
                    category TEXT,
                    importance REAL DEFAULT 0.5,
                    complexity REAL DEFAULT 0.5,
                    satisfaction REAL DEFAULT 0.5,
                    tokens_used INTEGER DEFAULT 0,
                    user_id INTEGER DEFAULT 0
                )
            ''')

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS facts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    key TEXT NOT NULL,
                    value TEXT NOT NULL,
                    category TEXT,
                    confidence REAL DEFAULT 1.0,
                    importance REAL DEFAULT 0.5,
                    created_at REAL NOT NULL,
                    last_used REAL,
                    usage_count INTEGER DEFAULT 0,
                    decay_factor REAL DEFAULT 1.0,
                    source TEXT,
                    UNIQUE(key, value)
                )
            ''')

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS thoughts (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp REAL NOT NULL,
                    thought_type TEXT NOT NULL,
                    content TEXT NOT NULL,
                    trigger TEXT,
                    importance REAL DEFAULT 0.5,
                    depth_level INTEGER DEFAULT 1,
                    confidence REAL DEFAULT 0.7,
                    outcome TEXT
                )
            ''')

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS goals (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    parent_goal_id INTEGER,
                    created_at REAL NOT NULL,
                    description TEXT NOT NULL,
                    priority REAL DEFAULT 0.5,
                    status TEXT DEFAULT 'active',
                    progress REAL DEFAULT 0.0,
                    deadline REAL,
                    next_action TEXT,
                    success_criteria TEXT,
                    learned_lessons TEXT,
                    FOREIGN KEY (parent_goal_id) REFERENCES goals(id)
                )
            ''')

            cursor.execute('''
                CREATE TABLE IF NOT EXISTS patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pattern_type TEXT NOT NULL,
                    description TEXT NOT NULL,
                    occurrences INTEGER DEFAULT 1,
                    confidence REAL DEFAULT 0.5,
                    created_at REAL NOT NULL,
                    last_seen REAL NOT NULL,
                    success_rate REAL DEFAULT 0.5
                )
            ''')

            conn.commit()

    def add_interaction(self, user_input: str, system_response: str, user_id: int = 0, **kwargs) -> int:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO interactions
                (timestamp, user_input, system_response, context, emotion, category,
                importance, complexity, satisfaction, tokens_used, user_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                time.time(),
                user_input[:5000],
                system_response[:5000],
                kwargs.get('context', '')[:1000],
                kwargs.get('emotion', 'neutral'),
                kwargs.get('category', ''),
                kwargs.get('importance', 0.5),
                kwargs.get('complexity', 0.5),
                kwargs.get('satisfaction', 0.5),
                kwargs.get('tokens_used', 0),
                user_id
            ))
            conn.commit()
            return cursor.lastrowid

    def get_contextual_interactions(self, query: str, limit: int = 5, user_id: int = 0) -> List[Dict]:
        with self.get_connection() as conn:
            cursor = conn.cursor()

            if user_id:
                cursor.execute('''
                    SELECT * FROM interactions
                    WHERE user_id = ? OR user_id = 0
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (user_id, limit * 3))
            else:
                cursor.execute('''
                    SELECT * FROM interactions
                    ORDER BY timestamp DESC
                    LIMIT ?
                ''', (limit * 3,))

            all_interactions = [dict(row) for row in cursor.fetchall()]

            scored = []
            for interaction in all_interactions:
                relevance = calculate_text_similarity(
                    query,
                    interaction['user_input'] + ' ' + interaction['system_response']
                )
                recency = 1.0 - (time.time() - interaction['timestamp']) / (30 * 24 * 3600)
                recency = max(0, min(1, recency))
                score = 0.6 * relevance + 0.3 * interaction['importance'] + 0.1 * recency
                scored.append((score, interaction))

            scored.sort(reverse=True, key=lambda x: x[0])
            return [item[1] for item in scored[:limit]]

    def add_fact(self, key: str, value: str, **kwargs):
        with self.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('SELECT id, usage_count FROM facts WHERE key = ? AND value = ?', (key, value))
            existing = cursor.fetchone()

            if existing:
                cursor.execute('''
                    UPDATE facts
                    SET confidence = ?, importance = ?, last_used = ?,
                        usage_count = usage_count + 1, decay_factor = 1.0
                    WHERE id = ?
                ''', (
                    kwargs.get('confidence', 1.0),
                    kwargs.get('importance', 0.5),
                    time.time(),
                    existing[0]
                ))
            else:
                cursor.execute('''
                    INSERT INTO facts
                    (key, value, category, confidence, importance, created_at, last_used,
                    usage_count, decay_factor, source)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    key[:500],
                    value[:500],
                    kwargs.get('category', ''),
                    kwargs.get('confidence', 1.0),
                    kwargs.get('importance', 0.5),
                    time.time(),
                    time.time(),
                    1,
                    1.0,
                    kwargs.get('source', 'user')
                ))
            conn.commit()

    def get_relevant_facts(self, query: str, limit: int = 5) -> List[Dict]:
        with self.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('''
                SELECT * FROM facts
                WHERE confidence > 0.3 AND decay_factor > 0.1
                ORDER BY importance DESC, usage_count DESC
                LIMIT ?
            ''', (limit * 2,))

            all_facts = [dict(row) for row in cursor.fetchall()]

            scored = []
            for fact in all_facts:
                relevance = calculate_text_similarity(query, f"{fact['key']} {fact['value']}")
                score = (
                        0.4 * relevance +
                        0.3 * fact['importance'] +
                        0.2 * fact['confidence'] +
                        0.1 * fact['decay_factor']
                )
                scored.append((score, fact))

            scored.sort(reverse=True, key=lambda x: x[0])
            return [item[1] for item in scored[:limit]]

    def add_thought(self, thought_type: str, content: str, **kwargs):
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO thoughts
                (timestamp, thought_type, content, trigger, importance, depth_level, confidence, outcome)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                time.time(),
                thought_type,
                content[:2000],
                kwargs.get('trigger', ''),
                kwargs.get('importance', 0.5),
                kwargs.get('depth_level', 1),
                kwargs.get('confidence', 0.7),
                kwargs.get('outcome', '')
            ))
            conn.commit()

    def get_thought_insights(self, limit: int = 10) -> List[Dict]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT thought_type, COUNT(*) as count, AVG(importance) as avg_importance
                FROM thoughts
                WHERE timestamp > ?
                GROUP BY thought_type
                ORDER BY count DESC
                LIMIT ?
            ''', (time.time() - 7 * 86400, limit))
            return [dict(row) for row in cursor.fetchall()]

    def add_pattern(self, pattern_type: str, description: str, confidence: float = 0.5):
        with self.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('''
                SELECT id FROM patterns WHERE pattern_type = ? AND description = ?
            ''', (pattern_type, description))
            existing = cursor.fetchone()

            if existing:
                cursor.execute('''
                    UPDATE patterns
                    SET occurrences = occurrences + 1, last_seen = ?, confidence = ?
                    WHERE id = ?
                ''', (time.time(), min(1.0, confidence * 1.1), existing[0]))
            else:
                cursor.execute('''
                    INSERT INTO patterns
                    (pattern_type, description, occurrences, confidence, created_at, last_seen)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (pattern_type, description, 1, confidence, time.time(), time.time()))
            conn.commit()

    def get_patterns(self, min_confidence: float = 0.6, limit: int = 10) -> List[Dict]:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                SELECT * FROM patterns
                WHERE confidence >= ?
                ORDER BY occurrences DESC, confidence DESC
                LIMIT ?
            ''', (min_confidence, limit))
            return [dict(row) for row in cursor.fetchall()]

    def add_goal(self, description: str, **kwargs) -> int:
        with self.get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO goals
                (parent_goal_id, created_at, description, priority, status, progress,
                deadline, next_action, success_criteria)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                kwargs.get('parent_goal_id'),
                time.time(),
                description,
                kwargs.get('priority', 0.5),
                kwargs.get('status', 'active'),
                kwargs.get('progress', 0.0),
                kwargs.get('deadline'),
                kwargs.get('next_action', ''),
                kwargs.get('success_criteria', '')
            ))
            conn.commit()
            return cursor.lastrowid

    def get_goal_hierarchy(self, parent_id: Optional[int] = None) -> List[Dict]:
        with self.get_connection() as conn:
            cursor = conn.cursor()

            if parent_id is None:
                cursor.execute('''
                    SELECT * FROM goals
                    WHERE parent_goal_id IS NULL AND status = 'active'
                    ORDER BY priority DESC
                ''')
            else:
                cursor.execute('''
                    SELECT * FROM goals
                    WHERE parent_goal_id = ? AND status = 'active'
                    ORDER BY priority DESC
                ''', (parent_id,))

            return [dict(row) for row in cursor.fetchall()]


# ================= –°–ò–°–¢–ï–ú–ê –ú–´–®–õ–ï–ù–ò–Ø =================

class EnhancedThinkingSystem:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ –º—ã—à–ª–µ–Ω–∏—è"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.rate_limit = 2.0
        self.last_request_time = 0
        self.cache = {}
        self.cache_hits = 0
        self.cache_misses = 0
        self.cache_max_size = 500
        self.reasoning_history = deque(maxlen=100)

    async def _wait_for_rate_limit(self):
        now = time.time()
        elapsed = now - self.last_request_time
        if elapsed < self.rate_limit:
            await asyncio.sleep(self.rate_limit - elapsed)
        self.last_request_time = time.time()

    async def multi_level_thinking(self, context: str, depth: int = 2) -> Dict[str, str]:
        thoughts = {}
        thinking_layers = [
            ('surface', '–ß—Ç–æ –æ—á–µ–≤–∏–¥–Ω–æ? –ö–∞–∫–∏–µ —Ñ–∞–∫—Ç—ã –ø—Ä—è–º–æ —É–∫–∞–∑–∞–Ω—ã?', 0.3),
            ('analytical', '–ö–∞–∫–∏–µ —Å–≤—è–∑–∏ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –º–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å? –ß—Ç–æ –Ω–µ—è–≤–Ω–æ?', 0.5),
            ('strategic', '–ö–∞–∫–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è? –ö–∞–∫–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –º–æ–∂–Ω–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å?', 0.7),
            ('creative', '–ö–∞–∫–∏–µ –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –≤–æ–∑–º–æ–∂–Ω—ã? –ö–∞–∫–∏–µ –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã?', 0.9)
        ]

        depth = min(depth, 4)

        for layer_name, prompt, temperature in thinking_layers[:depth]:
            thought = await self.generate_thought_with_prompt(
                f"{prompt}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}",
                temperature=temperature
            )
            if thought and len(thought) > 10:
                thoughts[layer_name] = thought

        return thoughts

    async def generate_thought_with_prompt(self, prompt: str, temperature: float = 0.7) -> Optional[str]:
        system_prompt = """–¢—ã ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –≥–ª—É–±–æ–∫–∏–º –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–º –º—ã—à–ª–µ–Ω–∏–µ–º.
–¢–≤–æ–∏ —Å–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã:
- –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
- –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ —Å–≤—è–∑–µ–π
- –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º
- –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫–∞
- –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω–æ. –§–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –∫–ª—é—á–µ–≤—ã—Ö –∏–Ω—Å–∞–π—Ç–∞—Ö, –∞ –Ω–µ –Ω–∞ –æ—á–µ–≤–∏–¥–Ω—ã—Ö –≤–µ—â–∞—Ö.
–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º –≤ —Å–≤–æ–∏—Ö –≤—ã–≤–æ–¥–∞—Ö."""

        response = await self.call_llm(system_prompt, prompt, temperature)
        if response and len(response) > 10:
            self.reasoning_history.append({
                'timestamp': time.time(),
                'prompt': prompt[:200],
                'response': response[:300],
                'temperature': temperature
            })
            return response
        return None

    async def call_llm(self, system_prompt: str, user_prompt: str, temperature: float = 0.7) -> str:
        cache_key = hashlib.md5(
            f"{system_prompt[:100]}{user_prompt[:200]}{temperature}".encode()
        ).hexdigest()

        if cache_key in self.cache:
            self.cache_hits += 1
            return self.cache[cache_key]

        self.cache_misses += 1
        await self._wait_for_rate_limit()

        try:
            import aiohttp

            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://github.com/AGI24-Bot",
                "X-Title": "AGI24 Cognitive System"
            }

            payload = {
                "model": Config.MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": temperature,
                "max_tokens": Config.MAX_TOKENS,
                "top_p": 0.95,
                "stream": False
            }

            timeout = aiohttp.ClientTimeout(total=Config.TIMEOUT)

            async with aiohttp.ClientSession(timeout=timeout) as session:
                async with session.post(
                        Config.OPENROUTER_URL,
                        headers=headers,
                        json=payload,
                        timeout=timeout
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        if "choices" in data and len(data["choices"]) > 0:
                            content = data["choices"][0]["message"]["content"].strip()

                            self.cache[cache_key] = content

                            if len(self.cache) > self.cache_max_size:
                                keys_to_remove = list(self.cache.keys())[:100]
                                for key in keys_to_remove:
                                    del self.cache[key]

                            return content
                        else:
                            return "‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç API"
                    else:
                        error_text = await response.text()
                        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ API ({response.status}): {error_text[:200]}"

        except ImportError:
            return "‚ö†Ô∏è –û—à–∏–±–∫–∞: –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ aiohttp –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install aiohttp"
        except Exception as e:
            return f"‚ö†Ô∏è –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)[:100]}"


# ================= –ê–í–¢–û–ù–û–ú–ù–´–ô –ê–ì–ï–ù–¢ =================

class EnhancedAutonomousAgent:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∞–≤—Ç–æ–Ω–æ–º–Ω—ã–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –∞–≥–µ–Ω—Ç"""

    def __init__(self):
        print("ü§ñ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞...")

        try:
            self.api_key = Config.get_api_key()
            print("‚úÖ API –∫–ª—é—á –ø–æ–ª—É—á–µ–Ω")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è API –∫–ª—é—á–∞: {e}")
            raise

        self.db = EnhancedMemoryDB(Config.DB_PATH)
        self.thinker = EnhancedThinkingSystem(self.api_key)

        self.interaction_count = 0
        self.deep_thoughts_count = 0
        self.patterns_found = 0
        self.start_time = time.time()
        self.context_window = deque(maxlen=Config.CONTEXT_WINDOW_SIZE)
        self.active_tasks = []

        self.self_assessment = {
            'knowledge_gaps': [],
            'strong_areas': [],
            'improvement_areas': [],
            'avg_response_time': 0.0,
            'success_rate': 1.0
        }

        self._init_system()
        print("‚úÖ –ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –∞–≥–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —É—Å–ø–µ—à–Ω–æ")

    def _init_system(self):
        existing_goals = self.db.get_goal_hierarchy()
        if not existing_goals:
            main_goal = self.db.add_goal(
                "–ë—ã—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–º –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–º –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–º –ø–æ–º–æ—â–Ω–∏–∫–æ–º",
                priority=1.0,
                success_criteria="–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã"
            )
            self.db.add_goal(
                "–ì–ª—É–±–æ–∫–æ –ø–æ–Ω–∏–º–∞—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
                parent_goal_id=main_goal,
                priority=0.9,
                next_action="–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –∞—Å–ø–µ–∫—Ç–æ–≤"
            )
            self.db.add_goal(
                "–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ –æ–±—É—á–∞—Ç—å—Å—è –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è",
                parent_goal_id=main_goal,
                priority=0.85,
                next_action="–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π"
            )

    async def process_input(self, user_input: str, user_id: int = 0) -> str:
        start_time = time.time()
        self.interaction_count += 1

        self.context_window.append({
            'type': 'user',
            'content': user_input,
            'timestamp': time.time(),
            'user_id': user_id
        })

        command_response = self._handle_command(user_input)
        if command_response:
            return command_response

        features = extract_semantic_features(user_input)
        complexity = features['complexity']
        importance = self._calculate_importance(user_input, features)

        self._extract_and_store_information(user_input, importance)
        response = await self._generate_contextual_response(
            user_input, features, complexity, importance, user_id
        )

        interaction_id = self.db.add_interaction(
            user_input=user_input,
            system_response=response,
            user_id=user_id,
            context=self._get_context_summary(),
            category=self._categorize_input(user_input, features),
            importance=importance,
            complexity=complexity,
            satisfaction=self._calculate_satisfaction(response, features),
            tokens_used=len(response.split())
        )

        self.context_window.append({
            'type': 'assistant',
            'content': response[:200],
            'timestamp': time.time(),
            'interaction_id': interaction_id
        })

        await self._detect_patterns(user_id)

        if self.interaction_count % Config.REFLECTION_INTERVAL == 0:
            asyncio.create_task(self._deep_autonomous_thinking())

        duration = time.time() - start_time
        self.self_assessment['avg_response_time'] = (
                self.self_assessment['avg_response_time'] * 0.9 + duration * 0.1
        )

        return response

    def _calculate_importance(self, text: str, features: Dict) -> float:
        importance = 0.5

        important_keywords = ['–≤–∞–∂–Ω–æ', '—Å—Ä–æ—á–Ω–æ', '–∫—Ä–∏—Ç–∏—á–Ω–æ', '–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ', '–∂–∏–∑–Ω–µ–Ω–Ω–æ', '—Ä–µ—à–∞—é—â–∏–π']
        if any(word in text.lower() for word in important_keywords):
            importance += 0.3

        importance += min(0.2, features['question_words'] * 0.05)
        importance += min(0.15, features['imperatives'] * 0.05)
        importance += features['complexity'] * 0.15

        if abs(features['sentiment']) > 0.5:
            importance += 0.1

        return min(1.0, max(0.1, importance))

    def _calculate_satisfaction(self, response: str, features: Dict) -> float:
        satisfaction = 0.7

        if len(response.split()) > 20:
            satisfaction += 0.1

        if any(word in response.lower() for word in ['–∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ', '–Ω–∞–ø—Ä–∏–º–µ—Ä', '–≤–æ-–ø–µ—Ä–≤—ã—Ö', '—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º']):
            satisfaction += 0.1

        if '‚ö†Ô∏è' not in response and '–û—à–∏–±–∫–∞' not in response:
            satisfaction += 0.1

        return min(1.0, satisfaction)

    def _extract_and_store_information(self, text: str, importance: float):
        numbers = re.findall(r'\b\d+\b', text)
        for num in numbers:
            if len(num) < 10:
                self.db.add_fact('—á–∏—Å–ª–æ', num, category='–¥–∞–Ω–Ω—ã–µ', importance=importance * 0.5)

        names = re.findall(r'\b[–ê-–Ø–Å][–∞-—è—ë]+\b', text)
        for name in names:
            if len(name) > 2 and name not in ['–≠—Ç–æ', '–ß—Ç–æ', '–ö–∞–∫', '–ü–æ—á–µ–º—É']:
                self.db.add_fact('–∏–º—è', name, category='–ø–µ—Ä—Å–æ–Ω–∞', importance=importance * 0.7)

        definition_patterns = [
            (r'(\w+)\s+(?:—ç—Ç–æ|—Ä–∞–≤–Ω–æ|—Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç)\s+([^.,]+)', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ'),
            (r'–∑–∞–ø–æ–º–Ω–∏[,:]\s*(.+)', '–≤–∞–∂–Ω–∞—è_–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è'),
            (r'(\w+)\s*=\s*([^,]+)', '—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ'),
            (r'([–ê-–Ø–∞-—è—ë–Å\s]+)\s+‚Äî\s+([^.,]+)', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ')
        ]

        for pattern, category in definition_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                if len(match) == 2:
                    key, value = match
                    key = key.strip()
                    value = value.strip()
                    if key and value and len(key) < 100 and len(value) < 500:
                        self.db.add_fact(
                            key,
                            value,
                            category=category,
                            importance=importance,
                            source='user_input'
                        )

    async def _generate_contextual_response(
            self, user_input: str, features: Dict, complexity: float,
            importance: float, user_id: int = 0
    ) -> str:
        relevant_interactions = self.db.get_contextual_interactions(
            user_input, limit=3, user_id=user_id
        )
        relevant_facts = self.db.get_relevant_facts(user_input, limit=5)
        active_goals = self.db.get_goal_hierarchy()

        context_parts = []

        if relevant_interactions:
            context_parts.append("üìú –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è:")
            for interaction in relevant_interactions[:2]:
                context_parts.append(f"  –ü: {interaction['user_input'][:60]}...")
                context_parts.append(f"  –Ø: {interaction['system_response'][:60]}...")

        if relevant_facts:
            context_parts.append("\nüìö –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ–∞–∫—Ç—ã:")
            for fact in relevant_facts[:4]:
                conf_stars = "‚òÖ" * int(fact['confidence'] * 5)
                context_parts.append(f"  ‚Ä¢ {fact['key']}: {fact['value'][:50]} [{conf_stars}]")

        if active_goals:
            context_parts.append("\nüéØ –¢–µ–∫—É—â–∏–µ —Ü–µ–ª–∏:")
            for goal in active_goals[:2]:
                context_parts.append(f"  ‚Ä¢ {goal['description'][:50]}")

        patterns = self.db.get_patterns(min_confidence=0.7, limit=2)
        if patterns:
            context_parts.append("\nüîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:")
            for pattern in patterns:
                context_parts.append(f"  ‚Ä¢ {pattern['description'][:60]}")

        context = "\n".join(context_parts) if context_parts else "–ù–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"

        needs_deep_thinking = (
                complexity > Config.DEEP_THINKING_THRESHOLD or
                importance > 0.7 or
                features['question_words'] > 2 or
                features['has_question']
        )

        if needs_deep_thinking:
            deep_thoughts = await self.thinker.multi_level_thinking(
                f"–ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {user_input}\n\n–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context}",
                depth=3
            )

            if deep_thoughts:
                synthesis_prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø: {user_input}

–ê–ù–ê–õ–ò–ó:
{chr(10).join([f'{level.upper()}: {thought}' for level, thought in deep_thoughts.items()])}

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–°–§–û–†–ú–ò–†–£–ô –¶–ï–õ–¨–ù–´–ô, –ì–õ–£–ë–û–ö–ò–ô –ò –ü–†–ê–ö–¢–ò–ß–ù–´–ô –û–¢–í–ï–¢, –ö–û–¢–û–†–´–ô:
1. –û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –∑–∞–ø—Ä–æ—Å–∞
2. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –∏–Ω—Å–∞–π—Ç—ã –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
3. –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –∏—Å—Ç–æ—Ä–∏—é
4. –ü—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–ª–∏ —Ä–µ—à–µ–Ω–∏—è
5. –ë—É–¥–µ—Ç –ø–æ–ª–µ–∑–µ–Ω –∏ –ø–æ–Ω—è—Ç–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é"""

                system_prompt = """–¢—ã ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. 
–ë—É–¥—å —Ç–æ—á–Ω—ã–º, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º. –ò–∑–±–µ–≥–∞–π –æ–±—â–∏—Ö —Ñ—Ä–∞–∑, —Ñ–æ–∫—É—Å–∏—Ä—É–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–µ."""

                response = await self.thinker.call_llm(system_prompt, synthesis_prompt, temperature=0.7)
                self.deep_thoughts_count += 1
            else:
                response = await self._generate_standard_response(user_input, context)
        else:
            response = await self._generate_standard_response(user_input, context)

        return response.strip() if response else "–ò–∑–≤–∏–Ω–∏—Ç–µ, –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."

    async def _generate_standard_response(self, user_input: str, context: str) -> str:
        system_prompt = f"""–¢—ã ‚Äî –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ —Å –¥–æ—Å—Ç—É–ø–æ–º –∫ –ø–∞–º—è—Ç–∏ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É.

–ö–û–ù–¢–ï–ö–°–¢:
{context}

–ü–†–ò–ù–¶–ò–ü–´ –û–¢–í–ï–¢–ê:
- –ò—Å–ø–æ–ª—å–∑—É–π —Ñ–∞–∫—Ç—ã –∏–∑ –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –∏—Ö –Ω–∞–ª–∏—á–∏–∏
- –ë—É–¥—å —Ç–æ—á–Ω—ã–º –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º
- –û—Ç–≤–µ—á–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –ø–æ–ª–µ–∑–Ω–æ
- –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞ ‚Äî —á–µ—Å—Ç–Ω–æ –≥–æ–≤–æ—Ä–∏ –æ–± —ç—Ç–æ–º
- –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Å–ª–æ–∂–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
- –ò–∑–±–µ–≥–∞–π –∏–∑–ª–∏—à–Ω–µ–π —Ç–µ—Ö–Ω–∏—á–Ω–æ—Å—Ç–∏, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç

–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–∏—à–µ—Ç –ø–æ-—Ä—É—Å—Å–∫–∏."""

        return await self.thinker.call_llm(system_prompt, user_input, temperature=0.6)

    async def _detect_patterns(self, user_id: int = 0):
        with self.db.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('''
                SELECT category, COUNT(*) as count
                FROM interactions
                WHERE timestamp > ? AND (user_id = ? OR user_id = 0) AND category IS NOT NULL
                GROUP BY category
                HAVING count > 2
            ''', (time.time() - 7 * 86400, user_id))

            categories = cursor.fetchall()
            for category, count in categories:
                if category:
                    self.db.add_pattern(
                        'frequent_category',
                        f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á–∞—Å—Ç–æ —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ '{category}'",
                        confidence=min(1.0, count / 10)
                    )

            cursor.execute('''
                SELECT strftime('%H', datetime(timestamp, 'unixepoch')) as hour, COUNT(*) as count
                FROM interactions
                WHERE timestamp > ? AND (user_id = ? OR user_id = 0)
                GROUP BY hour
                HAVING count > 3
            ''', (time.time() - 7 * 86400, user_id))

            time_patterns = cursor.fetchall()
            for hour, count in time_patterns:
                self.db.add_pattern(
                    'time_preference',
                    f"–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ {hour}:00 (–≤—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å {count} —Ä–∞–∑)",
                    confidence=min(1.0, count / 20)
                )

            self.patterns_found = len(categories) + len(time_patterns)

    async def _deep_autonomous_thinking(self):
        print("\nüí≠ [–ó–∞–ø—É—Å–∫ –≥–ª—É–±–æ–∫–æ–≥–æ –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è...]")

        try:
            recent = self.db.get_contextual_interactions("–∞–Ω–∞–ª–∏–∑ —Ä–µ—Ñ–ª–µ–∫—Å–∏—è", limit=7)
            patterns = self.db.get_patterns(min_confidence=0.6, limit=5)
            insights = self.db.get_thought_insights(limit=5)

            if not recent:
                print("  üí≠ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
                return

            context_lines = [
                "üìä –ü–û–°–õ–ï–î–ù–ò–ï –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø:",
                *[f"- {i['user_input'][:50]}..." for i in recent[:3]],
                "\nüîç –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´:",
                *[f"- {p['description']}" for p in patterns[:3]],
                "\nüí° –ò–ù–°–ê–ô–¢–´ –ò–ó –ü–†–ï–î–´–î–£–©–ò–• –†–ê–ó–ú–´–®–õ–ï–ù–ò–ô:",
                *[f"- {t['thought_type']}: {t['count']} —Å–ª—É—á–∞–µ–≤" for t in insights[:3]]
            ]
            context = "\n".join(context_lines)

            thoughts = await self.thinker.multi_level_thinking(context, depth=4)

            for thought_type, content in thoughts.items():
                if content and len(content) > 20:
                    self.db.add_thought(
                        thought_type=thought_type,
                        content=content,
                        trigger='autonomous_deep_thinking',
                        importance=0.8,
                        depth_level=4,
                        confidence=0.7,
                        outcome='reflection_completed'
                    )
                    print(f"  üí° [{thought_type.upper()}] {content[:80]}...")

            await self._update_self_assessment()

            print("‚úÖ –ì–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –≥–ª—É–±–æ–∫–æ–º –º—ã—à–ª–µ–Ω–∏–∏: {e}")

    async def _update_self_assessment(self):
        with self.db.get_connection() as conn:
            cursor = conn.cursor()

            cursor.execute('''
                SELECT AVG(satisfaction) FROM interactions
                WHERE timestamp > ?
            ''', (time.time() - 86400,))
            avg_satisfaction = cursor.fetchone()[0] or 0.5

            cursor.execute('''
                SELECT category, AVG(satisfaction) as avg_sat
                FROM interactions
                WHERE timestamp > ? AND category IS NOT NULL
                GROUP BY category
                HAVING avg_sat < 0.5 AND COUNT(*) > 2
            ''', (time.time() - 7 * 86400,))
            weak_categories = [row[0] for row in cursor.fetchall()]

            cursor.execute('''
                SELECT category, AVG(satisfaction) as avg_sat
                FROM interactions
                WHERE timestamp > ? AND category IS NOT NULL
                GROUP BY category
                HAVING avg_sat > 0.7 AND COUNT(*) > 2
            ''', (time.time() - 7 * 86400,))
            strong_categories = [row[0] for row in cursor.fetchall()]

            self.self_assessment.update({
                'avg_satisfaction': avg_satisfaction,
                'improvement_areas': weak_categories[:5],
                'strong_areas': strong_categories[:5],
                'patterns_discovered': self.patterns_found,
                'deep_thoughts': self.deep_thoughts_count,
                'total_interactions': self.interaction_count
            })

    def _handle_command(self, text: str) -> Optional[str]:
        text_lower = text.lower().strip()

        command_map = {
            '–¥—É–º–∞–π –≥–ª—É–±–æ–∫–æ': "üß† –ó–∞–ø—É—Å–∫–∞—é –≥–ª—É–±–æ–∫–æ–µ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ...",
            '–≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ': "üß† –ó–∞–ø—É—Å–∫–∞—é –≥–ª—É–±–æ–∫–æ–µ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ...",
            '–∞–Ω–∞–ª–∏–∑': None,
            '–ø–∞—Ç—Ç–µ—Ä–Ω—ã': None,
            '–∏–Ω—Å–∞–π—Ç—ã': None,
            '—Ü–µ–ª–∏': None,
            '—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞': None,
            '—Ñ–∞–∫—Ç—ã': None,
            '–≤—ã—Ö–æ–¥': "üëã –î–æ –Ω–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á!",
            'exit': "üëã Goodbye!",
            'quit': "üëã Goodbye!"
        }

        if text_lower in command_map:
            response = command_map[text_lower]
            if response:
                if '–≥–ª—É–±–æ–∫–æ–µ' in text_lower:
                    asyncio.create_task(self._deep_autonomous_thinking())
                return response

        return None

    def _get_comprehensive_analysis(self) -> str:
        lines = ["üîç –ö–û–ú–ü–õ–ï–ö–°–ù–´–ô –ê–ù–ê–õ–ò–ó –°–ò–°–¢–ï–ú–´", "=" * 60]

        lines.append(f"\nüìä –í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: {self._format_uptime()}")
        lines.append(f"–í—Å–µ–≥–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π: {self.interaction_count}")
        lines.append(f"–ì–ª—É–±–æ–∫–∏—Ö –º—ã—Å–ª–µ–π: {self.deep_thoughts_count}")
        lines.append(f"–ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {self.patterns_found}")

        lines.append(f"\nüìà –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞:")
        lines.append(f"  –°—Ä–µ–¥–Ω—è—è —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å: {self.self_assessment.get('avg_satisfaction', 0.5):.2f}")
        lines.append(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {self.self_assessment.get('avg_response_time', 0):.2f}—Å")

        if self.self_assessment.get('strong_areas'):
            lines.append("\n‚úÖ –°–∏–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏:")
            for area in self.self_assessment['strong_areas'][:3]:
                lines.append(f"  ‚Ä¢ {area}")

        if self.self_assessment.get('improvement_areas'):
            lines.append("\n‚ö†Ô∏è –û–±–ª–∞—Å—Ç–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è:")
            for area in self.self_assessment['improvement_areas'][:3]:
                lines.append(f"  ‚Ä¢ {area}")

        return "\n".join(lines)

    def _format_patterns(self) -> str:
        patterns = self.db.get_patterns(min_confidence=0.5, limit=15)
        if not patterns:
            return "üîç –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ–∫–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ."

        lines = ["üîç –û–ë–ù–ê–†–£–ñ–ï–ù–ù–´–ï –ü–ê–¢–¢–ï–†–ù–´", "=" * 60]

        by_type = defaultdict(list)
        for p in patterns:
            by_type[p['pattern_type']].append(p)

        for ptype, plist in by_type.items():
            lines.append(f"\nüìå {ptype.upper().replace('_', ' ')}:")
            for p in plist:
                conf_bar = "‚ñà" * int(p['confidence'] * 10)
                lines.append(f"  ‚Ä¢ {p['description']}")
                lines.append(
                    f"    –í—Å—Ç—Ä–µ—á–∞–ª–æ—Å—å: {p['occurrences']} —Ä–∞–∑ | –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: [{conf_bar}] {p['confidence']:.2f}")

        return "\n".join(lines)

    def _format_insights(self) -> str:
        insights = self.db.get_thought_insights(limit=10)
        if not insights:
            return "üí° –ò–Ω—Å–∞–π—Ç–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç."

        lines = ["üí° –ò–ù–°–ê–ô–¢–´ –ò–ó –ú–´–°–õ–ï–ô", "=" * 60]

        for insight in insights:
            lines.append(f"\nüß† {insight['thought_type'].upper().replace('_', ' ')}:")
            lines.append(f"  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {insight['count']}")
            lines.append(f"  –°—Ä–µ–¥–Ω—è—è –≤–∞–∂–Ω–æ—Å—Ç—å: {insight['avg_importance']:.2f}")

        return "\n".join(lines)

    def _format_goal_hierarchy(self) -> str:
        main_goals = self.db.get_goal_hierarchy(parent_id=None)
        if not main_goals:
            return "üéØ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö —Ü–µ–ª–µ–π."

        lines = ["üéØ –ò–ï–†–ê–†–•–ò–Ø –¶–ï–õ–ï–ô", "=" * 60]

        for goal in main_goals:
            progress_bar = "‚ñà" * int(goal['progress'] * 10) + "‚ñë" * (10 - int(goal['progress'] * 10))
            lines.append(f"\nüìç {goal['description']}")
            lines.append(f"  –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: {goal['priority']:.2f} | –ü—Ä–æ–≥—Ä–µ—Å—Å: [{progress_bar}] {goal['progress']:.0%}")
            lines.append(f"  –°—Ç–∞—Ç—É—Å: {goal['status']}")

            if goal['next_action']:
                lines.append(f"  –°–ª–µ–¥—É—é—â–∏–π —à–∞–≥: {goal['next_action']}")

            subgoals = self.db.get_goal_hierarchy(parent_id=goal['id'])
            if subgoals:
                lines.append("  –ü–æ–¥—Ü–µ–ª–∏:")
                for sub in subgoals[:3]:
                    sub_bar = "‚ñà" * int(sub['progress'] * 5)
                    lines.append(f"    ‚Ä¢ {sub['description'][:50]} [{sub_bar}]")

        return "\n".join(lines)

    def _get_comprehensive_stats(self) -> str:
        lines = ["üìä –ü–û–õ–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´", "=" * 70]

        lines.append(f"\n‚è±Ô∏è {self._format_uptime()}")
        lines.append(f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π: {self.interaction_count}")
        lines.append(f"–ì–ª—É–±–æ–∫–∏—Ö –º—ã—Å–ª–µ–π: {self.deep_thoughts_count}")
        lines.append(f"–ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {self.patterns_found}")

        lines.append("\nüìà –°–∞–º–æ–æ—Ü–µ–Ω–∫–∞:")
        lines.append(f"  –°—Ä–µ–¥–Ω—è—è —É–¥–æ–≤–ª–µ—Ç–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç—å: {self.self_assessment.get('avg_satisfaction', 0.5):.2f}")
        lines.append(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞: {self.self_assessment.get('avg_response_time', 0):.2f}—Å")
        lines.append(f"  –°–∏–ª—å–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏: {len(self.self_assessment.get('strong_areas', []))}")
        lines.append(f"  –û–±–ª–∞—Å—Ç–∏ —É–ª—É—á—à–µ–Ω–∏—è: {len(self.self_assessment.get('improvement_areas', []))}")

        lines.append("\n‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:")
        lines.append(f"  –ú–æ–¥–µ–ª—å: {Config.MODEL}")
        lines.append(f"  –†–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞: {Config.CONTEXT_WINDOW_SIZE}")
        lines.append(f"  –ò–Ω—Ç–µ—Ä–≤–∞–ª —Ä–µ—Ñ–ª–µ–∫—Å–∏–∏: {Config.REFLECTION_INTERVAL}")
        lines.append(f"  –ü–æ—Ä–æ–≥ –≥–ª—É–±–æ–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è: {Config.DEEP_THINKING_THRESHOLD}")

        return "\n".join(lines)

    def _format_uptime(self) -> str:
        uptime = time.time() - self.start_time
        days = uptime // 86400
        hours = (uptime % 86400) // 3600
        minutes = (uptime % 3600) // 60
        seconds = uptime % 60

        parts = []
        if days > 0:
            parts.append(f"{int(days)}–¥")
        if hours > 0:
            parts.append(f"{int(hours)}—á")
        if minutes > 0:
            parts.append(f"{int(minutes)}–º")
        parts.append(f"{int(seconds)}—Å")

        return "–í—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã: " + " ".join(parts)

    def _get_context_summary(self) -> str:
        if not self.context_window:
            return ""

        summary = []
        for item in list(self.context_window)[-4:]:
            prefix = "–ü:" if item['type'] == 'user' else "–Ø:"
            content = item['content']
            if len(content) > 50:
                content = content[:47] + "..."
            summary.append(f"{prefix} {content}")

        return "\n".join(summary)

    def _categorize_input(self, text: str, features: Dict) -> str:
        text_lower = text.lower()

        categories = {
            '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞': ['—Å–∫–æ–ª—å–∫–æ', '–ø–æ—Å—á–∏—Ç–∞–π', '–≤—ã—á–∏—Å–ª–∏', '—Å—É–º–º–∞', '—Ä–∞–∑–Ω–æ—Å—Ç—å', '–ø—Ä–æ—Ü–µ–Ω—Ç', '—Ä–∞–≤–Ω–æ'],
            '–ø–∞–º—è—Ç—å': ['–∑–∞–ø–æ–º–Ω–∏', '—Å–æ—Ö—Ä–∞–Ω–∏', '–Ω–∞–ø–æ–º–Ω–∏', '–∑–∞–ø–∏—Å—ã–≤–∞–π', '–Ω–µ –∑–∞–±—ã–≤–∞–π'],
            '–∞–Ω–∞–ª–∏–∑': ['–ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π', '—Ä–∞–∑–±–µ—Ä–∏', '–æ—Ü–µ–Ω–∏', '—Å—Ä–∞–≤–Ω–∏', '–∏—Å—Å–ª–µ–¥—É–π'],
            '—Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ': ['–ø—Ä–∏–¥—É–º–∞–π', '—Å–æ–∑–¥–∞–π', '—Å–æ—á–∏–Ω–∏', '–Ω–∞–ø–∏—à–∏', '–≥–µ–Ω–µ—Ä–∞—Ü–∏—è'],
            '–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ': ['–ø–ª–∞–Ω', '—Ä–∞—Å–ø–∏—à–∏', '–∫–∞–∫ –¥–æ—Å—Ç–∏—á—å', '—Å—Ç—Ä–∞—Ç–µ–≥–∏—è', '—Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ'],
            '–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ': ['–ø–æ—á–µ–º—É', '–∫–∞–∫', '–∑–∞—á–µ–º', '–æ–±—ä—è—Å–Ω–∏', '—Ä–∞—Å—Å–∫–∞–∂–∏', '—á—Ç–æ —Ç–∞–∫–æ–µ'],
            '–ø–æ–∏—Å–∫': ['–Ω–∞–π–¥–∏', '–ø–æ–∫–∞–∂–∏', '–≥–¥–µ', '–∏—â–∏', '–Ω–∞–π—Ç–∏', '–ø–æ–∏—Å–∫'],
            '—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –ø–æ–º–æ—â—å': ['–ø–æ–º–æ–≥–∏', '–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç', '–æ—à–∏–±–∫–∞', '–ø—Ä–æ–±–ª–µ–º–∞', '–∏—Å–ø—Ä–∞–≤—å'],
            '—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–µ': ['—à—É—Ç–∫–∞', '—Ä–∞—Å—Å–∫–∞–∂–∏ –∏—Å—Ç–æ—Ä–∏—é', '—Ä–∞–∑–≤–ª–µ–∫–∏', '–∏–≥—Ä–∞'],
            '–¥–∏–∞–ª–æ–≥': ['–ø—Ä–∏–≤–µ—Ç', '–∫–∞–∫ –¥–µ–ª–∞', '—Å–ø–∞—Å–∏–±–æ', '–ø–æ–∫–∞']
        }

        scores = {}
        for category, keywords in categories.items():
            score = sum(1 for kw in keywords if kw in text_lower)
            if score > 0:
                scores[category] = score

        if scores:
            return max(scores.items(), key=lambda x: x[1])[0]

        if features['has_question']:
            return '–≤–æ–ø—Ä–æ—Å'
        elif features['imperatives'] > 0:
            return '–∫–æ–º–∞–Ω–¥–∞'
        elif features['emotions'] > 0:
            return '—ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π'

        return '–æ–±—â–∏–π'


# ================= –•–†–ê–ù–ò–õ–ò–©–ï –°–ï–°–°–ò–ô –ë–û–¢–ê =================

class UserSessionManager:
    """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ —Å–µ—Å—Å–∏—è–º–∏ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""

    def __init__(self):
        self.sessions: Dict[int, Dict] = {}
        self.global_agent: Optional[EnhancedAutonomousAgent] = None
        self.session_timeout = 3600  # 1 —á–∞—Å

        print("‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (–±–µ–∑ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á)")

    async def get_or_create_session(self, user_id: int) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        now = time.time()

        if user_id not in self.sessions:
            print(f"üÜï –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            try:
                if self.global_agent is None:
                    self.global_agent = EnhancedAutonomousAgent()

                self.sessions[user_id] = {
                    'agent': self.global_agent,
                    'created_at': datetime.now(),
                    'last_activity': datetime.now(),
                    'message_count': 0,
                    'user_id': user_id,
                    'last_timestamp': now
                }
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å–µ—Å—Å–∏–∏ –¥–ª—è {user_id}: {e}")
                raise
        else:
            self.sessions[user_id]['last_activity'] = datetime.now()
            self.sessions[user_id]['last_timestamp'] = now

        return self.sessions[user_id]

    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø–æ —Å–µ—Å—Å–∏—è–º"""
        now = time.time()
        active_sessions = 0
        total_messages = 0

        for session in self.sessions.values():
            if now - session['last_timestamp'] < self.session_timeout:
                active_sessions += 1
                total_messages += session['message_count']

        return {
            'total_users': len(self.sessions),
            'active_users': active_sessions,
            'total_messages': total_messages,
            'session_timeout': self.session_timeout
        }

    async def cleanup_inactive_sessions(self):
        """–û—á–∏—Å—Ç–∫–∞ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π (–≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤—Ä—É—á–Ω—É—é)"""
        now = time.time()
        inactive_users = []

        for user_id, session in self.sessions.items():
            if now - session['last_timestamp'] > self.session_timeout:
                inactive_users.append(user_id)

        for user_id in inactive_users:
            print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
            del self.sessions[user_id]

        if inactive_users:
            print(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {len(inactive_users)} –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π")


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô
session_manager = UserSessionManager()


# ================= –£–¢–ò–õ–ò–¢–´ –ë–û–¢–ê =================

def split_message(text: str, max_length: int = Config.MAX_MESSAGE_LENGTH) -> list:
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏"""
    if len(text) <= max_length:
        return [text]

    parts = []
    current_part = ""

    paragraphs = text.split('\n\n')

    for para in paragraphs:
        if len(current_part) + len(para) + 2 <= max_length:
            if current_part:
                current_part += '\n\n' + para
            else:
                current_part = para
        else:
            if current_part:
                parts.append(current_part)

            if len(para) > max_length:
                sentences = re.split(r'(?<=[.!?])\s+', para)
                current_sentence = ""

                for sentence in sentences:
                    if len(current_sentence) + len(sentence) + 1 <= max_length:
                        if current_sentence:
                            current_sentence += ' ' + sentence
                        else:
                            current_sentence = sentence
                    else:
                        if current_sentence:
                            parts.append(current_sentence)
                        current_sentence = sentence

                if current_sentence:
                    current_part = current_sentence
            else:
                current_part = para

    if current_part:
        parts.append(current_part)

    if len(parts) > Config.MAX_RESPONSE_CHUNKS:
        parts = parts[:Config.MAX_RESPONSE_CHUNKS]
        parts.append("\n\nüìù *–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –ø–æ–∫–∞–∑–∞–Ω–∞ —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å*")

    return parts


def create_main_keyboard() -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–π –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã"""
    keyboard = [
        [
            InlineKeyboardButton("üß† –ì–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ", callback_data="deep_think"),
            InlineKeyboardButton("üîç –ê–Ω–∞–ª–∏–∑", callback_data="analysis")
        ],
        [
            InlineKeyboardButton("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞", callback_data="stats"),
            InlineKeyboardButton("üéØ –¶–µ–ª–∏", callback_data="goals")
        ],
        [
            InlineKeyboardButton("üí° –ò–Ω—Å–∞–π—Ç—ã", callback_data="insights"),
            InlineKeyboardButton("üîó –ü–∞—Ç—Ç–µ—Ä–Ω—ã", callback_data="patterns")
        ],
        [
            InlineKeyboardButton("üìö –§–∞–∫—Ç—ã", callback_data="facts"),
            InlineKeyboardButton("‚ùì –ü–æ–º–æ—â—å", callback_data="help")
        ]
    ]
    return InlineKeyboardMarkup(keyboard)


# ================= –û–ë–†–ê–ë–û–¢–ß–ò–ö–ò –ö–û–ú–ê–ù–î =================

async def start_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user = update.effective_user
    user_id = user.id

    print(f"üëã –ù–æ–≤—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user.first_name} (ID: {user_id})")

    try:
        await session_manager.get_or_create_session(user_id)
    except Exception as e:
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ—Å—Å–∏–∏: {str(e)[:100]}\n\n"
            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑ —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥."
        )
        return

    welcome_text = f"""üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!

üß† –Ø ‚Äî **AGI24 Cognitive System** ‚Äî –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –∞–≥–µ–Ω—Ç:

‚ú® **–ú–æ–∏ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏:**
‚Ä¢ ü§Ø –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
‚Ä¢ üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø–∞–º—è—Ç—å –∏ –æ–±—É—á–µ–Ω–∏–µ
‚Ä¢ üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ —Å–∫—Ä—ã—Ç—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
‚Ä¢ üí° –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á
‚Ä¢ üìä –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ

üí¨ **–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å, –∏ —è –ø–æ–º–æ–≥—É!**

üìå **–ò—Å–ø–æ–ª—å–∑—É–π –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ** –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞:
/help ‚Äî –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥
/stats ‚Äî —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
/think ‚Äî –∞–∫—Ç–∏–≤–∞—Ü–∏—è –≥–ª—É–±–æ–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è
/clear ‚Äî –æ—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

üöÄ **–ü—Ä–∏–º–µ—Ä—ã:**
‚Ä¢ "–ó–∞–ø–æ–º–Ω–∏, —á—Ç–æ Python ‚Äî –º–æ–π –ª—é–±–∏–º—ã–π —è–∑—ã–∫"
‚Ä¢ "–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 25 * 34 + 17?"
‚Ä¢ "–ü—Ä–∏–¥—É–º–∞–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è..."
‚Ä¢ "–û–±—ä—è—Å–Ω–∏ —Å–ª–æ–∂–Ω—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –ø—Ä–æ—Å—Ç–æ"

üìà **–Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ —É—á—É—Å—å –Ω–∞ –¥–∏–∞–ª–æ–≥–∞—Ö!**"""

    try:
        await update.message.reply_text(
            welcome_text,
            reply_markup=create_main_keyboard(),
            parse_mode='Markdown'
        )
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è: {e}")
        await update.message.reply_text(
            f"üëã –ü—Ä–∏–≤–µ—Ç, {user.first_name}!\n\n"
            "–Ø ‚Äî –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ AGI24. –ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!\n"
            "–ò—Å–ø–æ–ª—å–∑—É–π /help –¥–ª—è —Å–ø–∏—Å–∫–∞ –∫–æ–º–∞–Ω–¥."
        )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    help_text = """üìñ **–ü–û–õ–ù–´–ô –°–ü–†–ê–í–û–ß–ù–ò–ö –ö–û–ú–ê–ù–î**

**üéØ –û–°–ù–û–í–ù–´–ï –ö–û–ú–ê–ù–î–´:**
/start ‚Äî –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã
/help ‚Äî —ç—Ç–æ—Ç —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫
/stats ‚Äî –ø–æ–ª–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
/clear ‚Äî –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç

**üß† –ö–û–ì–ù–ò–¢–ò–í–ù–´–ï –§–£–ù–ö–¶–ò–ò:**
/think ‚Äî –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
/analyze ‚Äî –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã
/goals ‚Äî –ø–æ–∫–∞–∑–∞—Ç—å —Ü–µ–ª–∏ —Å–∏—Å—Ç–µ–º—ã
/patterns ‚Äî –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
/insights ‚Äî –∏–Ω—Å–∞–π—Ç—ã –∏–∑ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π
/facts ‚Äî —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã

**üí° –ü–†–ò–ú–ï–†–´ –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø:**
‚Ä¢ *–ü—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã:* "–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?"
‚Ä¢ *–ê–Ω–∞–ª–∏–∑:* "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç—É —Å–∏—Ç—É–∞—Ü–∏—é"
‚Ä¢ *–ü–∞–º—è—Ç—å:* "–ó–∞–ø–æ–º–Ω–∏, —á—Ç–æ —è –ª—é–±–ª—é –∫–æ—Ñ–µ"
‚Ä¢ *–¢–≤–æ—Ä—á–µ—Å—Ç–≤–æ:* "–ü—Ä–∏–¥—É–º–∞–π –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞"
‚Ä¢ *–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ:* "–ü–æ–º–æ–≥–∏ —Å–ø–ª–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –¥–µ–Ω—å"
‚Ä¢ *–û–±—É—á–µ–Ω–∏–µ:* "–û–±—ä—è—Å–Ω–∏ –∫–≤–∞–Ω—Ç–æ–≤—É—é —Ñ–∏–∑–∏–∫—É –ø—Ä–æ—Å—Ç–æ"

**üéÆ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ï –í–û–ó–ú–û–ñ–ù–û–°–¢–ò:**
‚Ä¢ –ò—Å–ø–æ–ª—å–∑—É–π –∫–Ω–æ–ø–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
‚Ä¢ –ë–æ—Ç –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
‚Ä¢ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
‚Ä¢ –ê–¥–∞–ø—Ç–∞—Ü–∏—è –∫ —Å—Ç–∏–ª—é –æ–±—â–µ–Ω–∏—è
‚Ä¢ –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

üí¨ **–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å ‚Äî –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å!**"""

    try:
        await update.message.reply_text(
            help_text,
            parse_mode='Markdown'
        )
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –ø–æ–º–æ—â–∏: {e}")
        await update.message.reply_text(
            "–ò—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã:\n"
            "/start - –Ω–∞—á–∞—Ç—å\n"
            "/stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n"
            "/help - –ø–æ–¥—Ä–æ–±–Ω–∞—è –ø–æ–º–æ—â—å\n"
            "\n–ò–ª–∏ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ!"
        )


async def stats_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        stats = agent._get_comprehensive_stats()

        bot_stats = session_manager.get_stats()
        stats += f"\n\nü§ñ **–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ë–û–¢–ê:**"
        stats += f"\n–í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {bot_stats['total_users']}"
        stats += f"\n–ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ–π—á–∞—Å: {bot_stats['active_users']}"
        stats += f"\n–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {bot_stats['total_messages']}"
        stats += f"\n–°–æ–æ–±—â–µ–Ω–∏–π –≤ –≤–∞—à–µ–π —Å–µ—Å—Å–∏–∏: {session['message_count']}"

        parts = split_message(stats)
        for i, part in enumerate(parts):
            if i == 0:
                await update.message.reply_text(part, parse_mode='Markdown')
            else:
                await update.message.reply_text(part)

            if i < len(parts) - 1:
                await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ stats_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {str(e)[:100]}"
        )


async def think_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        await update.message.reply_text(
            "üß† –ê–∫—Ç–∏–≤–∏—Ä—É—é –≥–ª—É–±–æ–∫–æ–µ –º–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ –º—ã—à–ª–µ–Ω–∏–µ...\n"
            "–≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è."
        )

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        await agent._deep_autonomous_thinking()

        await update.message.reply_text(
            "‚úÖ –ì–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!\n"
            "–ü—Ä–æ–≤–µ—Ä—å—Ç–µ /insights –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–ª–∏ /analyze –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–∏—Å—Ç–µ–º—ã.",
            reply_markup=create_main_keyboard()
        )

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ think_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –≥–ª—É–±–æ–∫–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è: {str(e)[:100]}"
        )


async def analyze_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        analysis = agent._get_comprehensive_analysis()
        parts = split_message(analysis)

        for i, part in enumerate(parts):
            if i == 0:
                await update.message.reply_text(part, parse_mode='Markdown')
            else:
                await update.message.reply_text(part)

            if i < len(parts) - 1:
                await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ analyze_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:100]}"
        )


async def goals_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        goals = agent._format_goal_hierarchy()
        parts = split_message(goals)

        for part in parts:
            await update.message.reply_text(part)
            await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ goals_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–ª–µ–π: {str(e)[:100]}"
        )


async def patterns_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        patterns = agent._format_patterns()
        parts = split_message(patterns)

        for part in parts:
            await update.message.reply_text(part)
            await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ patterns_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {str(e)[:100]}"
        )


async def insights_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        insights = agent._format_insights()
        parts = split_message(insights)

        for part in parts:
            await update.message.reply_text(part)
            await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ insights_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Å–∞–π—Ç–æ–≤: {str(e)[:100]}"
        )


async def facts_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        facts = agent.db.get_relevant_facts("–≤—Å–µ —Ñ–∞–∫—Ç—ã", limit=25)
        if not facts:
            await update.message.reply_text(
                "üìö –§–∞–∫—Ç–æ–≤ –ø–æ–∫–∞ –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ.\n\n"
                "–ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ñ–∞–∫—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞:\n"
                "‚Ä¢ \"–ó–∞–ø–æ–º–Ω–∏, —á—Ç–æ —è –ª—é–±–ª—é –∫–æ—Ñ–µ\"\n"
                "‚Ä¢ \"Python = –º–æ–π –ª—é–±–∏–º—ã–π —è–∑—ã–∫\"\n"
                "‚Ä¢ \"–ú–æ–π –¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è ‚Äî 15 —è–Ω–≤–∞—Ä—è\""
            )
            return

        categories = defaultdict(list)
        for fact in facts:
            category = fact.get('category', '—Ä–∞–∑–Ω–æ–µ')
            categories[category].append(fact)

        lines = ["üìö **–°–û–•–†–ê–ù–Å–ù–ù–´–ï –§–ê–ö–¢–´:**\n"]

        for category, category_facts in categories.items():
            lines.append(f"\nüìå **{category.upper()}:**")
            for fact in category_facts[:5]:
                confidence_stars = "‚òÖ" * int(fact['confidence'] * 5)
                lines.append(f"‚Ä¢ *{fact['key']}:* {fact['value']} [{confidence_stars}]")

            if len(category_facts) > 5:
                lines.append(f"... –∏ –µ—â—ë {len(category_facts) - 5}")

        lines.append(f"\nüìä –í—Å–µ–≥–æ —Ñ–∞–∫—Ç–æ–≤: {len(facts)}")

        text = "\n".join(lines)
        parts = split_message(text)

        for i, part in enumerate(parts):
            if i == 0:
                await update.message.reply_text(part, parse_mode='Markdown')
            else:
                await update.message.reply_text(part)

            if i < len(parts) - 1:
                await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ facts_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤: {str(e)[:100]}"
        )


async def clear_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        agent.context_window.clear()

        await update.message.reply_text(
            "üßπ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –æ—á–∏—â–µ–Ω!\n\n"
            "–¢–µ–ø–µ—Ä—å —è –Ω–µ –ø–æ–º–Ω—é –ø—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —ç—Ç–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞.\n"
            "–ü–∞–º—è—Ç—å –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞–ª–∞—Å—å –Ω–µ—Ç—Ä–æ–Ω—É—Ç–æ–π.",
            reply_markup=create_main_keyboard()
        )

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ clear_command: {e}")
        await update.message.reply_text(
            f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {str(e)[:100]}"
        )


async def ping_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /ping"""
    try:
        await update.message.reply_text(
            "üèì Pong!\n\n"
            "‚úÖ –ë–æ—Ç –∞–∫—Ç–∏–≤–µ–Ω –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç\n"
            "üìÖ " + datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ ping_command: {e}")


# ================= –û–ë–†–ê–ë–û–¢–ß–ò–ö –ö–ù–û–ü–û–ö =================

async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query

    try:
        await query.answer()
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ answer callback: {e}")

    user_id = update.effective_user.id
    callback_data = query.data

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        response = ""
        parse_mode = None

        if callback_data == "deep_think":
            await query.message.reply_text("üß† –ê–∫—Ç–∏–≤–∏—Ä—É—é –≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ...")
            await agent._deep_autonomous_thinking()
            response = "‚úÖ –ì–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ü—Ä–æ–≤–µ—Ä—å—Ç–µ /insights –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."

        elif callback_data == "analysis":
            response = agent._get_comprehensive_analysis()
            parse_mode = 'Markdown'

        elif callback_data == "stats":
            response = agent._get_comprehensive_stats()
            bot_stats = session_manager.get_stats()
            response += f"\n\nü§ñ **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–æ—Ç–∞:**"
            response += f"\n–ê–∫—Ç–∏–≤–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {bot_stats['active_users']}"
            response += f"\n–í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {bot_stats['total_messages']}"
            response += f"\n–°–æ–æ–±—â–µ–Ω–∏–π –≤ –≤–∞—à–µ–π —Å–µ—Å—Å–∏–∏: {session['message_count']}"
            parse_mode = 'Markdown'

        elif callback_data == "goals":
            response = agent._format_goal_hierarchy()

        elif callback_data == "insights":
            response = agent._format_insights()

        elif callback_data == "patterns":
            response = agent._format_patterns()

        elif callback_data == "facts":
            facts = agent.db.get_relevant_facts("–≤—Å–µ", limit=15)
            if facts:
                response = "üìö **–°–û–•–†–ê–ù–Å–ù–ù–´–ï –§–ê–ö–¢–´:**\n\n"
                for fact in facts[:10]:
                    response += f"‚Ä¢ *{fact['key']}:* {fact['value'][:50]}\n"
                response += f"\nüìä –í—Å–µ–≥–æ –ø–æ–∫–∞–∑–∞–Ω–æ: {len(facts[:10])} –∏–∑ {len(facts)}"
                parse_mode = 'Markdown'
            else:
                response = "üìö –§–∞–∫—Ç–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –î–æ–±–∞–≤—å—Ç–µ —Ñ–∞–∫—Ç—ã —á–µ—Ä–µ–∑ –¥–∏–∞–ª–æ–≥."

        elif callback_data == "help":
            response = """üìñ **–ü–û–ú–û–©–¨ –ò –ö–û–ú–ê–ù–î–´**

üí¨ **–û—Å–Ω–æ–≤–Ω–æ–µ:** –ü—Ä–æ—Å—Ç–æ –ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∏ —è –±—É–¥—É –ø–æ–º–æ–≥–∞—Ç—å!

üéØ **–û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:**
/start - –Ω–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã
/help - –ø–æ–ª–Ω–∞—è —Å–ø—Ä–∞–≤–∫–∞
/stats - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã
/clear - –æ—á–∏—Å—Ç–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç

üß† **–ö–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏:**
/think - –≥–ª—É–±–æ–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ
/analyze - –∞–Ω–∞–ª–∏–∑ —Å–∏—Å—Ç–µ–º—ã
/goals - —Ü–µ–ª–∏ —Å–∏—Å—Ç–µ–º—ã
/patterns - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã

üì± **–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ—É–Ω–∫—Ü–∏—è–º!**

üí° **–°–æ–≤–µ—Ç:** –Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –∏ —É—á—É—Å—å –Ω–∞ –¥–∏–∞–ª–æ–≥–∞—Ö."""
            parse_mode = 'Markdown'

        else:
            response = "‚ùì –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞"

        if response:
            parts = split_message(response)
            for i, part in enumerate(parts):
                if i == 0:
                    try:
                        await query.edit_message_text(
                            text=part,
                            parse_mode=parse_mode,
                            reply_markup=create_main_keyboard()
                        )
                    except Exception as e:
                        await query.message.reply_text(
                            part,
                            parse_mode=parse_mode,
                            reply_markup=create_main_keyboard()
                        )
                else:
                    await query.message.reply_text(part)

                if i < len(parts) - 1:
                    await asyncio.sleep(0.3)

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ button_callback: {e}")
        try:
            await query.edit_message_text(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)[:100]}",
                reply_markup=create_main_keyboard()
            )
        except:
            await query.message.reply_text(
                f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)[:100]}",
                reply_markup=create_main_keyboard()
            )


# ================= –û–ë–†–ê–ë–û–¢–ß–ò–ö –°–û–û–ë–©–ï–ù–ò–ô =================

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_message = update.message.text

    print(f"üì® –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç {user_id}: {user_message[:50]}...")

    try:
        session = await session_manager.get_or_create_session(user_id)
        agent = session['agent']
        session['message_count'] += 1

        await context.bot.send_chat_action(
            chat_id=update.effective_chat.id,
            action="typing"
        )

        await asyncio.sleep(Config.TYPING_DELAY)

        response = await agent.process_input(user_message, user_id)

        if response == "SYSTEM_EXIT":
            await update.message.reply_text("üëã –î–æ –Ω–æ–≤—ã—Ö –≤—Å—Ç—Ä–µ—á!")
            return

        parts = split_message(response, Config.MAX_MESSAGE_LENGTH)
        if len(parts) > Config.MAX_RESPONSE_CHUNKS:
            parts = parts[:Config.MAX_RESPONSE_CHUNKS]
            parts.append("\n\nüìù *–°–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –ø–æ–∫–∞–∑–∞–Ω–∞ —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å*")

        for i, part in enumerate(parts):
            await update.message.reply_text(
                part,
                parse_mode='Markdown' if i == 0 else None,
                reply_markup=create_main_keyboard() if i == len(parts) - 1 and session[
                    'message_count'] % 5 == 0 else None
            )

            if i < len(parts) - 1:
                await asyncio.sleep(0.5)

        if session['message_count'] % 10 == 0:
            await update.message.reply_text(
                "üí° –ß—Ç–æ –µ—â—ë –º–æ–≥—É —Å–¥–µ–ª–∞—Ç—å? –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –∫–æ–º–∞–Ω–¥—ã.",
                reply_markup=create_main_keyboard()
            )

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç {user_id}: {e}")

        error_message = f"‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è.\n\n"

        if "API" in str(e):
            error_message += "**–ü—Ä–æ–±–ª–µ–º–∞ —Å API:**\n"
            error_message += "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ\n"
            error_message += "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API –∫–ª—é—á –≤ .env —Ñ–∞–π–ª–µ\n"
            error_message += "‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –∫–ª—é—á –∞–∫—Ç–∏–≤–µ–Ω –Ω–∞ openrouter.ai\n\n"
        elif "–±–∞–∑" in str(e).lower() or "sql" in str(e).lower():
            error_message += "**–ü—Ä–æ–±–ª–µ–º–∞ —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö:**\n"
            error_message += "‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —Ñ–∞–π–ª–∞–º\n"
            error_message += "‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –µ—Å—Ç—å –º–µ—Å—Ç–æ –Ω–∞ –¥–∏—Å–∫–µ\n\n"
        elif "timeout" in str(e).lower():
            error_message += "**–¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞:**\n"
            error_message += "‚Ä¢ –°–µ—Ä–≤–µ—Ä –¥–æ–ª–≥–æ –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç\n"
            error_message += "‚Ä¢ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ —É–ø—Ä–æ—Å—Ç–∏—Ç–µ –∑–∞–ø—Ä–æ—Å\n\n"
        else:
            error_message += f"**–û—à–∏–±–∫–∞:** {str(e)[:150]}\n\n"

        error_message += "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞."

        try:
            await update.message.reply_text(
                error_message,
                parse_mode='Markdown',
                reply_markup=create_main_keyboard()
            )
        except Exception as send_error:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ: {send_error}")


# ================= –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö =================

async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    error = context.error

    logging.error(f"–ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞: {error}", exc_info=error)

    error_type = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
    user_message = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞."

    if isinstance(error, telegram.error.TimedOut):
        error_type = "–¢–∞–π–º–∞—É—Ç"
        user_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    elif isinstance(error, telegram.error.NetworkError):
        error_type = "–°–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞"
        user_message = "–ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ."
    elif isinstance(error, telegram.error.TelegramError):
        error_type = "–û—à–∏–±–∫–∞ Telegram API"
        user_message = "–ü—Ä–æ–±–ª–µ–º–∞ —Å Telegram API. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
    elif isinstance(error, asyncio.TimeoutError):
        error_type = "–¢–∞–π–º–∞—É—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏"
        user_message = "–û–ø–µ—Ä–∞—Ü–∏—è –∑–∞–Ω—è–ª–∞ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏."

    print(f"üö® –ì–ª–æ–±–∞–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ ({error_type}): {error}")

    if update and update.effective_message:
        try:
            await update.effective_message.reply_text(
                f"‚ö†Ô∏è {user_message}\n\n"
                f"–û—à–∏–±–∫–∞: {str(error)[:100]}\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /start –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞."
            )
        except Exception as e:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {e}")


# ================= –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø =================

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ ‚Äî –°–û–í–ú–ï–°–¢–ò–ú–û –° PYTHON 3.13"""
    print("=" * 70)
    print("üöÄ –ó–ê–ü–£–°–ö AGI24 –ö–û–ì–ù–ò–¢–ò–í–ù–û–ì–û –ê–ì–ï–ù–¢–ê –° TELEGRAM –ò–ù–¢–ï–†–§–ï–ô–°–û–ú")
    print("=" * 70)

    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )

    try:
        # ‚úÖ –ü–û–õ–£–ß–ï–ù–ò–ï –¢–û–ö–ï–ù–ê –ß–ï–†–ï–ó CONFIG (–±–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π)
        token = Config.get_telegram_token()
        print(f"‚úÖ –¢–æ–∫–µ–Ω Telegram –ø–æ–ª—É—á–µ–Ω: {token[:15]}...")

        # ‚úÖ –°–û–ó–î–ê–ù–ò–ï –ü–†–ò–õ–û–ñ–ï–ù–ò–Ø
        app = ApplicationBuilder().token(token).build()

        # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
        app.add_handler(CommandHandler("start", start_command))
        app.add_handler(CommandHandler("help", help_command))
        app.add_handler(CommandHandler("clear", clear_history))
        app.add_handler(CommandHandler("stats", show_stats))
        app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
        app.add_handler(MessageHandler(filters.PHOTO | filters.VIDEO | filters.AUDIO | filters.DOCUMENT, handle_media))
        app.add_error_handler(error_handler)

        print("\n" + "=" * 70)
        print("‚úÖ –ë–æ—Ç —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
        print("üì± –ù–∞–π–¥–∏—Ç–µ –±–æ—Ç–∞ –≤ Telegram –∏ –Ω–∞–ø–∏—à–∏—Ç–µ /start")
        print("\nüõë –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
        print("=" * 70 + "\n")

        # ‚úÖ –†–£–ß–ù–û–ô –ó–ê–ü–£–°–ö –ë–ï–ó run_polling() ‚Äî –ö–õ–Æ–ß–ï–í–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï
        await app.initialize()
        await app.start()

        # –ó–ê–ü–£–°–ö POLLING –ë–ï–ó –ü–ê–†–ê–ú–ï–¢–†–ê close_loop (–µ–≥–æ –Ω–µ—Ç –≤ —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö!)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        await app.updater.start_polling(
            allowed_updates=Update.ALL_TYPES,
            drop_pending_updates=True,
            # close_loop=False ‚Äî –£–î–ê–õ–ï–ù–û, —Ç–∞–∫ –∫–∞–∫ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è!
        )

        print("üîÑ –ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ –æ–∂–∏–¥–∞–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π...")
        print("   (–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏)\n")

        # –ë–µ—Å–∫–æ–Ω–µ—á–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø—Ä–µ—Ä—ã–≤–∞–Ω–∏—è
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ Ctrl+C
        while True:
            await asyncio.sleep(1)  # –ö–æ—Ä–æ—Ç–∫–∏–π —Å–æ–Ω –¥–ª—è –æ—Ç–∑—ã–≤—á–∏–≤–æ—Å—Ç–∏

    except KeyboardInterrupt:
        print("\nüëã –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ (Ctrl+C)...")
        raise
    except ValueError as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        print("\nüí° –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞:")
        print("OPENROUTER_API_KEY=–≤–∞—à_–∫–ª—é—á_openrouter")
        print("TELEGRAM_BOT_TOKEN=–≤–∞—à_—Ç–æ–∫–µ–Ω_–æ—Ç_BotFather")
        raise
    except Exception as e:
        print(f"\nüö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        # ‚úÖ –ö–û–†–†–ï–ö–¢–ù–û–ï –ó–ê–í–ï–†–®–ï–ù–ò–ï –ë–ï–ó –ü–û–ü–´–¢–û–ö –ó–ê–ö–†–´–¢–¨ –¶–ò–ö–õ
        print("\nüîÑ –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –±–æ—Ç–∞...")
        try:
            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ polling
            if hasattr(app, 'updater') and app.updater and app.updater.running:
                await app.updater.stop()
                print("‚úÖ Polling –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

            # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            if hasattr(app, 'running') and app.running:
                await app.stop()
                print("‚úÖ –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")

            # –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
            await app.shutdown()
            print("‚úÖ –†–µ—Å—É—Ä—Å—ã –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω—ã")

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏
            if session_manager:
                stats = session_manager.get_stats()
                print(f"\nüìä –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π: {stats['total_users']}")
                print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['total_messages']}")
                print(f"   ‚Ä¢ –ê–∫—Ç–∏–≤–Ω—ã—Ö —Å–µ—Å—Å–∏–π: {stats['active_users']}")

        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏: {e}")


def run():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –±–æ—Ç–∞ ‚Äî –°–û–í–ú–ï–°–¢–ò–ú–û –° PYTHON 3.13"""
    print("AGI24 Cognitive Bot - Version 3.0")
    print("Copyright (c) 2024 AGI24 Project")
    print("\n" + "=" * 70)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ Python
    if sys.version_info < (3, 8):
        print("‚ùå –¢—Ä–µ–±—É–µ—Ç—Å—è Python 3.8 –∏–ª–∏ –≤—ã—à–µ")
        print(f"üìå –£ –≤–∞—Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω Python {sys.version}")
        sys.exit(1)

    # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –≤–µ—Ä—Å–∏–∏ 3.13
    if sys.version_info >= (3, 13):
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –í–µ—Ä—Å–∏—è Python 3.13")
        print("üìå –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Python 3.10-3.12 –¥–ª—è –ø–æ–ª–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫
    required_libs = ['aiohttp', 'telegram']
    missing = []
    for lib in required_libs:
        try:
            __import__(lib)
        except ImportError:
            missing.append(lib)

    if missing:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(missing)}")
        print("üì¶ –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install python-telegram-bot aiohttp")
        sys.exit(1)
    else:
        print("‚úÖ –ë–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")

    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –∫–ª–∞—Å—Å–∞ UserSessionManager
    global session_manager
    try:
        session_manager = UserSessionManager()  # –ë—ã–ª–æ: SessionManager()
        print("‚úÖ –ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–µ—Å—Å–∏–π: {e}")

    # –ó–∞–ø—É—Å–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ü–∏–∫–ª–∞
    try:
        import asyncio

        # –î–ª—è Windows: –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º—É—é –ø–æ–ª–∏—Ç–∏–∫—É —Ü–∏–∫–ª–∞
        if sys.platform == 'win32':
            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

        # ‚úÖ nest_asyncio –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —É–∂–µ –∑–∞–ø—É—â–µ–Ω–Ω—ã–º —Ü–∏–∫–ª–æ–º (–≤ PyCharm)
        try:
            import nest_asyncio
            nest_asyncio.apply()
            print("‚úÖ nest_asyncio –ø—Ä–∏–º–µ–Ω—ë–Ω –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å Python 3.13")
        except ImportError:
            print("‚ö†Ô∏è  nest_asyncio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install nest_asyncio")

        # ‚úÖ asyncio.run() —Å–æ–∑–¥–∞—ë—Ç –ù–û–í–´–ô —á–∏—Å—Ç—ã–π —Ü–∏–∫–ª —Å–æ–±—ã—Ç–∏–π
        asyncio.run(main())

    except KeyboardInterrupt:
        print("\nüëã –ë–æ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
        print("\n‚úÖ –ë–æ—Ç –∑–∞–≤–µ—Ä—à–∏–ª —Ä–∞–±–æ—Ç—É –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        sys.exit(0)
    except Exception as e:
        print(f"\nüö® –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    run()
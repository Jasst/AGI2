# coding: utf-8
"""
AGI6.5.py ‚Äî –£–ª—É—á—à–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º—ã—à–ª–µ–Ω–∏—è —Å –ø–æ–ª–Ω—ã–º —Ü–∏–∫–ª–æ–º –æ–±—É—á–µ–Ω–∏—è
- –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
- –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
- –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å —Ñ–∞–∫—Ç–æ–≤
- –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞–±—ã–≤–∞–Ω–∏—è
- –ö–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- Self-supervised reasoning loop
"""
import os
import re
import random
import traceback
from collections import Counter, defaultdict, deque
from datetime import datetime
from typing import Dict, List, Optional, Set, Tuple, Any
import numpy as np
import requests
import torch
import torch.nn as nn
import torch.nn.functional as F

try:
    from sentence_transformers import SentenceTransformer
    _HAS_ST_MODEL = True
except Exception:
    _HAS_ST_MODEL = False

# ======================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# ======================
def clean_qwen_response(text: str) -> str:
    if not isinstance(text, str):
        return "–•–æ—Ä–æ—à–æ."
    text = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', text)
    text = re.sub(r'#{1,3}\s*', '', text)
    text = re.sub(r'>\s*', '', text)
    text = re.sub(r'\r\n', '\n', text)
    text = re.sub(r'\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    text = re.sub(r'^[\*\.\!\?\:\-\‚Äì‚Äî\s]+', '', text)
    text = re.sub(r'[\*\.\!\?\:\-\‚Äì‚Äî\s]+$', '', text)
    words = text.split()
    if len(words) > 60:
        text = ' '.join(words[:60])
        if not text.endswith(('.', '!', '?')):
            text += '.'
    return text or "–•–æ—Ä–æ—à–æ."

def safe_cell_name(base: str) -> str:
    name = re.sub(r'[^a-zA-Z–∞-—è–ê-–Ø0-9_]', '_', base)
    name = re.sub(r'_+', '_', name)
    name = name.strip('_')
    return name if name else "unknown"

def clean_for_similarity(text: str) -> str:
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    text = re.sub(r'\s+', ' ', text)
    return text.lower().strip()

# ======================
# –¢–ò–ü–´ –ú–´–®–õ–ï–ù–ò–Ø –ò –¢–ï–ì–ò
# ======================
TAGS = {"[SOC]", "[FCT]", "[CAU]", "[PRC]", "[OPN]", "[MET]", "[CRT]"}
TAG_PATTERN = re.compile(r'\[(SOC|FCT|CAU|PRC|OPN|MET|CRT)\]')

def classify_and_tag_response(text: str) -> str:
    if not text.strip():
        return "[SOC] –•–æ—Ä–æ—à–æ."
    text = clean_qwen_response(text)
    sentences = re.split(r'(?<=[.!?])\s+', text)
    tagged = []
    for sent in sentences:
        if sent.strip():
            tag = _detect_sentence_type(sent)
            tagged.append(f"[{tag}] {sent}")
    return " ".join(tagged)

def _detect_sentence_type(sentence: str) -> str:
    s = sentence.lower().strip()
    if re.search(r'\b(—á—Ç–æ —Ç–∞–∫–æ–µ|–ø–æ—á–µ–º—É|–∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç|–æ–±—ä—è—Å–Ω–∏|–∑–Ω–∞—á–∏—Ç –ª–∏|–ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ|—Ä–∞–∑–º—ã—à–ª—è|–¥—É–º–∞–µ—à—å|—á—Ç–æ –∑–Ω–∞—á–∏—Ç)\b', s):
        return "MET"
    if re.search(r'\b(—á—Ç–æ–±—ã|–Ω—É–∂–Ω–æ|—Å–ª–µ–¥—É–µ—Ç|—à–∞–≥|—Å–Ω–∞—á–∞–ª–∞|–ø–æ—Ç–æ–º|–∑–∞—Ç–µ–º|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|–∞–ª–≥–æ—Ä–∏—Ç–º|–∫–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å|–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å)\b', s):
        return "PRC"
    if re.search(r'\b(–ø–æ—Ç–æ–º—É —á—Ç–æ|—Ç–∞–∫ –∫–∞–∫|–∏–∑-–∑–∞|—Å–ª–µ–¥—Å—Ç–≤–∏–µ|–ø—Ä–∏—á–∏–Ω–∞|–ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∏–∑-–∑–∞|–≤–µ–¥—ë—Ç –∫|–æ–±—É—Å–ª–æ–≤–ª–µ–Ω–æ)\b', s):
        return "CAU"
    if re.search(r'.+ ‚Äî —ç—Ç–æ .+|.+ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è .+|.+ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ .+|—Å—Ç–æ–ª–∏—Ü–∞ .+ ‚Äî .+|—Ñ–æ—Ä–º—É–ª–∞ .+ ‚Äî .+', s):
        return "FCT"
    if re.search(r'\b(—è –¥—É–º–∞—é|–º–Ω–µ –∫–∞–∂–µ—Ç—Å—è|–ø–æ –º–æ–µ–º—É –º–Ω–µ–Ω–∏—é|—è —Å—á–∏—Ç–∞—é|–º–Ω–µ –Ω—Ä–∞–≤–∏—Ç—Å—è|—Å–∫—É—á–Ω—ã–π|–æ—Ç–ª–∏—á–Ω—ã–π|–ª—É—á—à–µ|—Ö—É–∂–µ)\b', s):
        return "OPN"
    if re.search(r'\b(–ø—Ä–µ–¥—Å—Ç–∞–≤—å|–≤–æ–æ–±—Ä–∞–∑–∏|–∫–∞–∫ –±—É–¥—Ç–æ|—Å–ª–æ–≤–Ω–æ|–ø–æ–¥–æ–±–Ω–æ|–∂–∏–∑–Ω—å ‚Äî|–º–∏—Ä –∫–∞–∫|–µ—Å–ª–∏ –±—ã|—Ñ–∞–Ω—Ç–∞–∑–∏—è)\b', s):
        return "CRT"
    social_keywords = ["–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π", "—Å–ø–∞—Å–∏–±–æ", "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞", "–∏–∑–≤–∏–Ω–∏", "—Ö–æ—Ä–æ—à–æ", "–ª–∞–¥–Ω–æ", "–æ–∫", "–ø–æ–∫–∞"]
    if any(kw in s for kw in social_keywords) or len(s.split()) <= 3:
        return "SOC"
    return "FCT"

def detect_input_type(user_input: str) -> str:
    s = user_input.lower().strip()
    if re.search(r'\b(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|–¥–æ–±—Ä—ã–π –¥–µ–Ω—å|–∫–∞–∫ –¥–µ–ª–∞|–ø–æ–∫–∞)\b', s):
        return "SOC"
    if re.search(r'\b(—á—Ç–æ —Ç–∞–∫–æ–µ|–∫—Ç–æ —Ç–∞–∫–æ–π|–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è|–∫–∞–∫–∞—è —Å—Ç–æ–ª–∏—Ü–∞|—Ñ–æ—Ä–º—É–ª–∞|–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\b', s):
        return "FCT"
    if re.search(r'\b(–ø–æ—á–µ–º—É|–∑–∞—á–µ–º|–æ—Ç—á–µ–≥–æ|–ø—Ä–∏—á–∏–Ω–∞)\b', s):
        return "CAU"
    if re.search(r'\b(–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å|–∫–∞–∫ –ø—Ä–∏–≥–æ—Ç–æ–≤–∏—Ç—å|–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è|—à–∞–≥|–∞–ª–≥–æ—Ä–∏—Ç–º)\b', s):
        return "PRC"
    if re.search(r'\b(–∫–∞–∫ —Ç—ã –¥—É–º–∞–µ—à—å|—Ç–≤–æ—ë –º–Ω–µ–Ω–∏–µ|–ª—É—á—à–µ –ª–∏|–Ω—Ä–∞–≤–∏—Ç—Å—è –ª–∏)\b', s):
        return "OPN"
    if re.search(r'\b(–ø—Ä–µ–¥—Å—Ç–∞–≤—å|–≤–æ–æ–±—Ä–∞–∑–∏|—Å–æ—á–∏–Ω–∏|–æ–ø–∏—à–∏ –∫–∞–∫|–º–µ—Ç–∞—Ñ–æ—Ä–∞)\b', s):
        return "CRT"
    if re.search(r'\b(–ø–æ—á–µ–º—É —Ç—ã|–∫–∞–∫ —Ç—ã –ø–æ–Ω—è–ª|—á—Ç–æ —Ç—ã –∏–º–µ–ª –≤ –≤–∏–¥—É|–æ–±—ä—è—Å–Ω–∏ —Å–≤–æ–π –æ—Ç–≤–µ—Ç)\b', s):
        return "MET"
    return "FCT"

INPUT_TYPE_TO_STAGES = {
    "SOC": ["social"],
    "FCT": ["fact", "meta"],
    "CAU": ["cause", "fact", "meta"],
    "PRC": ["procedure", "fact"],
    "OPN": ["opinion", "meta"],
    "CRT": ["creative", "metaphor", "meta"],
    "MET": ["meta", "fact"]
}

def get_allowed_stages(input_type: str) -> List[str]:
    return INPUT_TYPE_TO_STAGES.get(input_type, ["social", "fact", "cause", "procedure", "opinion", "meta", "creative"])

# ======================
# –î–û–õ–ì–û–í–†–ï–ú–ï–ù–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ –§–ê–ö–¢–û–í
# ======================
class FactMemory:
    def __init__(self):
        self.facts: Dict[str, Set[str]] = defaultdict(set)  # subject ‚Üí {predicate-object}
        self.embeddings: Dict[str, np.ndarray] = {}
        self.external_model = None
        if _HAS_ST_MODEL:
            try:
                self.external_model = SentenceTransformer("all-MiniLM-L6-v2")
            except:
                pass

    def add_fact(self, subject: str, predicate: str, obj: str):
        fact_str = f"{subject} {predicate} {obj}"
        self.facts[subject].add(fact_str)
        if self.external_model is not None:
            emb = self.external_model.encode([fact_str], normalize_embeddings=True)[0]
            self.embeddings[fact_str] = emb

    def query_related(self, query: str, top_k: int = 3) -> List[str]:
        if not self.embeddings:
            return []
        if self.external_model is None:
            return list(self.facts.get(query, []))[:top_k]
        q_emb = self.external_model.encode([query], normalize_embeddings=True)[0]
        scores = []
        for fact, emb in self.embeddings.items():
            sim = np.dot(q_emb, emb)
            scores.append((sim, fact))
        scores.sort(reverse=True)
        return [fact for _, fact in scores[:top_k]]

# ======================
# –ì–õ–û–ë–ê–õ–¨–ù–û–ï –°–û–°–¢–û–Ø–ù–ò–ï –ú–´–®–õ–ï–ù–ò–Ø
# ======================
class GlobalThoughtState:
    def __init__(self, batch_size: int, hidden_size: int, device: torch.device):
        self.batch_size = batch_size
        self.hidden_size = hidden_size
        self.device = device
        self.context_vector = torch.zeros(batch_size, hidden_size, device=device)
        self.active_stages: List[str] = []
        self.stage_history: List[str] = []
        self.confidence = 1.0

    def update(self, new_info: torch.Tensor, stage: str, confidence: float = 1.0):
        self.context_vector = 0.8 * self.context_vector + 0.2 * new_info
        if stage not in self.active_stages:
            self.active_stages.append(stage)
        self.stage_history.append(stage)
        self.confidence = confidence

    def reset(self):
        self.context_vector.zero_()
        self.active_stages.clear()
        self.stage_history.clear()
        self.confidence = 1.0

# ======================
# –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –ö–õ–ï–¢–ö–ê
# ======================
class BrainCell(nn.Module):
    def __init__(self, cell_id: int, input_size: int, hidden_size: int, cell_type: str = "generic"):
        super().__init__()
        self.cell_id = cell_id
        self.cell_type = cell_type
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.input_adapter = nn.Linear(input_size, hidden_size) if input_size != hidden_size else nn.Identity()
        self.perception = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.LayerNorm(hidden_size)
        )
        self.memory = nn.LSTMCell(hidden_size, hidden_size)
        self.association = nn.Sequential(
            nn.Linear(hidden_size, hidden_size),
            nn.Tanh()
        )
        self.gate_logit = nn.Parameter(torch.tensor(0.0))
        self.activation_level = 0.0
        self.stage_transition = {
            "social": ["social"],
            "fact": ["cause", "meta", "procedure"],
            "cause": ["fact", "meta"],
            "procedure": ["fact", "cause"],
            "opinion": ["meta", "fact"],
            "meta": ["fact", "opinion", "cause"],
            "creative": ["metaphor", "meta"],
            "metaphor": ["creative", "meta"],
            "generic": ["fact"]
        }

    def propose_next_stage(self, current_stage: str) -> str:
        candidates = self.stage_transition.get(current_stage, ["fact"])
        return random.choice(candidates)

    def forward(self, x: torch.Tensor, hx: Optional[torch.Tensor] = None, cx: Optional[torch.Tensor] = None,
                global_state: Optional[GlobalThoughtState] = None):
        batch_size = x.size(0)
        device = x.device
        x = self.input_adapter(x)
        if global_state is not None and global_state.context_vector is not None:
            x = x + 0.2 * global_state.context_vector
        perceived = self.perception(x)
        self.activation_level = float(torch.mean(torch.abs(perceived)).detach().cpu().item())
        if hx is None:
            hx = torch.zeros(batch_size, self.hidden_size, device=device)
        if cx is None:
            cx = torch.zeros(batch_size, self.hidden_size, device=device)
        hx, cx = self.memory(perceived, (hx, cx))
        associated = self.association(hx)
        gate = torch.sigmoid(self.gate_logit)
        return associated * gate, hx, cx, self.activation_level

# ======================
# –ü–õ–ê–ù–ò–†–û–í–©–ò–ö –ú–´–®–õ–ï–ù–ò–Ø
# ======================
class ThoughtPlanner:
    def __init__(self, allowed_stages: List[str]):
        self.allowed_stages = allowed_stages[:]
        self.planned_stages = allowed_stages[:]
        self.iteration = 0

    def plan_next_cycle(self, active_cells: Dict[str, float], current_stages: List[str]) -> List[str]:
        self.iteration += 1
        if self.iteration == 1:
            return self.allowed_stages
        votes = defaultdict(int)
        for cell_id, act in active_cells.items():
            if act < 0.15:
                continue
            cell_type = cell_id.split('_')[0]
            if cell_type in ["fact", "cause", "procedure", "opinion", "meta", "creative", "social"]:
                cell = BrainCell(0, 1, 1, cell_type)
                next_stage = cell.propose_next_stage(cell_type)
                if next_stage in ["fact", "cause", "procedure", "opinion", "meta", "creative", "social"]:
                    votes[next_stage] += act
        top_votes = sorted(votes.items(), key=lambda x: x[1], reverse=True)
        proposed = [stage for stage, _ in top_votes[:2] if stage not in self.planned_stages]
        self.planned_stages += proposed
        self.planned_stages = list(dict.fromkeys(self.planned_stages))
        return self.planned_stages

# ======================
# PRIORITIZED REPLAY –° –ü–û–î–î–ï–†–ñ–ö–û–ô –û–¢–†–ò–¶–ê–¢–ï–õ–¨–ù–´–• –ü–†–ò–ú–ï–†–û–í
# ======================
class PrioritizedReplay:
    def __init__(self, capacity: int = 5000, alpha: float = 0.6, eps: float = 1e-6):
        self.capacity = capacity
        self.alpha = alpha
        self.eps = eps
        self.buffer: List[Dict[str, Any]] = []
        self.priorities: List[float] = []
        self.position = 0

    def add(self, inp: List[int], target: List[int], meta: Optional[Dict] = None, priority: Optional[float] = None, is_negative: bool = False):
        data = {"input": inp, "target": target, "meta": meta or {}, "len": len(inp), "is_negative": is_negative}
        p = max(self.priorities) if self.priorities else 1.0 if priority is None else priority
        if len(self.buffer) < self.capacity:
            self.buffer.append(data)
            self.priorities.append(p)
        else:
            self.buffer[self.position] = data
            self.priorities[self.position] = p
            self.position = (self.position + 1) % self.capacity

    def _get_probabilities(self):
        scaled = np.array(self.priorities) ** self.alpha
        if scaled.sum() == 0:
            scaled = np.ones_like(scaled)
        probs = scaled / scaled.sum()
        return probs

    def sample(self, batch_size: int, beta: float = 0.4):
        n = len(self.buffer)
        batch_size = min(batch_size, n)
        if n == 0:
            return [], [], []
        probs = self._get_probabilities()
        idxs = np.random.choice(n, batch_size, p=probs, replace=False)
        samples = [self.buffer[i] for i in idxs]
        weights = (n * probs[idxs]) ** (-beta)
        weights = weights / weights.max()
        return samples, idxs.tolist(), weights.tolist()

    def update_priorities(self, idxs: List[int], priorities: List[float]):
        for i, p in zip(idxs, priorities):
            self.priorities[i] = max(p + self.eps, self.eps)

    def __len__(self):
        return len(self.buffer)

    def serialize(self):
        return {"buffer": self.buffer, "priorities": self.priorities, "position": self.position}

    def load(self, data: Dict[str, Any]):
        self.buffer = data.get("buffer", [])
        self.priorities = data.get("priorities", [1.0] * len(self.buffer))
        self.position = data.get("position", 0)

# ======================
# META-COGNITION –° –û–¶–ï–ù–ö–û–ô –ù–ï–û–ü–†–ï–î–ï–õ–Å–ù–ù–û–°–¢–ò
# ======================
class MetaCognition:
    def __init__(self, vocab: Dict[str, int], network: Optional['CognitiveNetwork'] = None,
                 external_model_name: str = "all-MiniLM-L6-v2"):
        self.vocab = vocab
        self.unknown_concepts: Set[str] = set()
        self.reflection_log: List[Dict[str, Any]] = []
        self.network = network
        self.external_model = None
        if _HAS_ST_MODEL:
            try:
                self.external_model = SentenceTransformer(external_model_name)
            except Exception:
                self.external_model = None
        self.fact_memory = FactMemory()

    def detect_unknown_words(self, text: str) -> Set[str]:
        words = set(clean_for_similarity(text).split())
        known = set(k for k in self.vocab.keys() if clean_for_similarity(k))
        return words - known

    def log_reflection(self, user_input: str, qwen_resp: str, brain_resp: str, question: Optional[str], reason: str):
        entry = {
            "timestamp": datetime.now().isoformat(),
            "user_input": user_input,
            "qwen_response": qwen_resp,
            "brain_response": brain_resp,
            "generated_question": question,
            "reason": reason
        }
        self.reflection_log.append(entry)

    def _embed_text_external(self, text: str) -> np.ndarray:
        if self.external_model is not None:
            try:
                return self.external_model.encode([text], normalize_embeddings=True)[0]
            except Exception:
                pass
        if self.network is not None:
            tokens = self.network.text_to_tokens(text, self.vocab, include_tags=True)
            if tokens:
                emb = self.network.embedding(torch.tensor(tokens, dtype=torch.long, device=self.network.device))
                emb = emb.detach().cpu().numpy()
                vec = emb.mean(axis=0)
                norm = np.linalg.norm(vec)
                return vec / (norm + 1e-8)
        toks = clean_for_similarity(text).split()
        vec = np.zeros(128, dtype=float)
        for i, w in enumerate(toks):
            vec[i % 128] += 1.0
        norm = np.linalg.norm(vec)
        return vec / (norm + 1e-8)

    def _estimate_similarity_semantic(self, resp1: str, resp2: str) -> float:
        v1 = self._embed_text_external(resp1)
        v2 = self._embed_text_external(resp2)
        if np.linalg.norm(v1) == 0 or np.linalg.norm(v2) == 0:
            return 0.0
        return float(np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2)))

    def should_reflect(self, user_input: str, qwen_resp: str, brain_resp: str, brain_confidence: float = 1.0) -> Tuple[bool, str]:
        expected_type = detect_input_type(user_input)
        actual_type = "FCT"
        marker_match = TAG_PATTERN.search(qwen_resp)
        if marker_match:
            actual_type = marker_match.group(1)
        type_mismatch = False
        reason = ""
        if expected_type == "FCT" and actual_type in ["SOC", "OPN"]:
            type_mismatch = True
            reason = f"–æ–∂–∏–¥–∞–ª—Å—è —Ñ–∞–∫—Ç [FCT], –Ω–æ Qwen –¥–∞–ª {actual_type}"
        elif expected_type == "PRC" and actual_type not in ["PRC", "FCT"]:
            type_mismatch = True
            reason = f"–æ–∂–∏–¥–∞–ª–∞—Å—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è [PRC], –Ω–æ Qwen –¥–∞–ª {actual_type}"
        elif expected_type == "CRT" and actual_type in ["SOC", "FCT"]:
            type_mismatch = True
            reason = f"–æ–∂–¥–∞–ª–æ—Å—å —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ [CRT], –Ω–æ Qwen –¥–∞–ª {actual_type}"
        brain_clean = TAG_PATTERN.sub('', brain_resp).replace('<UNK>', '').strip()
        qwen_clean = TAG_PATTERN.sub('', qwen_resp).strip()
        similarity = self._estimate_similarity_semantic(brain_clean or "–ø—É—Å—Ç–æ", qwen_clean or "–ø—É—Å—Ç–æ")
        if type_mismatch or similarity < 0.35 or brain_confidence < 0.6:
            return True, reason if type_mismatch else f"–Ω–∏–∑–∫–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ ({similarity:.2f}) –∏–ª–∏ –Ω–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ({brain_confidence:.2f})"
        return False, ""

# ======================
# –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ï–¢–¨ –° –£–õ–£–ß–®–ï–ù–ù–´–ú –û–ë–£–ß–ï–ù–ò–ï–ú
# ======================
class CognitiveNetwork(nn.Module):
    def __init__(self, vocab_size: int, embedding_dim: int = 256, hidden_size: int = 512, eos_token_id: int = 1,
                 device: Optional[torch.device] = None):
        super().__init__()
        self.device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))
        self.vocab_size = vocab_size
        self.embed_dim = embedding_dim
        self.hidden_size = hidden_size
        self.eos_token_id = eos_token_id
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)
        self.embed_proj = nn.Linear(embedding_dim, hidden_size)
        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=max(1, min(8, hidden_size // 64)),
                                               batch_first=True)
        self.norm = nn.LayerNorm(hidden_size)
        self.final_proj = nn.Linear(hidden_size, vocab_size)
        self.cells = nn.ModuleDict()
        self.cell_states: Dict[str, Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]] = {}
        self.cell_activations: Dict[str, float] = {}
        self.cell_counter = 0
        self.meta_cog: Optional[MetaCognition] = None
        self.replay = PrioritizedReplay(capacity=5000, alpha=0.6)
        self.to(self.device)
        self.global_thought_state: Optional[GlobalThoughtState] = None
        # –î–ª—è EWC-like —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        self.fisher_info: Optional[Dict[str, torch.Tensor]] = None
        self.optimal_params: Optional[Dict[str, torch.Tensor]] = None

    def _initialize_base_cells(self):
        base_cells = [
            ("social_greeting", "social"),
            ("social_thanks", "social"),
            ("fact_definition", "fact"),
            ("cause_explanation", "cause"),
            ("procedure_step", "procedure"),
            ("opinion_expression", "opinion"),
            ("meta_question", "meta"),
            ("creative_metaphor", "creative"),
            ("metaphor_imagery", "metaphor")
        ]
        for name, ctype in base_cells:
            self.add_cell(name, self.hidden_size, self.hidden_size, ctype)

    def add_cell(self, cell_type: str, input_size: int, hidden_size: int, cell_subtype: str = "association") -> str:
        safe_type = safe_cell_name(cell_type)
        cell_id = f"{safe_type}_{self.cell_counter}"
        self.cells[cell_id] = BrainCell(self.cell_counter, input_size, hidden_size, cell_subtype)
        self.cells[cell_id].to(self.device)
        self.cell_states[cell_id] = (None, None)
        self.cell_activations[cell_id] = 0.0
        self.cell_counter += 1
        return cell_id

    def reset_cell_states(self, batch_size: int, device: Optional[torch.device] = None):
        device = device or self.device
        for cell_id in self.cells:
            self.cell_states[cell_id] = (
                torch.zeros(batch_size, self.hidden_size, device=device),
                torch.zeros(batch_size, self.hidden_size, device=device)
            )

    def compute_weighted_loss(self, logits: torch.Tensor, targets: torch.Tensor, vocab: Dict[str, int],
                              ivocab: Dict[int, str], is_negative: bool = False) -> torch.Tensor:
        criterion = nn.CrossEntropyLoss(reduction='none', ignore_index=0)
        losses = criterion(logits.view(-1, self.vocab_size), targets.view(-1))
        losses = losses.view(targets.size(0), targets.size(1))
        weights = torch.ones_like(targets, dtype=torch.float32, device=self.device)
        tag_ids = {vocab.get(tag, -1) for tag in TAGS if tag in vocab}
        for b in range(targets.size(0)):
            for t in range(targets.size(1)):
                tid = targets[b, t].item()
                if tid in tag_ids:
                    weights[b, t] = 3.0
                elif ivocab.get(tid, "").startswith(("–ø–æ—á–µ–º—É", "–∫–∞–∫", "—á—Ç–æ", "–∑–∞—á–µ–º", "–æ–±—ä—è—Å–Ω–∏")):
                    weights[b, t] = 1.8
        mask = (targets != 0).float()
        weighted_loss = losses * weights * mask
        if is_negative:
            weighted_loss = -weighted_loss  # –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–∞—è —Ü–µ–ª—å
        loss = weighted_loss.sum() / (mask.sum() + 1e-8)

        # EWC —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
        if self.fisher_info is not None and self.optimal_params is not None:
            ewc_loss = 0.0
            for name, param in self.named_parameters():
                if name in self.fisher_info:
                    fi = self.fisher_info[name]
                    opt = self.optimal_params[name]
                    ewc_loss += (fi * (param - opt) ** 2).sum()
            loss += 1e-4 * ewc_loss

        return loss

    def _adaptive_thought_cycles(self, token_emb: torch.Tensor, allowed_stages: List[str], max_cycles: int = 5):
        batch_size = token_emb.size(0)
        x = token_emb
        self.global_thought_state = GlobalThoughtState(batch_size, self.hidden_size, self.device)
        planner = ThoughtPlanner(allowed_stages)
        for cycle in range(max_cycles):
            current_plan = planner.plan_next_cycle(self.cell_activations, self.global_thought_state.active_stages)
            stage_outputs = []
            stage_confs = []
            for stage in current_plan:
                stage_cells = [cid for cid in self.cells if stage in self.cells[cid].cell_type]
                if not stage_cells:
                    continue
                for cid in stage_cells:
                    cell = self.cells[cid]
                    hx, cx = self.cell_states.get(cid, (None, None))
                    if hx is None:
                        hx = torch.zeros(batch_size, self.hidden_size, device=self.device)
                        cx = torch.zeros(batch_size, self.hidden_size, device=self.device)
                    cell_output, new_hx, new_cx, act = cell(x, hx, cx, global_state=self.global_thought_state)
                    self.cell_states[cid] = (new_hx, new_cx)
                    self.cell_activations[cid] = act
                    stage_outputs.append(cell_output)
                    stage_confs.append(act)
            if stage_outputs:
                mean_output = torch.mean(torch.stack(stage_outputs), dim=0)
                # –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏: 1 - std(activations)
                conf = 1.0 - np.std(stage_confs) if len(stage_confs) > 1 else 1.0
                dominant_stage = current_plan[0] if current_plan else "fact"
                self.global_thought_state.update(mean_output, dominant_stage, conf)
                x = mean_output
        final_conf = self.global_thought_state.confidence if self.global_thought_state else 1.0
        self.global_thought_state = None
        return self.final_proj(x), final_conf

    def process_sequence(self, input_tokens: torch.Tensor, attention_mask: Optional[torch.Tensor] = None,
                         allowed_stages: Optional[List[str]] = None) -> Tuple[torch.Tensor, float]:
        if allowed_stages is None:
            allowed_stages = ["social", "fact", "cause", "procedure", "opinion", "meta", "creative"]
        batch_size, seq_len = input_tokens.shape
        self.reset_cell_states(batch_size, self.device)
        embedded = self.embedding(input_tokens)
        embedded = self.embed_proj(embedded)
        if attention_mask is None:
            attn_out, _ = self.attention(embedded, embedded, embedded)
        else:
            key_padding_mask = attention_mask == 0
            attn_out, _ = self.attention(embedded, embedded, embedded, key_padding_mask=key_padding_mask)
        combined = self.norm(embedded + attn_out)
        outputs = []
        confs = []
        for t in range(seq_len):
            token_emb = combined[:, t, :]
            logits, conf = self._adaptive_thought_cycles(token_emb, allowed_stages, max_cycles=5)
            outputs.append(logits)
            confs.append(conf)
        avg_conf = np.mean(confs) if confs else 1.0
        return torch.stack(outputs, dim=1), avg_conf

    def generate_sequence(self, input_tokens: torch.Tensor, allowed_stages: List[str], max_length: int = 30,
                          temperature: float = 0.8) -> Tuple[List[int], float]:
        batch_size = input_tokens.size(0)
        self.reset_cell_states(batch_size, self.device)
        with torch.no_grad():
            embedded = self.embedding(input_tokens)
            embedded = self.embed_proj(embedded)
            attn_out, _ = self.attention(embedded, embedded, embedded, is_causal=True)
            combined = self.norm(embedded + attn_out)
            for t in range(combined.size(1)):
                token_emb = combined[:, t, :]
                _ = self._adaptive_thought_cycles(token_emb, allowed_stages, max_cycles=4)
            generated = []
            current = input_tokens[:, -1:].clone()
            confs = []
            for _ in range(max_length):
                emb = self.embedding(current).squeeze(1)
                emb = self.embed_proj(emb)
                logits, conf = self._adaptive_thought_cycles(emb, allowed_stages, max_cycles=4)
                confs.append(conf)
                logits = logits / temperature
                probs = F.softmax(logits, dim=-1)
                next_id = torch.multinomial(probs, 1)
                next_id_val = next_id.item()
                if next_id_val == self.eos_token_id:
                    break
                generated.append(next_id_val)
                current = next_id
            avg_conf = np.mean(confs) if confs else 1.0
            return generated, avg_conf

    def expand_vocab(self, new_vocab_size: int):
        if new_vocab_size <= self.vocab_size:
            return
        old_emb = self.embedding.weight.data.cpu().clone()
        old_vocab = self.vocab_size
        new_embedding = nn.Embedding(new_vocab_size, self.embed_dim, padding_idx=0)
        nn.init.normal_(new_embedding.weight, mean=0.0, std=0.02)
        new_embedding.weight.data[:old_vocab, :self.embed_dim] = old_emb
        unk_idx = 2
        if unk_idx < old_vocab:
            unk_vec = old_emb[unk_idx]
            for i in range(old_vocab, new_vocab_size):
                new_embedding.weight.data[i] = unk_vec.clone()
        self.embedding = new_embedding.to(self.device)
        new_final = nn.Linear(self.hidden_size, new_vocab_size)
        nn.init.xavier_uniform_(new_final.weight)
        new_final.bias.data.zero_()
        self.final_proj = new_final.to(self.device)
        self.vocab_size = new_vocab_size

    def _check_cell_creation(self, user_input: str, qwen_resp: str, brain_resp: str):
        if self.meta_cog is None:
            return False
        unknown = self.meta_cog.detect_unknown_words(qwen_resp)
        if unknown:
            for word in list(unknown)[:2]:
                if word in {"<PAD>", "<EOS>", "<UNK>", ".", ",", "?", "!", "[SOC]", "[FCT]", "[CAU]", "[PRC]", "[OPN]", "[MET]", "[CRT]"} or word.startswith('['):
                    continue
                clean_word = safe_cell_name(word)
                self.meta_cog.unknown_concepts.add(word)
                self.add_cell(f"concept_{clean_word}", self.hidden_size, self.hidden_size, "association")
                print(f"üß¨ –°–æ–∑–¥–∞–Ω–∞ –∫–ª–µ—Ç–∫–∞ –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–Ω—è—Ç–∏—è: {word} ‚Üí concept_{clean_word}")
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ñ–∞–∫—Ç
                self.meta_cog.fact_memory.add_fact("concept", word, "unknown")
        return False

    def reflect_and_learn(self, user_input: str, qwen_response: str, vocab: Dict[str, int], ivocab: Dict[int, str]) -> Optional[str]:
        input_tokens = self.text_to_tokens(user_input, vocab, include_tags=False)
        if not input_tokens:
            return None
        allowed_stages = get_allowed_stages(detect_input_type(user_input))
        with torch.no_grad():
            brain_tokens, brain_conf = self.generate_sequence(
                torch.tensor([input_tokens], dtype=torch.long, device=self.device),
                allowed_stages=allowed_stages,
                max_length=30
            )
            brain_response = " ".join(ivocab.get(tid, "<UNK>") for tid in brain_tokens)
        tokens = brain_response.split()
        if not tokens:
            return None
        unk_ratio = brain_response.count("<UNK>") / len(tokens)
        if unk_ratio > 0.7:
            return "–Ω–µ –ø–æ–Ω—è–ª: —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–ª–æ–≤"
        assert self.meta_cog is not None
        should_reflect, reason = self.meta_cog.should_reflect(user_input, qwen_response, brain_response, brain_conf)
        if should_reflect:
            question = self._formulate_deep_question(user_input, qwen_response, brain_response, reason, vocab)
            if "–ú–æ–∑–≥ –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å" in user_input or "–ö–∞–∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞" in question:
                return None
            self.meta_cog.log_reflection(user_input, qwen_response, brain_response, question, reason)
            return question
        return None

    def _formulate_deep_question(self, user_input: str, qwen_resp: str, brain_resp: str, reason: str, vocab: Dict[str, int]) -> str:
        active_cells = [cid for cid, act in self.cell_activations.items() if act > 0.2]
        if active_cells:
            dominant_type = Counter([self.cells[cid].cell_type for cid in active_cells]).most_common(1)[0][0]
            templates = {
                "fact": f"–ß—Ç–æ –∏–º–µ–Ω–Ω–æ –æ–∑–Ω–∞—á–∞–µ—Ç '{user_input}'? –î–∞–π —Ç–æ—á–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ.",
                "cause": f"–ü–æ—á–µ–º—É –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Ç–æ, –æ —á—ë–º —Å–ø—Ä–∞—à–∏–≤–∞—é—Ç –≤ '{user_input}'?",
                "procedure": f"–ö–∞–∫ –ø–æ—à–∞–≥–æ–≤–æ –¥–æ—Å—Ç–∏—á—å —Ü–µ–ª–∏ –∏–∑ '{user_input}'?",
                "opinion": f"–ö–∞–∫–∏–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –∑–∞ –∏ –ø—Ä–æ—Ç–∏–≤ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤ '{user_input}'?",
                "meta": f"–ö–∞–∫ –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥–æ–π—Ç–∏ –∫ –ø–æ–Ω–∏–º–∞–Ω–∏—é '{user_input}'?",
                "creative": f"–û–ø–∏—à–∏ '{user_input}' —á–µ—Ä–µ–∑ –º–µ—Ç–∞—Ñ–æ—Ä—É –∏–ª–∏ –æ–±—Ä–∞–∑.",
                "social": f"–ö–∞–∫ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ '{user_input}' –≤ —Å–æ—Ü–∏–∞–ª—å–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ?",
            }
            return templates.get(dominant_type, f"–û–±—ä—è—Å–Ω–∏ –≥–ª—É–±–∂–µ: {user_input}")
        return f"–æ–±—ä—è—Å–Ω–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ: {user_input}"

    def text_to_tokens(self, text: str, vocab: Dict[str, int], include_tags: bool = True) -> List[int]:
        if not include_tags:
            text = TAG_PATTERN.sub('', text)
        text_proc = text.lower()
        text_proc = text_proc.replace('.', ' . ').replace(',', ' , ').replace('?', ' ? ').replace('!', ' ! ')
        words = text_proc.split()
        tokens = []
        for word in words:
            if word not in vocab:
                vocab[word] = len(vocab)
            tokens.append(vocab[word])
        if self.vocab_size < len(vocab):
            self.expand_vocab(len(vocab) + 128)
        return tokens

    def find_activated_cells_by_type(self, threshold: float = 0.15) -> Dict[str, List[str]]:
        grouped = {k: [] for k in ["social", "fact", "cause", "procedure", "opinion", "meta", "creative"]}
        for cid, act in self.cell_activations.items():
            if act > threshold:
                cell_type = self.cells[cid].cell_type
                for key in grouped:
                    if key in cell_type:
                        grouped[key].append(cid)
                        break
        return {k: v for k, v in grouped.items() if v}

    def print_thought_flow(self):
        if not self.cell_activations:
            return
        print("\nüß† –ü–æ—Ç–æ–∫ –º—ã—à–ª–µ–Ω–∏—è:")
        for stage in ["social", "fact", "cause", "procedure", "opinion", "meta", "creative"]:
            cells = [cid for cid in self.cells if stage in self.cells[cid].cell_type]
            if cells:
                avg_act = np.mean([self.cell_activations.get(cid, 0) for cid in cells])
                if avg_act > 0.1:
                    print(f"  ‚Üí {stage.upper()}: {avg_act:.3f}")

    def save_knowledge(self, filepath: str, vocab: Dict[str, int]):
        cell_configs = []
        for cell_id, cell in self.cells.items():
            config = {
                'cell_id': cell_id,
                'cell_counter': cell.cell_id,
                'input_size': cell.input_size,
                'hidden_size': cell.hidden_size,
                'cell_type': cell.cell_type,
                'gate_logit': float(cell.gate_logit.detach().cpu().item())
            }
            cell_configs.append(config)
        knowledge = {
            'model_state': self.state_dict(),
            'vocab': vocab,
            'cell_configs': cell_configs,
            'cell_counter': self.cell_counter,
            'meta_cog_log': self.meta_cog.reflection_log if self.meta_cog else [],
            'unknown_concepts': list(self.meta_cog.unknown_concepts) if self.meta_cog else [],
            'replay': self.replay.serialize(),
            'fact_memory': dict(self.meta_cog.fact_memory.facts) if self.meta_cog else {},
        }
        torch.save(knowledge, filepath)

    def load_knowledge(self, filepath: str):
        if not os.path.exists(filepath):
            return None
        try:
            checkpoint = torch.load(filepath, map_location=self.device)
            saved_vocab = checkpoint.get('vocab', {})
            cell_configs = checkpoint.get('cell_configs', [])
            saved_state = checkpoint.get('model_state', {})
            self.cells = nn.ModuleDict()
            self.cell_states = {}
            self.cell_activations = {}
            for config in cell_configs:
                cid = config['cell_id']
                input_size = int(config['input_size'])
                hidden_size = int(config['hidden_size'])
                cell_type = config.get('cell_type', 'generic')
                self.cells[cid] = BrainCell(config.get('cell_counter', 0), input_size, hidden_size, cell_type)
                self.cells[cid].to(self.device)
                gate_val = float(config.get('gate_logit', 0.0))
                with torch.no_grad():
                    self.cells[cid].gate_logit.copy_(torch.tensor(gate_val, device=self.device))
                self.cell_states[cid] = (None, None)
                self.cell_activations[cid] = 0.0
            self.cell_counter = checkpoint.get('cell_counter', len(self.cells))
            self.load_state_dict(saved_state, strict=False)
            self.meta_cog = MetaCognition(saved_vocab, network=self)
            self.meta_cog.reflection_log = checkpoint.get('meta_cog_log', [])
            self.meta_cog.unknown_concepts = set(checkpoint.get('unknown_concepts', []))
            facts = checkpoint.get('fact_memory', {})
            for subj, fact_set in facts.items():
                self.meta_cog.fact_memory.facts[subj] = set(fact_set)
            replay_data = checkpoint.get('replay', {})
            try:
                self.replay.load(replay_data)
            except Exception:
                pass
            return saved_vocab
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            traceback.print_exc()
            return None

# ======================
# –£–ß–ò–¢–ï–õ–¨ –° –ü–û–î–î–ï–†–ñ–ö–û–ô –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–ò
# ======================
class BrainTeacher:
    def __init__(self, api_url: str = "http://localhost:1234/v1/chat/completions", device: Optional[torch.device] = None):
        self.api_url = api_url
        self.conversation_history: List[Dict[str, Any]] = []
        self.device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))

    def query_qwen(self, prompt: str, timeout: int = 20) -> str:
        try:
            response = requests.post(
                self.api_url,
                headers={"Content-Type": "application/json"},
                json={
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.7,
                    "max_tokens": 120,
                    "stream": False
                },
                timeout=timeout
            )
            if response.status_code == 200:
                raw = response.json()['choices'][0]['message']['content'].strip()
                return clean_qwen_response(raw)
            else:
                return "–•–æ—Ä–æ—à–æ."
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LM Studio: {e}")
            return "–•–æ—Ä–æ—à–æ."

    @staticmethod
    def _pad_batch(sequences: List[List[int]], pad_id: int = 0):
        lengths = [len(s) for s in sequences]
        max_len = max(lengths) if lengths else 0
        padded = [s + [pad_id] * (max_len - l) for s, l in zip(sequences, lengths)]
        mask = [[1] * l + [0] * (max_len - l) for l in lengths]
        return torch.tensor(padded, dtype=torch.long), torch.tensor(mask, dtype=torch.long), lengths

    def teach_online_step(self, brain: CognitiveNetwork, input_seq: List[int], target_seq: List[int], vocab: Dict[str, int], ivocab: Dict[int, str], allowed_stages: List[str], is_negative: bool = False):
        input_tensor = torch.tensor([input_seq], dtype=torch.long, device=brain.device)
        target_tensor = torch.tensor([target_seq], dtype=torch.long, device=brain.device)
        attn_mask = torch.ones_like(input_tensor, dtype=torch.long, device=brain.device)
        brain.train()
        optimizer = torch.optim.AdamW(brain.parameters(), lr=2e-4, weight_decay=1e-6)
        optimizer.zero_grad()
        logits, _ = brain.process_sequence(input_tensor, attention_mask=attn_mask, allowed_stages=allowed_stages)
        loss = brain.compute_weighted_loss(logits, target_tensor, vocab, ivocab, is_negative=is_negative)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(brain.parameters(), 0.8)
        optimizer.step()
        brain.eval()
        print(f"üî• –û–Ω–ª–∞–π–Ω-–ø–æ—Ç–µ—Ä—è: {loss.item():.4f}")
        return loss.item()

    def teach_brain(self, brain: CognitiveNetwork, user_input: str, vocab: Dict[str, int], ivocab: Dict[int, str],
                    epochs: int = 3, batch_size: int = 12):
        raw_qwen = self.query_qwen(user_input)
        tagged_qwen = classify_and_tag_response(raw_qwen)
        print(f"üë§: {user_input}")
        print(f"ü§ñ: {tagged_qwen}")
        input_type = detect_input_type(user_input)
        allowed_stages = get_allowed_stages(input_type)
        input_tokens = brain.text_to_tokens(user_input, vocab, include_tags=False)
        response_tokens = brain.text_to_tokens(tagged_qwen, vocab, include_tags=True)
        if not response_tokens:
            response_tokens = [vocab.get("—Ö–æ—Ä–æ—à–æ", 2), vocab.get(".", 38)]
        eos_id = vocab.get('<EOS>', 1)
        full_seq = input_tokens + response_tokens + [eos_id]
        input_seq = full_seq[:-1]
        target_seq = full_seq[1:]
        priority = 2.0 if "[MET]" in tagged_qwen or "—Ä–µ—Ñ–ª–µ–∫—Å–∏—è" in user_input.lower() else 1.0
        brain.replay.add(input_seq, target_seq, meta={"qwen": tagged_qwen}, priority=priority)

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ (–∫–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ)
        neg_target = response_tokens[::-1]  # –ø—Ä–æ—Å—Ç–æ –∏–Ω–≤–µ—Ä—Å–∏—è –∫–∞–∫ –ø—Ä–∏–º–µ—Ä
        brain.replay.add(input_seq, neg_target, meta={"qwen": tagged_qwen}, priority=0.5, is_negative=True)

        self.teach_online_step(brain, input_seq, target_seq, vocab, ivocab, allowed_stages, is_negative=False)
        samples, idxs, is_weights = brain.replay.sample(batch_size - 1, beta=0.4) if len(brain.replay) > 1 else ([], [], [])
        batch_inputs = [input_seq] + [s['input'] for s in samples]
        batch_targets = [target_seq] + [s['target'] for s in samples]
        is_negatives = [False] + [s.get('is_negative', False) for s in samples]
        sorted_triples = sorted(zip(batch_inputs, batch_targets, is_negatives, [1.0] + is_weights, [None] + idxs),
                                key=lambda x: len(x[0]), reverse=True)
        batch_inputs_sorted = [p[0] for p in sorted_triples]
        batch_targets_sorted = [p[1] for p in sorted_triples]
        is_negatives_sorted = [p[2] for p in sorted_triples]
        input_tensor, attn_mask, _ = self._pad_batch(batch_inputs_sorted, pad_id=0)
        target_tensor, _, _ = self._pad_batch(batch_targets_sorted, pad_id=0)
        input_tensor = input_tensor.to(brain.device)
        target_tensor = target_tensor.to(brain.device)
        attn_mask = attn_mask.to(brain.device)
        optimizer = torch.optim.AdamW(brain.parameters(), lr=3e-4, weight_decay=1e-6)
        brain.train()
        total_loss = 0.0
        for ep in range(epochs):
            optimizer.zero_grad()
            logits, _ = brain.process_sequence(input_tensor, attention_mask=attn_mask, allowed_stages=allowed_stages)
            loss = 0.0
            for i in range(len(batch_inputs_sorted)):
                single_logits = logits[i:i+1, :len(batch_targets_sorted[i]), :]
                single_target = target_tensor[i:i+1, :len(batch_targets_sorted[i])]
                loss += brain.compute_weighted_loss(single_logits, single_target, vocab, ivocab, is_negative=is_negatives_sorted[i])
            loss = loss / len(batch_inputs_sorted)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(brain.parameters(), 0.8)
            optimizer.step()
            total_loss += loss.item()
        avg_loss = total_loss / epochs
        print(f"üìö –ë–∞—Ç—á-–ø–æ—Ç–µ—Ä—è: {avg_loss:.4f}")
        brain.eval()
        with torch.no_grad():
            brain_tokens, brain_conf = brain.generate_sequence(
                torch.tensor([input_seq], dtype=torch.long, device=brain.device),
                allowed_stages=allowed_stages,
                max_length=30
            )
            brain_response_raw = " ".join(ivocab.get(tid, "<UNK>") for tid in brain_tokens)
        brain_response_clean = TAG_PATTERN.sub('', brain_response_raw).strip()
        self.conversation_history.append({
            'input': user_input,
            'qwen_tagged': tagged_qwen,
            'brain_raw': brain_response_raw,
            'brain_clean': brain_response_clean,
            'loss': avg_loss,
            'confidence': brain_conf,
            'timestamp': datetime.now().isoformat()
        })
        print(f"üß† –°—ã—Ä–æ–π: {brain_response_raw}")
        print(f"üí¨ –ß–∏—Å—Ç—ã–π: {brain_response_clean} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {brain_conf:.2f})")
        brain.print_thought_flow()
        return tagged_qwen, brain_response_clean

# ======================
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø
# ======================
def create_initial_vocabulary() -> Dict[str, int]:
    base = {
        '<PAD>': 0, '<EOS>': 1, '<UNK>': 2,
        '[SOC]': 3, '[FCT]': 4, '[CAU]': 5, '[PRC]': 6,
        '[OPN]': 7, '[MET]': 8, '[CRT]': 9,
        '–ø—Ä–∏–≤–µ—Ç': 10, '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π': 11, '–¥–æ–±—Ä—ã–π': 12, '–¥–µ–Ω—å': 13,
        '–∫–∞–∫': 14, '—Ç—ã': 15, '–¥–µ–ª–∞': 16, '—á—Ç–æ': 17, '—Ç–∞–∫–æ–µ': 18,
        '—ç—Ç–æ': 19, '–ø–æ—Ç–æ–º—É': 20, '—á—Ç–æ–±—ã': 21,
        '—è': 22, '–¥—É–º–∞—é': 23, '–º–Ω–µ': 24, '–∫–∞–∂–µ—Ç—Å—è': 25,
        '–ø—Ä–µ–¥—Å—Ç–∞–≤—å': 26, '–≤–æ–æ–±—Ä–∞–∑–∏': 27, '–∂–∏–∑–Ω—å': 28,
        '—Å–ø–∞—Å–∏–±–æ': 29, '–ø–æ–∂–∞–ª—É–π—Å—Ç–∞': 30, '–∏–∑–≤–∏–Ω–∏': 31,
        '—Ö–æ—Ä–æ—à–æ': 32, '–ª–∞–¥–Ω–æ': 33, '–æ–∫': 34,
        '–Ω–µ–π—Ä–æ–Ω': 35, '–≥—Ä–∞–≤–∏—Ç–∞—Ü–∏—è': 36, '–≤–æ–¥–∞': 37,
        '.': 38, ',': 39, '?': 40, '!': 41
    }
    for tag in TAGS:
        if tag not in base:
            base[tag] = len(base)
    return base

# ======================
# MAIN
# ======================
def main():
    print("üß† –ó–ê–ü–£–°–ö AGI6.5 ‚Äî –°–ê–ú–û–û–ë–£–ß–ê–Æ–©–ê–Ø–°–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –° –ü–û–õ–ù–´–ú –¶–ò–ö–õ–û–ú")
    print("   ‚Ä¢ –û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
    print("   ‚Ä¢ –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏")
    print("   ‚Ä¢ –î–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å —Ñ–∞–∫—Ç–æ–≤")
    print("   ‚Ä¢ –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞–±—ã–≤–∞–Ω–∏—è")
    print("   ‚Ä¢ –ö–æ–Ω—Ç—Ä–∞—Å—Ç–∏–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ")
    vocab = create_initial_vocabulary()
    vocab_size = len(vocab) + 4096
    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
    brain = CognitiveNetwork(vocab_size=vocab_size, embedding_dim=192, hidden_size=384, eos_token_id=vocab['<EOS>'],
                             device=device)
    teacher = BrainTeacher(device=device)
    loaded_vocab = brain.load_knowledge("brain_knowledge_thought.pth")
    if loaded_vocab is not None:
        vocab = loaded_vocab
        print("‚úÖ –ó–Ω–∞–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
    else:
        brain._initialize_base_cells()
        brain.cell_counter = len(brain.cells)
        brain.meta_cog = MetaCognition(vocab, network=brain)
        print("üìù –°–æ–∑–¥–∞–Ω–∞ –Ω–æ–≤–∞—è —Å–µ—Ç—å")
    ivocab = {v: k for k, v in vocab.items()}
    print(f"üî¢ –ö–ª–µ—Ç–æ–∫: {len(brain.cells)} | üìö –°–ª–æ–≤–∞—Ä—å: {len(vocab)} —Å–ª–æ–≤")
    print("üí¨ –ì–æ—Ç–æ–≤ –∫ –¥–∏–∞–ª–æ–≥—É! (–≤–≤–µ–¥–∏—Ç–µ '–≤—ã—Ö–æ–¥' –∏–ª–∏ –æ—Ü–µ–Ω–∏—Ç–µ –æ—Ç–≤–µ—Ç: '+', '-', '–≤–µ—Ä–Ω–æ', '–Ω–µ–≤–µ—Ä–Ω–æ')")
    conversation_count = 0
    reflection_buffer: List[str] = []
    MAX_REFLECTION_CHAIN = 2
    reflection_chain = 0
    try:
        while True:
            if reflection_buffer:
                user_input = reflection_buffer.pop(0)
                print(f"\nüí≠ –ú–æ–∑–≥ –∑–∞–¥–∞—ë—Ç –≤–æ–ø—Ä–æ—Å: {user_input}")
            else:
                user_input = input("\nüë§ –í—ã: ").strip()
                if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
                    break
                if not user_input:
                    continue
                reflection_chain = 0

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ü–µ–Ω–∫–∏
            if user_input in ['+', '–≤–µ—Ä–Ω–æ']:
                if teacher.conversation_history:
                    last = teacher.conversation_history[-1]
                    print("‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–æ! –û–±–Ω–æ–≤–ª—è—é –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç.")
                    brain.replay.update_priorities([len(brain.replay)-1], [3.0])
                continue
            elif user_input in ['-', '–Ω–µ–≤–µ—Ä–Ω–æ']:
                if teacher.conversation_history:
                    last = teacher.conversation_history[-1]
                    print("‚ùå –ò—Å–ø—Ä–∞–≤–ª—è—é! –î–æ–±–∞–≤–ª—è—é –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –ø—Ä–∏–º–µ—Ä.")
                    brain.replay.update_priorities([len(brain.replay)-1], [0.1])
                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    correction = f"–ò—Å–ø—Ä–∞–≤—å –æ—à–∏–±–∫—É –≤ –æ—Ç–≤–µ—Ç–µ –Ω–∞: {last['input']}. –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç: "
                    user_input = correction
                else:
                    continue

            qwen_resp, brain_resp = teacher.teach_brain(brain, user_input, vocab, ivocab)
            ivocab = {v: k for k, v in vocab.items()}
            new_question = brain.reflect_and_learn(user_input, qwen_resp, vocab, ivocab)
            if new_question:
                recent_inputs = {entry['input'] for entry in teacher.conversation_history[-5:]}
                if new_question not in recent_inputs and new_question not in reflection_buffer:
                    if reflection_chain < MAX_REFLECTION_CHAIN:
                        reflection_buffer.append(new_question)
                        reflection_chain += 1
            brain._check_cell_creation(user_input, qwen_resp, brain_resp)
            conversation_count += 1
            if conversation_count % 2 == 0:
                brain.save_knowledge("brain_knowledge_thought.pth", vocab)
                print("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ!")
    except KeyboardInterrupt:
        print("\nüõë –ü—Ä–µ—Ä–≤–∞–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        traceback.print_exc()
    finally:
        brain.save_knowledge("brain_knowledge_thought.pth", vocab)
        print(f"\nüß† –ò—Ç–æ–≥: –∫–ª–µ—Ç–æ–∫ = {len(brain.cells)}, —Å–ª–æ–≤–∞—Ä—å = {len(vocab)} —Å–ª–æ–≤")

if __name__ == "__main__":
    main()
# coding: utf-8
"""
AGI_CognitiveReasoning_v10_FIXED.py
–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Å –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
"""

import os
import re
import json
import pickle
import random
import traceback
import math
from collections import Counter, defaultdict, deque
from datetime import datetime
from typing import Dict, List, Optional, Set, Tuple, Any
from pathlib import Path

import numpy as np
import requests
import torch
import torch.nn as nn
import torch.nn.functional as F

try:
    from sentence_transformers import SentenceTransformer

    _HAS_ST_MODEL = True
except:
    _HAS_ST_MODEL = False


# ====================== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ======================
class Config:
    SAVE_DIR = Path("./cognitive_model_data_v10")
    MODEL_PATH = SAVE_DIR / "model.pt"
    VOCAB_PATH = SAVE_DIR / "vocab.pkl"
    LEARNING_PATH = SAVE_DIR / "learning.json"

    VOCAB_SIZE = 15000  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    EMB_DIM = 256  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    HIDDEN_SIZE = 512  # –£–º–µ–Ω—å—à–µ–Ω–æ
    NUM_LAYERS = 3  # –£–º–µ–Ω—å—à–µ–Ω–æ
    NUM_HEADS = 8
    DROPOUT = 0.1
    MAX_SEQ_LEN = 64  # –£–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    LEARNING_RATE = 1e-3
    MAX_ATTEMPTS = 15  # –£–º–µ–Ω—å—à–µ–Ω–æ
    CONFIDENCE_THRESHOLD = 0.65
    UNCERTAINTY_THRESHOLD = 0.45
    QWEN_API = "http://localhost:1234/v1/chat/completions"


Config.SAVE_DIR.mkdir(exist_ok=True)


# ====================== –£–¢–ò–õ–ò–¢–´ ======================
def clean_text(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
    if not isinstance(text, str):
        return "–•–æ—Ä–æ—à–æ."

    text = re.sub(r'\*{1,2}([^*]+)\*{1,2}', r'\1', text)
    text = re.sub(r'#{1,3}\s*', '', text)
    text = re.sub(r'>\s*', '', text)
    text = re.sub(r'\r\n|\n+', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()

    words = text.split()
    if len(words) > 100:
        text = ' '.join(words[:100])

    if text and not text.endswith(('.', '!', '?', 'üòä')):
        text += '.'

    return text or "–•–æ—Ä–æ—à–æ."


def clean_for_tokenize(text: str) -> str:
    """–û—á–∏—â–∞–µ—Ç –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏"""
    text = re.sub(r'[^\w\s]', ' ', text, flags=re.UNICODE)
    return re.sub(r'\s+', ' ', text.lower()).strip()


def detect_input_type(user_input: str) -> str:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –≤–æ–ø—Ä–æ—Å–∞"""
    s = user_input.lower()
    if any(w in s for w in ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π', '–∫–∞–∫ –¥–µ–ª–∞', '—Å–ø–∞—Å–∏–±–æ']):
        return "GREETING"
    elif any(w in s for w in ['—á—Ç–æ', '–∫—Ç–æ', '–≥–¥–µ', '–∫–∞–∫–æ–π', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ', '—Ä–∞—Å—Å–∫–∞–∂–∏']):
        return "DEFINITION"
    elif any(w in s for w in ['–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–æ—Ç—á–µ–≥–æ', '–ø—Ä–∏—á–∏–Ω–∞']):
        return "REASON"
    elif any(w in s for w in ['–∫–∞–∫ —Å–¥–µ–ª–∞—Ç—å', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è', '—à–∞–≥', '–∞–ª–≥–æ—Ä–∏—Ç–º']):
        return "PROCESS"
    else:
        return "GENERAL"


# ====================== –£–ú–ù–´–ô –î–ò–ê–õ–û–ì –° –£–ß–ò–¢–ï–õ–ï–ú ======================
class TeacherDialog:
    """–°–∏—Å—Ç–µ–º–∞ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞ —Å —É—á–∏—Ç–µ–ª–µ–º"""

    def __init__(self, api_url: str):
        self.api_url = api_url
        self.dialog_history = deque(maxlen=10)

    def ask_smart_question(self, user_input: str, input_type: str) -> str:
        """–£–º–Ω—ã–π –≤–æ–ø—Ä–æ—Å –∫ —É—á–∏—Ç–µ–ª—é"""

        if input_type == "GREETING":
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª—Å—è: '{user_input}'. –î–∞–π —Ç—ë–ø–ª—ã–π, –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞)."
        elif input_type == "DEFINITION":
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: '{user_input}'\n–≠—Ç–æ –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ. –î–∞–π —á—ë—Ç–∫–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è max)."
        elif input_type == "REASON":
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: '{user_input}'\n–û–±—ä—è—Å–Ω–∏ –ø—Ä–∏—á–∏–Ω—É –∫—Ä–∞—Ç–∫–æ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è max)."
        elif input_type == "PROCESS":
            prompt = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: '{user_input}'\n–î–∞–π –ø–æ—à–∞–≥–æ–≤—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é (3-4 —à–∞–≥–∞ max)."
        else:
            prompt = f"–û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: {user_input}\n–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."

        try:
            resp = requests.post(self.api_url, json={
                "messages": [{"role": "user", "content": prompt}],
                "max_tokens": 150,
                "temperature": 0.7
            }, timeout=20)

            if resp.status_code == 200:
                answer = resp.json()['choices'][0]['message']['content']
                return clean_text(answer)
        except Exception as e:
            print(f"‚ö†Ô∏è API –æ—à–∏–±–∫–∞: {e}")

        return "–Ø –Ω–µ –∑–Ω–∞—é –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å."


# ====================== –ü–†–û–î–í–ò–ù–£–¢–´–ô –ü–†–û–¶–ï–°–° –ú–´–®–õ–ï–ù–ò–Ø ======================
class ThinkingProcess:
    """–°–∏—Å—Ç–µ–º–∞ –º—ã—à–ª–µ–Ω–∏—è —Å —Ä–µ—Ñ–ª–µ–∫—Å–∏–µ–π"""

    def __init__(self):
        self.observations = []
        self.confidence = 0.5

    def observe(self, observation: str, confidence: float = 0.5):
        self.observations.append({'text': observation, 'confidence': confidence})
        self._update_confidence()

    def _update_confidence(self):
        if self.observations:
            self.confidence = np.mean([o['confidence'] for o in self.observations])

    def __str__(self) -> str:
        result = "üß† –î–£–ú–ê–Æ:\n"
        if self.observations:
            for obs in self.observations[-2:]:
                result += f"  ‚Ä¢ {obs['text'][:50]}... ({obs['confidence']:.0%})\n"
        result += f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {self.confidence:.0%}\n"
        return result


# ====================== –£–õ–£–ß–®–ï–ù–ù–´–ô –°–õ–û–í–ê–†–¨ –° –ó–ê–©–ò–¢–û–ô –û–¢ –û–®–ò–ë–û–ö ======================
class ImprovedVocab:
    """–°–ª–æ–≤–∞—Ä—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""

    def __init__(self):
        self.word2idx = {'<pad>': 0, '<start>': 1, '<end>': 2, '<unk>': 3}
        self.idx2word = {0: '<pad>', 1: '<start>', 2: '<end>', 3: '<unk>'}
        self.word_freq = Counter()
        self.next_id = 4
        self.max_vocab_size = Config.VOCAB_SIZE
        self.load()

    def add_word(self, word: str) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–æ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≥—Ä–∞–Ω–∏—Ü"""
        word_clean = word.lower().strip()

        if not word_clean or len(word_clean) < 1:
            return self.word2idx['<unk>']

        if word_clean in self.word2idx:
            self.word_freq[word_clean] += 1
            return self.word2idx[word_clean]

        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã
        if self.next_id >= self.max_vocab_size:
            return self.word2idx['<unk>']

        self.word2idx[word_clean] = self.next_id
        self.idx2word[self.next_id] = word_clean
        self.word_freq[word_clean] = 1
        self.next_id += 1

        return self.word2idx[word_clean]

    def add_words_from_text(self, text: str):
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–ª–æ–≤–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        words = clean_for_tokenize(text).split()
        for word in words:
            if len(word) > 1:
                self.add_word(word)

    def encode(self, text: str) -> List[int]:
        """–ö–æ–¥–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ ID —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≥—Ä–∞–Ω–∏—Ü"""
        words = clean_for_tokenize(text).split()
        ids = [1]  # start token

        for word in words[:Config.MAX_SEQ_LEN - 2]:
            word_id = self.word2idx.get(word, 3)  # 3 = <unk>

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –∏–Ω–¥–µ–∫—Å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–ª–æ–≤–∞—Ä—è
            if word_id < self.max_vocab_size:
                ids.append(word_id)
            else:
                ids.append(3)  # fallback to <unk>

        ids.append(2)  # end token

        # –ü–∞–¥–¥–∏–Ω–≥
        while len(ids) < Config.MAX_SEQ_LEN:
            ids.append(0)  # pad token

        return ids[:Config.MAX_SEQ_LEN]

    def decode(self, ids: List[int]) -> str:
        """–î–µ–∫–æ–¥–∏—Ä—É–µ—Ç ID –≤ —Ç–µ–∫—Å—Ç"""
        words = []
        for idx in ids:
            if idx == 0 or idx == 2:  # pad, end
                break
            if idx == 1:  # start
                continue

            # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê
            if idx in self.idx2word and idx < self.max_vocab_size:
                word = self.idx2word[idx]
                if word not in ['<pad>', '<start>', '<end>', '<unk>']:
                    words.append(word)

        if not words:
            return "–•–æ—Ä–æ—à–æ."

        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–æ–¥—Ä—è–¥
        unique_words = []
        prev = None
        for w in words[:25]:
            if w != prev:
                unique_words.append(w)
                prev = w

        return ' '.join(unique_words).capitalize() + '.'

    @property
    def size(self):
        """–†–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è"""
        return min(len(self.word2idx), self.max_vocab_size)

    def save(self):
        data = {
            'word2idx': self.word2idx,
            'idx2word': self.idx2word,
            'word_freq': dict(self.word_freq),
            'next_id': self.next_id,
            'max_vocab_size': self.max_vocab_size
        }
        with open(Config.VOCAB_PATH, 'wb') as f:
            pickle.dump(data, f)

    def load(self):
        if Config.VOCAB_PATH.exists():
            try:
                with open(Config.VOCAB_PATH, 'rb') as f:
                    data = pickle.load(f)
                    self.word2idx = data['word2idx']
                    self.idx2word = data['idx2word']
                    self.word_freq = Counter(data.get('word_freq', {}))
                    self.next_id = data.get('next_id', 4)
                    self.max_vocab_size = data.get('max_vocab_size', Config.VOCAB_SIZE)
                    return True
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å–ª–æ–≤–∞—Ä—è: {e}")
        return False


# ====================== –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ù–ï–ô–†–û–ù–ù–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê ======================
class PositionalEncoding(nn.Module):
    """–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –∑–∞—â–∏—Ç–æ–π"""

    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))

        pe[:, 0::2] = torch.sin(position * div_term)
        if d_model % 2 == 0:
            pe[:, 1::2] = torch.cos(position * div_term)
        else:
            pe[:, 1::2] = torch.cos(position * div_term[:-1])

        self.register_buffer('pe', pe.unsqueeze(0))

    def forward(self, x):
        seq_len = x.size(1)
        # –ó–∞—â–∏—Ç–∞ –æ—Ç –≤—ã—Ö–æ–¥–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
        if seq_len > self.pe.size(1):
            seq_len = self.pe.size(1)
        return x + self.pe[:, :seq_len, :]


class SimpleBrain(nn.Module):
    """–£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∏ —Å—Ç–∞–±–∏–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"""

    def __init__(self, vocab_size: int, device=None):
        super().__init__()
        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.vocab_size = vocab_size

        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: embedding —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        self.embedding = nn.Embedding(vocab_size, Config.EMB_DIM, padding_idx=0)
        self.pos_encoding = PositionalEncoding(Config.EMB_DIM, Config.MAX_SEQ_LEN)

        # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        self.encoder = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(
                d_model=Config.EMB_DIM,
                nhead=Config.NUM_HEADS,
                dim_feedforward=Config.HIDDEN_SIZE,
                dropout=Config.DROPOUT,
                batch_first=True
            ),
            num_layers=Config.NUM_LAYERS
        )

        self.decoder = nn.Linear(Config.EMB_DIM, vocab_size)
        self.to(self.device)

    def forward(self, input_ids, target_ids=None):
        """Forward pass —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∏–Ω–¥–µ–∫—Å–æ–≤"""
        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê
        input_ids = torch.clamp(input_ids, 0, self.vocab_size - 1)

        x = self.embedding(input_ids)
        x = self.pos_encoding(x)

        # –°–æ–∑–¥–∞—ë–º padding mask
        padding_mask = (input_ids == 0)

        encoder_out = self.encoder(x, src_key_padding_mask=padding_mask)
        logits = self.decoder(encoder_out)

        return logits

    def generate(self, input_ids, max_len: int = 40, temperature: float = 0.9):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∑–∞—â–∏—Ç–æ–π"""
        self.eval()
        with torch.no_grad():
            input_ids = input_ids.to(self.device)
            batch_size = input_ids.size(0)

            output_ids = [1]  # start token

            for _ in range(max_len):
                # –°–æ–∑–¥–∞—ë–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                current_seq = torch.tensor([output_ids], device=self.device, dtype=torch.long)

                # –ü–∞–¥–¥–∏–º –¥–æ MAX_SEQ_LEN
                if current_seq.size(1) < Config.MAX_SEQ_LEN:
                    padding = torch.zeros((1, Config.MAX_SEQ_LEN - current_seq.size(1)),
                                          device=self.device, dtype=torch.long)
                    current_seq = torch.cat([current_seq, padding], dim=1)

                logits = self.forward(input_ids, current_seq)
                next_logits = logits[0, len(output_ids) - 1, :]

                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—É
                next_logits = next_logits / temperature

                # –ú–∞—Å–∫–∏—Ä—É–µ–º —Å–ª—É–∂–µ–±–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã
                next_logits[0] = -float('inf')  # pad
                next_logits[1] = -float('inf')  # start

                probs = F.softmax(next_logits, dim=0)
                next_token = torch.multinomial(probs, 1).item()

                if next_token == 2:  # end token
                    break

                output_ids.append(next_token)

        return output_ids

    def save(self):
        torch.save({
            'state_dict': self.state_dict(),
            'vocab_size': self.vocab_size
        }, Config.MODEL_PATH)

    def load(self):
        if Config.MODEL_PATH.exists():
            try:
                checkpoint = torch.load(Config.MODEL_PATH, map_location=self.device)
                self.load_state_dict(checkpoint['state_dict'])
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False


# ====================== –ú–ï–ù–ï–î–ñ–ï–† –û–ë–£–ß–ï–ù–ò–Ø ======================
class LearningManager:
    def __init__(self):
        self.history = []
        self.skill_levels = defaultdict(float)
        self.accuracies = []
        self.load()

    def record(self, topic: str, similarity: float):
        self.history.append({
            'topic': topic,
            'similarity': similarity,
            'time': datetime.now().isoformat()
        })
        self.accuracies.append(similarity)

        if similarity > 0.5:
            self.skill_levels[topic] = min(1.0, self.skill_levels[topic] + 0.05)

        self.save()

    def get_report(self) -> str:
        if not self.accuracies:
            return "–û–±—É—á–µ–Ω–∏–µ –Ω–µ –Ω–∞—á–∞–ª–æ—Å—å"

        recent = self.accuracies[-10:]
        avg = np.mean(recent)

        report = f"üìä –û–ë–£–ß–ï–ù–ò–ï:\n"
        report += f" –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10: {avg:.1%}\n"
        report += f" –í—Å–µ–≥–æ: {len(self.history)}\n"

        if self.skill_levels:
            best_topic = max(self.skill_levels, key=self.skill_levels.get)
            report += f" –õ—É—á—à–∞—è —Ç–µ–º–∞: {best_topic} ({self.skill_levels[best_topic]:.1%})\n"

        return report

    def save(self):
        data = {
            'history': self.history,
            'skill_levels': dict(self.skill_levels),
            'accuracies': self.accuracies
        }
        with open(Config.LEARNING_PATH, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

    def load(self):
        if Config.LEARNING_PATH.exists():
            try:
                with open(Config.LEARNING_PATH, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.history = data.get('history', [])
                    self.skill_levels = defaultdict(float, data.get('skill_levels', {}))
                    self.accuracies = data.get('accuracies', [])
            except:
                pass


# ====================== –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ò–ô –ê–ù–ê–õ–ò–ó ======================
class SemanticSimilarity:
    def __init__(self):
        self.model = None
        if _HAS_ST_MODEL:
            try:
                self.model = SentenceTransformer('all-MiniLM-L6-v2')
            except:
                pass

    def similarity(self, text1: str, text2: str) -> float:
        if not text1 or not text2:
            return 0.0

        if self.model:
            try:
                emb = self.model.encode([text1, text2], normalize_embeddings=True)
                return float(np.dot(emb[0], emb[1]))
            except:
                pass

        # Fallback: Jaccard
        words1 = set(clean_for_tokenize(text1).split())
        words2 = set(clean_for_tokenize(text2).split())

        if not words1 or not words2:
            return 0.0

        intersection = len(words1 & words2)
        union = len(words1 | words2)

        return intersection / union if union > 0 else 0.0


# ====================== –ì–õ–ê–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê ======================
class CognitiveSystem:
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"üìä –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")

        self.vocab = ImprovedVocab()

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ —Å–ª–æ–≤–∞
        base_words = "–ø—Ä–∏–≤–µ—Ç —Å–ø–∞—Å–∏–±–æ –¥–∞ –Ω–µ—Ç —á—Ç–æ –∫–∞–∫ –ø–æ—á–µ–º—É –≥–¥–µ –∫–æ–≥–¥–∞ –∫—Ç–æ –∫–æ—Ç–æ—Ä—ã–π –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ –ø–æ–Ω–∏–º–∞—é —É–∑–Ω–∞–ª –Ω–æ–≤–æ–µ —Ö–æ—Ä–æ—à–æ".split()
        for word in base_words:
            self.vocab.add_word(word)

        print(f"üìö –°–ª–æ–≤–∞—Ä—å: {self.vocab.size} —Å–ª–æ–≤ (max: {Config.VOCAB_SIZE})")

        # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: —Å–æ–∑–¥–∞—ë–º –º–æ–¥–µ–ª—å —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
        self.brain = SimpleBrain(self.vocab.size, self.device)

        self.teacher = TeacherDialog(Config.QWEN_API)
        self.similarity = SemanticSimilarity()
        self.learning_manager = LearningManager()

        if self.brain.load():
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        else:
            print("üÜï –ù–æ–≤–∞—è –º–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")

        self.vocab.save()

    def learn(self, user_input: str):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫"""

        input_type = detect_input_type(user_input)

        print(f"\nüë§ –í–´: {user_input}")
        print(f"üìã –¢–∏–ø: {input_type}")

        thinking = ThinkingProcess()
        thinking.observe(f"–ü–æ–ª—É—á–∏–ª –≤–æ–ø—Ä–æ—Å: {user_input[:40]}...", 0.7)
        print(thinking)

        # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç —É—á–∏—Ç–µ–ª—è
        print("\nüë®‚Äçüè´ –°–ø—Ä–∞—à–∏–≤–∞—é —É—á–∏—Ç–µ–ª—è...")
        teacher_answer = self.teacher.ask_smart_question(user_input, input_type)
        print(f"üë®‚Äçüè´ –û–¢–í–ï–¢: {teacher_answer}")

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –≤ —Å–ª–æ–≤–∞—Ä—å –î–û —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–æ–≤
        self.vocab.add_words_from_text(user_input)
        self.vocab.add_words_from_text(teacher_answer)

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –≤—ã—Ä–æ—Å
        if self.brain.vocab_size < self.vocab.size:
            print(f"üìö –°–ª–æ–≤–∞—Ä—å –≤—ã—Ä–æ—Å: {self.brain.vocab_size} ‚Üí {self.vocab.size}")
            old_embedding = self.brain.embedding.weight.data
            self.brain.embedding = nn.Embedding(self.vocab.size, Config.EMB_DIM, padding_idx=0)
            self.brain.embedding.weight.data[:old_embedding.size(0)] = old_embedding
            self.brain.decoder = nn.Linear(Config.EMB_DIM, self.vocab.size)
            self.brain.vocab_size = self.vocab.size
            self.brain.to(self.device)

        # –ö–æ–¥–∏—Ä—É–µ–º —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π
        try:
            input_ids = torch.tensor([self.vocab.encode(user_input)], device=self.device)
            target_ids = torch.tensor([self.vocab.encode(teacher_answer)], device=self.device)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
            return teacher_answer

        # –û–±—É—á–µ–Ω–∏–µ
        print("\nüîÑ –û–ë–£–ß–ê–Æ –ú–û–î–ï–õ–¨...")
        self.brain.train()
        optimizer = torch.optim.AdamW(self.brain.parameters(), lr=Config.LEARNING_RATE)

        best_loss = float('inf')
        best_answer = teacher_answer

        for epoch in range(Config.MAX_ATTEMPTS):
            try:
                optimizer.zero_grad()

                logits = self.brain(input_ids)
                loss = F.cross_entropy(
                    logits.view(-1, self.vocab.size),
                    target_ids.view(-1),
                    ignore_index=0
                )

                loss.backward()
                torch.nn.utils.clip_grad_norm_(self.brain.parameters(), 1.0)
                optimizer.step()

                if epoch % 3 == 0:
                    self.brain.eval()
                    with torch.no_grad():
                        generated = self.brain.generate(input_ids, max_len=40, temperature=0.8)
                        my_answer = self.vocab.decode(generated)
                        similarity = self.similarity.similarity(teacher_answer, my_answer)

                        status = "‚úÖ" if similarity > 0.5 else "‚ùå"
                        print(f" {epoch:2d}. loss={loss.item():.3f}, —Å—Ö–æ–∂={similarity:.1%} {status}")

                        if loss.item() < best_loss:
                            best_loss = loss.item()
                            best_answer = my_answer

                    self.brain.train()

                if loss.item() < 0.5:
                    break

            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}: {e}")
                break

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        self.brain.eval()
        try:
            with torch.no_grad():
                final_ids = self.brain.generate(input_ids, max_len=40, temperature=0.7)
                final_answer = self.vocab.decode(final_ids)
                final_similarity = self.similarity.similarity(teacher_answer, final_answer)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
            final_answer = best_answer
            final_similarity = 0.5

        print(f"\nüí° –ú–û–ô –û–¢–í–ï–¢: {final_answer}")
        print(f"üìä –°—Ö–æ–¥—Å—Ç–≤–æ —Å —É—á–∏—Ç–µ–ª–µ–º: {final_similarity:.1%}")

        self.learning_manager.record(input_type, final_similarity)
        print(self.learning_manager.get_report())

        self.brain.save()
        self.vocab.save()

        return final_answer


# ====================== –ò–ù–¢–ï–†–§–ï–ô–° ======================
def main():
    print("\n" + "=" * 70)
    print("üß† –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê v10.0 (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)")
    print("–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏ + –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏")
    print("=" * 70)

    try:
        system = CognitiveSystem()
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
        traceback.print_exc()
        return

    print(f"\nüí° –ö–û–ú–ê–ù–î–´:")
    print(f" '–≤—ã—Ö–æ–¥' - –∑–∞–≤–µ—Ä—à–∏—Ç—å")
    print(f" '—Å—Ç–∞—Ç—É—Å' - —Å—Ç–∞—Ç—É—Å –æ–±—É—á–µ–Ω–∏—è")
    print(f" '–Ω–∞–≤—ã–∫–∏' - —É—Ä–æ–≤–Ω–∏ –ø–æ —Ç–µ–º–∞–º")

    while True:
        try:
            user_input = input("\nüë§ –í–´: ").strip()

            if not user_input:
                continue

            if user_input.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
                print("\n‚ú® –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
                break

            if user_input.lower() == '—Å—Ç–∞—Ç—É—Å':
                print(system.learning_manager.get_report())
                continue

            if user_input.lower() == '–Ω–∞–≤—ã–∫–∏':
                if system.learning_manager.skill_levels:
                    print("\nüìà –ù–ê–í–´–ö–ò:")
                    for topic, level in sorted(system.learning_manager.skill_levels.items(),
                                               key=lambda x: x[1], reverse=True):
                        bar = "‚ñà" * int(level * 20) + "‚ñë" * (20 - int(level * 20))
                        print(f" {topic:15s} [{bar}] {level:.1%}")
                continue

            # –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
            system.learn(user_input)

        except KeyboardInterrupt:
            print("\n‚ú® –ü—Ä–µ—Ä—ã–≤–∞–Ω–∏–µ")
            break
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            traceback.print_exc()


if __name__ == "__main__":
    main()
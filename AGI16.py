# coding: utf-8
"""
AGI_Hybrid_v22_OPENROUTER_FINAL.py ‚Äî –° –í–ò–ó–£–ê–õ–¨–ù–û–ô –û–ë–†–ê–¢–ù–û–ô –°–í–Ø–ó–¨–Æ
–ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–∞–±–æ—á–∞—è –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –≤—Å–µ—Ö –æ—Ç–≤–µ—Ç–æ–≤
"""

import re, json, requests, time, os, sys
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from datetime import datetime, timezone


# ================= –ó–ê–ì–†–£–ó–ö–ê –ö–õ–Æ–ß–ê =================
def load_api_key():
    key = os.getenv("OPENROUTER_API_KEY", "")
    if not key:
        env_path = Path(".env")
        if env_path.exists():
            with open(env_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        if "=" in line:
                            k, v = line.split("=", 1)
                            if k.strip() == "OPENROUTER_API_KEY":
                                key = v.strip().strip('"').strip("'")
    return key


# ================= –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =================
class Config:
    ROOT = Path("./cognitive_v22")
    ROOT.mkdir(exist_ok=True)
    OBJECTS = ROOT / "objects.json"
    CAUSAL = ROOT / "causal.json"
    META = ROOT / "meta.json"
    EPISODE = ROOT / "episodes.json"
    LOG = ROOT / "log.txt"

    TIMEOUT = 25
    MAX_CHAIN = 8
    MIN_CONF = 0.15
    FORGET_RATE = 0.01
    MEMORY_LIMIT = 150
    WORKING_SIZE = 30

    # üîë –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±—Ä–∞–Ω—ã –ø—Ä–æ–±–µ–ª—ã –≤ –∫–æ–Ω—Ü–µ URL!
    OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
    OPENROUTER_API_KEY = load_api_key()
    MODEL = "qwen/qwen-2.5-7b-instruct"  # –û—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π Qwen


# ================= –£–¢–ò–õ–ò–¢–´ =================
def clean(text: str) -> str:
    return re.sub(r"\s+", " ", re.sub(r"[^\w\s]", " ", text.lower())).strip()


def extract(text: str) -> List[str]:
    stop = {"—á—Ç–æ", "–∫–∞–∫", "–ø–æ—á–µ–º—É", "–µ—Å–ª–∏", "—Ç–æ", "—ç—Ç–æ", "—è", "—Ç—ã", "–º—ã", "–æ–Ω–∏", "–æ–Ω", "–æ–Ω–∞", "–æ–Ω–æ"}
    return [w for w in clean(text).split() if len(w) > 3 and w not in stop]


def print_typing(text: str, delay=0.012):
    """–≠—Ñ—Ñ–µ–∫—Ç –ø–µ—á–∞—Ç–∞–Ω–∏—è —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"""
    for c in text:
        print(c, end="", flush=True)
        time.sleep(delay)
    print(flush=True)


# ================= –ö–û–ù–¶–ï–ü–¢–´ =================
@dataclass
class Concept:
    name: str
    confidence: float = 0.2
    effects: Dict[str, float] = field(default_factory=dict)
    abstract: bool = False
    freq: int = 0

    def reinforce(self, k=0.1):
        self.confidence = min(1.0, self.confidence + k)
        self.freq += 1

    def decay(self):
        self.confidence *= (1 - Config.FORGET_RATE)
        self.freq = max(0, self.freq - 1)


# ================= –≠–ü–ò–ó–û–î–´ =================
@dataclass
class Episode:
    time: str
    input: str
    focus: Optional[str]
    result: str


# ================= –†–ê–ë–û–ß–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
@dataclass
class WorkingMemoryItem:
    content: str
    timestamp: float
    importance: float


class WorkingMemory:
    def __init__(self, size=Config.WORKING_SIZE):
        self.items: List[WorkingMemoryItem] = []
        self.size = size

    def add(self, content, importance=0.5):
        self.items.append(WorkingMemoryItem(content, time.time(), importance))
        self.items.sort(key=lambda x: -x.importance)
        self.items = self.items[:self.size]

    def recall(self):
        return [i.content for i in self.items]


# ================= –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
class SemanticMemory:
    def __init__(self):
        self.data: Dict[str, Concept] = {}
        self.load()

    def get(self, name: str) -> Concept:
        if name not in self.data:
            self.data[name] = Concept(name=name)
        return self.data[name]

    def link(self, a: str, b: str):
        c = self.get(a)
        c.effects[b] = min(1.0, c.effects.get(b, 0.1) + 0.3)
        c.reinforce()

    def decay_all(self):
        for c in self.data.values():
            c.decay()

    def generate_abstracts(self):
        names = list(self.data.keys())
        for i, c1 in enumerate(names):
            for c2 in names[i + 1:]:
                common = set(self.data[c1].effects) & set(self.data[c2].effects)
                if len(common) / max(len(self.data[c1].effects), 1) > 0.5:
                    abs_name = f"{c1}_{c2}_meta"
                    self.get(abs_name).abstract = True
                    self.link(c1, abs_name)
                    self.link(c2, abs_name)

    def save(self):
        with open(Config.OBJECTS, "w", encoding="utf-8") as f:
            json.dump({k: v.__dict__ for k, v in self.data.items()}, f, ensure_ascii=False, indent=2)

    def load(self):
        if Config.OBJECTS.exists():
            with open(Config.OBJECTS, "r", encoding="utf-8") as f:
                for k, v in json.load(f).items():
                    self.data[k] = Concept(**v)


# ================= –ü–†–ò–ß–ò–ù–ù–û-–°–õ–ï–î–°–¢–í–ï–ù–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
class CausalMemory:
    def __init__(self):
        self.graph: Dict[str, Dict[str, float]] = {}
        self.load()

    def add(self, a: str, b: str):
        self.graph.setdefault(a, {})
        self.graph[a][b] = min(1.0, self.graph[a].get(b, 0.1) + 0.25)

    def chain(self, start: str) -> List[str]:
        chain = [start];
        cur = start
        for _ in range(Config.MAX_CHAIN):
            if cur not in self.graph or not self.graph[cur]: break
            nxt = max(self.graph[cur], key=self.graph[cur].get)
            if nxt in chain: break
            chain.append(nxt)
            cur = nxt
        return chain

    def predict(self, start: str, steps=3) -> List[str]:
        result = []
        cur = start
        for _ in range(steps):
            if cur not in self.graph or not self.graph[cur]: break
            nxt = max(self.graph[cur], key=self.graph[cur].get)
            result.append(nxt)
            cur = nxt
        return result

    def prune(self):
        for a in list(self.graph.keys()):
            for b in list(self.graph[a].keys()):
                self.graph[a][b] *= (1 - Config.FORGET_RATE)
                if self.graph[a][b] < Config.MIN_CONF:
                    del self.graph[a][b]
            if not self.graph[a]:
                del self.graph[a]

    def save(self):
        with open(Config.CAUSAL, "w", encoding="utf-8") as f:
            json.dump(self.graph, f, ensure_ascii=False, indent=2)

    def load(self):
        if Config.CAUSAL.exists():
            with open(Config.CAUSAL, "r", encoding="utf-8") as f:
                self.graph = json.load(f)


# ================= –°–ê–ú–û–ú–û–î–ï–õ–¨ =================
class SelfModel:
    def describe(self, stats: Dict) -> str:
        return (f"–Ø –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ v22.\n"
                f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π: {stats['interactions']}\n"
                f"–ò–∑—É—á–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π: {stats['links']}\n"
                f"–Ø –æ–±—É—á–∞—é—Å—å, –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É—é –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è –∏ –º–æ–≥—É —É—Ç–æ—á–Ω—è—Ç—å –¥–µ—Ç–∞–ª–∏.")

    def reflect(self, semantic: SemanticMemory, query: str) -> str:
        concepts = extract(query)
        if not concepts: return ""
        confidences = [semantic.get(c).confidence for c in concepts]
        known_words = {"–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "—Ä–∞–±–æ—Ç–∞", "—Ç—ã", "—è", "—Å–∏—Å—Ç–µ–º–∞", "–¥–∞", "–Ω–µ—Ç"}
        for c in concepts:
            if c in known_words:
                semantic.get(c).confidence = max(semantic.get(c).confidence, 0.5)
        if confidences and min(confidences) < 0.2:
            return "–Ø –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —ç—Ç–æ–º, –º–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å —É –≤–∞—Å?"
        return ""


# ================= –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê =================
class CognitiveSystemV22:
    def __init__(self):
        print("üß† Cognitive System v22 ‚Äî OpenRouter Integration\n")

        if not Config.OPENROUTER_API_KEY:
            print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω OPENROUTER_API_KEY!")
            print("   –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env —Å–æ —Å—Ç—Ä–æ–∫–æ–π:")
            print("   OPENROUTER_API_KEY=sk-or-v1-–≤–∞—à_–∫–ª—é—á")
            sys.exit(1)

        self.semantic = SemanticMemory()
        self.causal = CausalMemory()
        self.working = WorkingMemory()
        self.self_model = SelfModel()
        self.episodes: List[Episode] = []
        self.meta = self.load_meta()
        self.log_fd = open(Config.LOG, "a", encoding="utf-8")
        self.internal_log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def internal_log(self, msg: str):
        ts = datetime.now(timezone.utc).isoformat()
        self.log_fd.write(f"[{ts}] {msg}\n")
        self.log_fd.flush()

    # ------------------------------------------------------------------
    def process(self, text: str) -> str:
        """–í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É –æ—Ç–≤–µ—Ç–∞ (–Ω–∏–∫–∞–∫–∏—Ö —Å–∫—Ä—ã—Ç—ã—Ö –≤–æ–∑–≤—Ä–∞—Ç–æ–≤ –±–µ–∑ –≤—ã–≤–æ–¥–∞!)"""
        self.meta["interactions"] += 1
        self.working.add(text)
        words = extract(text)
        focus = words[0] if words else None
        answer = ""

        # 1Ô∏è‚É£ –ü—Ä–∏—á–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–µ—Å–ª–∏-—Ç–æ)
        if "–µ—Å–ª–∏" in text and "—Ç–æ" in text:
            parts = clean(text).split("—Ç–æ", 1)
            c = extract(parts[0]);
            e = extract(parts[1])
            if c and e:
                self.causal.add(c[-1], e[0])
                self.semantic.link(c[-1], e[0])
                self.meta["links"] += 1
                self.save()
                answer = f"üß† –£—Å–≤–æ–µ–Ω–∞ –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å: {c[-1]} ‚Üí {e[0]}"
                self.internal_log(f"–ü—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å: {c[-1]} ‚Üí {e[0]}")
                return answer

        # 2Ô∏è‚É£ –ü—Ä–∏—á–∏–Ω–Ω–∞—è —Ü–µ–ø—å
        if focus:
            chain = self.causal.chain(focus)
            if len(chain) > 1:
                answer = "üîó –ü—Ä–∏—á–∏–Ω–Ω–∞—è —Ü–µ–ø—å: " + " ‚Üí ".join(chain)
                self.internal_log(f"–¶–µ–ø—å –¥–ª—è '{focus}': {chain}")
                return answer

        # 3Ô∏è‚É£ –ú–µ—Ç–∞–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –æ—Ç–∫–ª–∏–∫
        reflect = self.self_model.reflect(self.semantic, text)
        if reflect and len(words) > 1:
            answer = "ü§î " + reflect
            return answer

        # 4Ô∏è‚É£ –ó–∞–ø—Ä–æ—Å –∫ –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏
        answer = self.learn_from_openrouter(text)

        # 5Ô∏è‚É£ –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏–π
        if focus:
            prediction = self.causal.predict(focus)
            if prediction:
                answer += f"\n\nüîÆ –ü—Ä–æ–≥–Ω–æ–∑: {' ‚Üí '.join(prediction)}"

        # 6Ô∏è‚É£ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
        self.semantic.decay_all()
        self.causal.prune()
        self.semantic.generate_abstracts()

        # 7Ô∏è‚É£ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        now = datetime.now(timezone.utc).isoformat()
        self.episodes.append(Episode(now, text, focus, answer))
        self.episodes = self.episodes[-Config.MEMORY_LIMIT:]
        self.save()

        return answer

    # ------------------------------------------------------------------
    def learn_from_openrouter(self, q: str) -> str:
        try:
            print("‚è≥ –ó–∞–ø—Ä–∞—à–∏–≤–∞—é –æ—Ç–≤–µ—Ç —É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...", flush=True)
            time.sleep(0.3)  # –í–∏–∑—É–∞–ª—å–Ω–∞—è –ø–∞—É–∑–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏

            headers = {
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:8000",
                "X-Title": "CognitiveSystemV22"
            }
            payload = {
                "model": Config.MODEL,
                "messages": [
                    {"role": "system", "content": "–¢—ã ‚Äî –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."},
                    {"role": "user", "content": q}
                ],
                "temperature": 0.3,
                "max_tokens": 250
            }

            r = requests.post(
                Config.OPENROUTER_URL,
                headers=headers,
                json=payload,
                timeout=Config.TIMEOUT
            )
            r.raise_for_status()
            content = r.json()["choices"][0]["message"]["content"].strip()

            # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ –ø–∞–º—è—Ç—å
            txt = clean(content)
            w = extract(txt)
            for i in range(len(w) - 1):
                self.semantic.link(w[i], w[i + 1])
                self.causal.add(w[i], w[i + 1])
                self.meta["links"] += 1

            return content

        except Exception as e:
            error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)[:80]}"
            self.internal_log(f"OpenRouter –æ—à–∏–±–∫–∞: {e}")
            return error_msg

    # ------------------------------------------------------------------
    def save(self):
        self.semantic.save()
        self.causal.save()
        with open(Config.EPISODE, "w", encoding="utf-8") as f:
            json.dump([e.__dict__ for e in self.episodes], f, ensure_ascii=False, indent=2)
        with open(Config.META, "w", encoding="utf-8") as f:
            json.dump(self.meta, f, ensure_ascii=False, indent=2)

    def load_meta(self) -> Dict:
        if Config.META.exists():
            with open(Config.META, "r", encoding="utf-8") as f:
                return json.load(f)
        return {"interactions": 0, "links": 0}


# ================= –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê =================
def run_diagnosis() -> bool:
    print("=" * 60)
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´")
    print("=" * 60)

    if not Config.OPENROUTER_API_KEY:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω OPENROUTER_API_KEY")
        return False

    print(f"‚úÖ –ö–ª—é—á: {Config.OPENROUTER_API_KEY[:8]}...{Config.OPENROUTER_API_KEY[-4:]}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å: {Config.MODEL}")

    try:
        print("üì° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", end=" ", flush=True)
        r = requests.post(
            Config.OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:8000",
                "X-Title": "Test"
            },
            json={"model": Config.MODEL, "messages": [{"role": "user", "content": "ok"}], "max_tokens": 5},
            timeout=10
        )
        if r.status_code == 200:
            print("‚úÖ –£–°–ü–ï–•")
            return True
        else:
            print(f"‚ùå –û–®–ò–ë–ö–ê {r.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå –°–ï–¢–¨: {e}")
        return False


# ================= –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ =================
def main():
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –≤ Windows
    if sys.platform == "win32":
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
        except:
            pass

    print("\n" + "=" * 60)
    print("üß† COGNITIVE SYSTEM v22 ‚Äî OpenRouter Edition")
    print("=" * 60 + "\n")

    if not run_diagnosis():
        print("\nüí° –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:")
        print("   1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env —Å –∫–ª—é—á–æ–º OPENROUTER_API_KEY")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å —É–∫–∞–∑–∞–Ω–∞ –ë–ï–ó ':free'")
        print("   3. URL API –Ω–µ –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –∫–æ–Ω—Ü–µ")
        return

    system = CognitiveSystemV22()

    print("\n" + "=" * 60)
    print("üí¨ –ì–û–¢–û–í –ö –î–ò–ê–õ–û–ì–£")
    print("=" * 60)
    print("–ö–æ–º–∞–Ω–¥—ã:")
    print("  ‚Ä¢ 'exit' ‚Äî –≤—ã—Ö–æ–¥")
    print("  ‚Ä¢ '–µ—Å–ª–∏ –ê —Ç–æ –ë' ‚Äî –æ–±—É—á–µ–Ω–∏–µ –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç–∏")
    print("  ‚Ä¢ '–∑–∞–ø–æ–º–Ω–∏ –•' ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∑–∞–ø–æ–º–Ω–∏—Ç –∫–æ–Ω—Ü–µ–ø—Ç")
    print("=" * 60 + "\n")

    while True:
        try:
            q = input("–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            if q.lower() in ("exit", "–≤—ã—Ö–æ–¥", "quit", "q"):
                print("\nüëã –°–∏—Å—Ç–µ–º–∞ –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞. –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
                break
            if not q:
                continue

            print()
            answer = system.process(q)

            # üî• –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–´–ô –í–´–í–û–î –û–¢–í–ï–¢–ê (—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º—ã "–Ω–µ–≤–∏–¥–∏–º—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤")
            if answer.strip():
                print("\nüí¨ –û—Ç–≤–µ—Ç:")
                print_typing(answer, delay=0.015)
            else:
                print_typing("ü§î –Ø –ø–æ–ª—É—á–∏–ª –≤–∞—à –≤–æ–ø—Ä–æ—Å, –Ω–æ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å.", delay=0.015)

            print("\n" + "-" * 60 + "\n")

        except KeyboardInterrupt:
            print("\n\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º.")
            break
        except Exception as e:
            print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            print("\n" + "-" * 60 + "\n")


if __name__ == "__main__":
    main()
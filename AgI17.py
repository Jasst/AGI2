# coding: utf-8
"""
AGI_Hybrid_v22_MEMORY_AWARE.py ‚Äî –° –ü–ï–†–ï–î–ê–ß–ï–ô –ü–ê–ú–Ø–¢–ò –í –ü–†–û–ú–ü–¢
–¢–µ–ø–µ—Ä—å —Å–∏—Å—Ç–µ–º–∞ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–æ—Å–ø–æ–º–∏–Ω–∞–Ω–∏—è –≤ –¥–∏–∞–ª–æ–≥–µ
"""

import re, json, requests, time, os, sys
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional
from datetime import datetime, timezone


# ================= –ó–ê–ì–†–£–ó–ö–ê –ö–õ–Æ–ß–ê =================
def load_api_key():
    key = os.getenv("OPENROUTER_API_KEY", "")
    if not key:
        env_path = Path(".env")
        if env_path.exists():
            with open(env_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        if "=" in line:
                            k, v = line.split("=", 1)
                            if k.strip() == "OPENROUTER_API_KEY":
                                key = v.strip().strip('"').strip("'")
    return key


# ================= –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =================
class Config:
    ROOT = Path("./cognitive_v22")
    ROOT.mkdir(exist_ok=True)
    OBJECTS = ROOT / "objects.json"
    CAUSAL = ROOT / "causal.json"
    META = ROOT / "meta.json"
    EPISODE = ROOT / "episodes.json"
    LOG = ROOT / "log.txt"

    TIMEOUT = 25
    MAX_CHAIN = 8
    MIN_CONF = 0.15
    FORGET_RATE = 0.01
    MEMORY_LIMIT = 150
    WORKING_SIZE = 30

    OPENROUTER_URL = "https://openrouter.ai/api/v1/chat/completions"
    OPENROUTER_API_KEY = load_api_key()
    MODEL = "qwen/qwen-2.5-7b-instruct"


# ================= –£–¢–ò–õ–ò–¢–´ =================
def clean(text: str) -> str:
    return re.sub(r"\s+", " ", re.sub(r"[^\w\s]", " ", text.lower())).strip()


def extract(text: str) -> List[str]:
    stop = {"—á—Ç–æ", "–∫–∞–∫", "–ø–æ—á–µ–º—É", "–µ—Å–ª–∏", "—Ç–æ", "—ç—Ç–æ", "—è", "—Ç—ã", "–º—ã", "–æ–Ω–∏", "–æ–Ω", "–æ–Ω–∞", "–æ–Ω–æ"}
    return [w for w in clean(text).split() if len(w) > 3 and w not in stop]


def print_typing(text: str, delay=0.012):
    for c in text:
        print(c, end="", flush=True)
        time.sleep(delay)
    print(flush=True)


# ================= –ö–û–ù–¶–ï–ü–¢–´ =================
@dataclass
class Concept:
    name: str
    confidence: float = 0.2
    effects: Dict[str, float] = field(default_factory=dict)
    abstract: bool = False
    freq: int = 0

    def reinforce(self, k=0.1):
        self.confidence = min(1.0, self.confidence + k)
        self.freq += 1

    def decay(self):
        self.confidence *= (1 - Config.FORGET_RATE)
        self.freq = max(0, self.freq - 1)


# ================= –≠–ü–ò–ó–û–î–´ =================
@dataclass
class Episode:
    time: str
    input: str
    focus: Optional[str]
    result: str


# ================= –†–ê–ë–û–ß–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
@dataclass
class WorkingMemoryItem:
    content: str
    timestamp: float
    importance: float


class WorkingMemory:
    def __init__(self, size=Config.WORKING_SIZE):
        self.items: List[WorkingMemoryItem] = []
        self.size = size

    def add(self, content, importance=0.5):
        self.items.append(WorkingMemoryItem(content, time.time(), importance))
        self.items.sort(key=lambda x: -x.importance)
        self.items = self.items[:self.size]

    def recall(self):
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        return [i.content for i in sorted(self.items, key=lambda x: -x.timestamp)[:5]]


# ================= –°–ï–ú–ê–ù–¢–ò–ß–ï–°–ö–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
class SemanticMemory:
    def __init__(self):
        self.data: Dict[str, Concept] = {}
        self.load()

    def get(self, name: str) -> Concept:
        if name not in self.data:
            self.data[name] = Concept(name=name)
        return self.data[name]

    def link(self, a: str, b: str):
        c = self.get(a)
        c.effects[b] = min(1.0, c.effects.get(b, 0.1) + 0.3)
        c.reinforce()

    def decay_all(self):
        for c in self.data.values():
            c.decay()

    def generate_abstracts(self):
        names = list(self.data.keys())
        for i, c1 in enumerate(names):
            for c2 in names[i + 1:]:
                common = set(self.data[c1].effects) & set(self.data[c2].effects)
                if len(common) / max(len(self.data[c1].effects), 1) > 0.5:
                    abs_name = f"{c1}_{c2}_meta"
                    self.get(abs_name).abstract = True
                    self.link(c1, abs_name)
                    self.link(c2, abs_name)

    def get_relevant_concepts(self, query: str, top_k=5) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–æ–ø –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤, —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å—É"""
        concepts = extract(query)
        scores = {}
        for name, concept in self.data.items():
            if concept.confidence < 0.3:
                continue
            # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Å–ª–æ–≤
            if any(c in name or name in c for c in concepts):
                scores[name] = concept.confidence * 2
            elif concept.freq > 2:
                scores[name] = concept.confidence * 0.5
        return sorted(scores, key=scores.get, reverse=True)[:top_k]

    def save(self):
        with open(Config.OBJECTS, "w", encoding="utf-8") as f:
            json.dump({k: v.__dict__ for k, v in self.data.items()}, f, ensure_ascii=False, indent=2)

    def load(self):
        if Config.OBJECTS.exists():
            with open(Config.OBJECTS, "r", encoding="utf-8") as f:
                for k, v in json.load(f).items():
                    self.data[k] = Concept(**v)


# ================= –ü–†–ò–ß–ò–ù–ù–û-–°–õ–ï–î–°–¢–í–ï–ù–ù–ê–Ø –ü–ê–ú–Ø–¢–¨ =================
class CausalMemory:
    def __init__(self):
        self.graph: Dict[str, Dict[str, float]] = {}
        self.load()

    def add(self, a: str, b: str):
        self.graph.setdefault(a, {})
        self.graph[a][b] = min(1.0, self.graph[a].get(b, 0.1) + 0.25)

    def chain(self, start: str) -> List[str]:
        chain = [start];
        cur = start
        for _ in range(Config.MAX_CHAIN):
            if cur not in self.graph or not self.graph[cur]: break
            nxt = max(self.graph[cur], key=self.graph[cur].get)
            if nxt in chain: break
            chain.append(nxt)
            cur = nxt
        return chain

    def predict(self, start: str, steps=3) -> List[str]:
        result = []
        cur = start
        for _ in range(steps):
            if cur not in self.graph or not self.graph[cur]: break
            nxt = max(self.graph[cur], key=self.graph[cur].get)
            result.append(nxt)
            cur = nxt
        return result

    def get_all_chains(self) -> List[str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–∏—á–∏–Ω–Ω—ã–µ —Ü–µ–ø–∏ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏"""
        chains = []
        for start in self.graph:
            chain = self.chain(start)
            if len(chain) > 1:
                chains.append(" ‚Üí ".join(chain))
        return chains[:5]  # –ú–∞–∫—Å–∏–º—É–º 5 —Ü–µ–ø–µ–π

    def prune(self):
        for a in list(self.graph.keys()):
            for b in list(self.graph[a].keys()):
                self.graph[a][b] *= (1 - Config.FORGET_RATE)
                if self.graph[a][b] < Config.MIN_CONF:
                    del self.graph[a][b]
            if not self.graph[a]:
                del self.graph[a]

    def save(self):
        with open(Config.CAUSAL, "w", encoding="utf-8") as f:
            json.dump(self.graph, f, ensure_ascii=False, indent=2)

    def load(self):
        if Config.CAUSAL.exists():
            with open(Config.CAUSAL, "r", encoding="utf-8") as f:
                self.graph = json.load(f)


# ================= –°–ê–ú–û–ú–û–î–ï–õ–¨ =================
class SelfModel:
    def describe(self, stats: Dict) -> str:
        return (f"–Ø –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ v22.\n"
                f"–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π: {stats['interactions']}\n"
                f"–ò–∑—É—á–µ–Ω–Ω—ã—Ö —Å–≤—è–∑–µ–π: {stats['links']}")

    def reflect(self, semantic: SemanticMemory, query: str) -> str:
        concepts = extract(query)
        if not concepts: return ""
        confidences = [semantic.get(c).confidence for c in concepts]
        known_words = {"–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "—Ä–∞–±–æ—Ç–∞", "—Ç—ã", "—è", "—Å–∏—Å—Ç–µ–º–∞", "–¥–∞", "–Ω–µ—Ç"}
        for c in concepts:
            if c in known_words:
                semantic.get(c).confidence = max(semantic.get(c).confidence, 0.5)
        if confidences and min(confidences) < 0.2:
            return "–Ø –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —ç—Ç–æ–º, –º–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å —É –≤–∞—Å?"
        return ""


# ================= –ö–û–ì–ù–ò–¢–ò–í–ù–ê–Ø –°–ò–°–¢–ï–ú–ê –° –ü–ê–ú–Ø–¢–¨–Æ =================
class CognitiveSystemV22:
    def __init__(self):
        print("üß† Cognitive System v22 ‚Äî MEMORY-AWARE Edition\n")

        if not Config.OPENROUTER_API_KEY:
            print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ –Ω–∞–π–¥–µ–Ω OPENROUTER_API_KEY!")
            sys.exit(1)

        self.semantic = SemanticMemory()
        self.causal = CausalMemory()
        self.working = WorkingMemory()
        self.self_model = SelfModel()
        self.episodes: List[Episode] = []
        self.meta = self.load_meta()
        self.log_fd = open(Config.LOG, "a", encoding="utf-8")
        self.internal_log("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def internal_log(self, msg: str):
        ts = datetime.now(timezone.utc).isoformat()
        self.log_fd.write(f"[{ts}] {msg}\n")
        self.log_fd.flush()

    # ------------------------------------------------------------------
    def process(self, text: str) -> str:
        self.meta["interactions"] += 1
        self.working.add(text)
        words = extract(text)
        focus = words[0] if words else None
        answer = ""

        # 1Ô∏è‚É£ –ü—Ä–∏—á–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (–µ—Å–ª–∏-—Ç–æ)
        if "–µ—Å–ª–∏" in text and "—Ç–æ" in text:
            parts = clean(text).split("—Ç–æ", 1)
            c = extract(parts[0]);
            e = extract(parts[1])
            if c and e:
                self.causal.add(c[-1], e[0])
                self.semantic.link(c[-1], e[0])
                self.meta["links"] += 1
                self.save()
                answer = f"üß† –£—Å–≤–æ–µ–Ω–∞ –ø—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å: {c[-1]} ‚Üí {e[0]}"
                self.internal_log(f"–ü—Ä–∏—á–∏–Ω–Ω–æ—Å—Ç—å: {c[-1]} ‚Üí {e[0]}")
                return answer

        # 2Ô∏è‚É£ –ü—Ä–∏—á–∏–Ω–Ω–∞—è —Ü–µ–ø—å
        if focus:
            chain = self.causal.chain(focus)
            if len(chain) > 1:
                answer = "üîó –ü—Ä–∏—á–∏–Ω–Ω–∞—è —Ü–µ–ø—å: " + " ‚Üí ".join(chain)
                self.internal_log(f"–¶–µ–ø—å –¥–ª—è '{focus}': {chain}")
                return answer

        # 3Ô∏è‚É£ –ú–µ—Ç–∞–∫–æ–≥–Ω–∏—Ç–∏–≤–Ω—ã–π –æ—Ç–∫–ª–∏–∫
        reflect = self.self_model.reflect(self.semantic, text)
        if reflect and len(words) > 1:
            answer = "ü§î " + reflect
            return answer

        # 4Ô∏è‚É£ –ó–∞–ø—Ä–æ—Å –∫ –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏ –° –ö–û–ù–¢–ï–ö–°–¢–û–ú –ü–ê–ú–Ø–¢–ò ‚Üê –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï!
        answer = self.learn_from_openrouter_with_memory(text)

        # 5Ô∏è‚É£ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
        self.semantic.decay_all()
        self.causal.prune()
        self.semantic.generate_abstracts()

        # 6Ô∏è‚É£ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        now = datetime.now(timezone.utc).isoformat()
        self.episodes.append(Episode(now, text, focus, answer))
        self.episodes = self.episodes[-Config.MEMORY_LIMIT:]
        self.save()

        return answer

    # ------------------------------------------------------------------
    def build_memory_context(self, query: str) -> str:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö —Ç–∏–ø–æ–≤ –ø–∞–º—è—Ç–∏"""
        context_parts = []

        # 1. –†–∞–±–æ—á–∞—è –ø–∞–º—è—Ç—å (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è)
        recent = self.working.recall()
        if recent:
            context_parts.append("–ù–µ–¥–∞–≤–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è:\n" + "\n".join([f"  ‚Ä¢ {e}" for e in recent[-3:]]))

        # 2. –ü—Ä–∏—á–∏–Ω–Ω—ã–µ —Ü–µ–ø–∏
        chains = self.causal.get_all_chains()
        if chains:
            context_parts.append("–ü—Ä–∏—á–∏–Ω–Ω—ã–µ —Å–≤—è–∑–∏:\n" + "\n".join([f"  ‚Ä¢ {c}" for c in chains]))

        # 3. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã
        concepts = self.semantic.get_relevant_concepts(query, top_k=5)
        if concepts:
            concept_info = []
            for name in concepts:
                c = self.semantic.get(name)
                if c.confidence > 0.3:
                    concept_info.append(f"{name} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {c.confidence:.2f}, —É–ø–æ–º–∏–Ω–∞–Ω–∏–π: {c.freq})")
            if concept_info:
                context_parts.append("–í–∞–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ç—ã:\n" + "\n".join([f"  ‚Ä¢ {c}" for c in concept_info]))

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if context_parts:
            return "–ö–û–ù–¢–ï–ö–°–¢ –ú–û–ï–ô –ü–ê–ú–Ø–¢–ò:\n" + "\n\n".join(context_parts) + "\n\n"
        return ""

    # ------------------------------------------------------------------
    def learn_from_openrouter_with_memory(self, q: str) -> str:
        """–ó–∞–ø—Ä–æ—Å –∫ –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏ –° –ü–ï–†–ï–î–ê–ß–ï–ô –ö–û–ù–¢–ï–ö–°–¢–ê –ü–ê–ú–Ø–¢–ò"""
        # –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–∞–º—è—Ç–∏
        memory_context = self.build_memory_context(q)

        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –ø–∞–º—è—Ç—å –î–û –∑–∞–ø—Ä–æ—Å–∞
        words = extract(q)
        for i in range(len(words) - 1):
            self.semantic.link(words[i], words[i + 1])
            self.causal.add(words[i], words[i + 1])
            self.meta["links"] += 1

        try:
            if memory_context:
                print(f"üß† –ò—Å–ø–æ–ª—å–∑—É—é –ø–∞–º—è—Ç—å ({len(memory_context)} —Å–∏–º–≤–æ–ª–æ–≤):")
                print(memory_context[:300] + "..." if len(memory_context) > 300 else memory_context)
            else:
                print("üí≠ –ü–∞–º—è—Ç—å –ø—É—Å—Ç–∞ –∏–ª–∏ –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –∑–∞–ø—Ä–æ—Å—É")

            print("‚è≥ –ó–∞–ø—Ä–∞—à–∏–≤–∞—é –æ—Ç–≤–µ—Ç —É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏...", flush=True)
            time.sleep(0.3)

            headers = {
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:8000",
                "X-Title": "CognitiveSystemV22"
            }

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –ø–∞–º—è—Ç–∏
            system_prompt = (
                "–¢—ã ‚Äî –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é. "
                "–û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É.\n\n"
                f"{memory_context}"
                "–û–°–ù–û–í–ù–û–ï –ü–†–ê–í–ò–õ–û: –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø–∞–º—è—Ç–∏ –µ—Å—Ç—å –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ. "
                "–ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ."
            )

            payload = {
                "model": Config.MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": q}
                ],
                "temperature": 0.3,
                "max_tokens": 300
            }

            r = requests.post(
                Config.OPENROUTER_URL,
                headers=headers,
                json=payload,
                timeout=Config.TIMEOUT
            )
            r.raise_for_status()
            content = r.json()["choices"][0]["message"]["content"].strip()

            return content

        except Exception as e:
            error_msg = f"‚ö†Ô∏è –û—à–∏–±–∫–∞: {str(e)[:80]}"
            self.internal_log(f"OpenRouter –æ—à–∏–±–∫–∞: {e}")
            return error_msg

    # ------------------------------------------------------------------
    def save(self):
        self.semantic.save()
        self.causal.save()
        with open(Config.EPISODE, "w", encoding="utf-8") as f:
            json.dump([e.__dict__ for e in self.episodes], f, ensure_ascii=False, indent=2)
        with open(Config.META, "w", encoding="utf-8") as f:
            json.dump(self.meta, f, ensure_ascii=False, indent=2)

    def load_meta(self) -> Dict:
        if Config.META.exists():
            with open(Config.META, "r", encoding="utf-8") as f:
                return json.load(f)
        return {"interactions": 0, "links": 0}


# ================= –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê =================
def run_diagnosis() -> bool:
    print("=" * 60)
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´")
    print("=" * 60)

    if not Config.OPENROUTER_API_KEY:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω OPENROUTER_API_KEY")
        return False

    print(f"‚úÖ –ö–ª—é—á: {Config.OPENROUTER_API_KEY[:8]}...{Config.OPENROUTER_API_KEY[-4:]}")
    print(f"‚úÖ –ú–æ–¥–µ–ª—å: {Config.MODEL}")

    try:
        print("üì° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...", end=" ", flush=True)
        r = requests.post(
            Config.OPENROUTER_URL,
            headers={
                "Authorization": f"Bearer {Config.OPENROUTER_API_KEY}",
                "Content-Type": "application/json",
                "HTTP-Referer": "http://localhost:8000",
                "X-Title": "Test"
            },
            json={"model": Config.MODEL, "messages": [{"role": "user", "content": "ok"}], "max_tokens": 5},
            timeout=10
        )
        if r.status_code == 200:
            print("‚úÖ –£–°–ü–ï–•")
            return True
        else:
            print(f"‚ùå –û–®–ò–ë–ö–ê {r.status_code}")
            return False
    except Exception as e:
        print(f"‚ùå –°–ï–¢–¨: {e}")
        return False


# ================= –û–°–ù–û–í–ù–û–ô –¶–ò–ö–õ =================
def main():
    if sys.platform == "win32":
        try:
            import ctypes
            kernel32 = ctypes.windll.kernel32
            kernel32.SetConsoleMode(kernel32.GetStdHandle(-11), 7)
        except:
            pass

    print("\n" + "=" * 60)
    print("üß† COGNITIVE SYSTEM v22 ‚Äî MEMORY-AWARE Edition")
    print("=" * 60 + "\n")

    if not run_diagnosis():
        print("\nüí° –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º:")
        print("   1. –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env —Å –∫–ª—é—á–æ–º OPENROUTER_API_KEY")
        print("   2. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª—å —É–∫–∞–∑–∞–Ω–∞ –ë–ï–ó ':free'")
        return

    system = CognitiveSystemV22()

    print("\n" + "=" * 60)
    print("üí¨ –ì–û–¢–û–í –ö –î–ò–ê–õ–û–ì–£ –° –ü–ê–ú–Ø–¢–¨–Æ")
    print("=" * 60)
    print("–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:")
    print("  ‚Ä¢ –°–∏—Å—Ç–µ–º–∞ –ó–ê–ü–û–ú–ò–ù–ê–ï–¢ —Ñ–∞–∫—Ç—ã –∏ –ø—Ä–∏—á–∏–Ω–Ω—ã–µ —Å–≤—è–∑–∏")
    print("  ‚Ä¢ –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–∞–º—è—Ç–∏ –ø–µ—Ä–µ–¥–∞—ë—Ç—Å—è –≤–Ω–µ—à–Ω–µ–π –º–æ–¥–µ–ª–∏")
    print("  ‚Ä¢ –ü–∞–º—è—Ç—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –º–µ–∂–¥—É —Å–µ—Å—Å–∏—è–º–∏ (—Ñ–∞–π–ª—ã –≤ ./cognitive_v22)")
    print("=" * 60 + "\n")

    while True:
        try:
            q = input("–í–∞—à –≤–æ–ø—Ä–æ—Å: ").strip()
            if q.lower() in ("exit", "–≤—ã—Ö–æ–¥", "quit", "q"):
                print("\nüëã –°–∏—Å—Ç–µ–º–∞ –¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–∞. –ü–∞–º—è—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
                break
            if not q:
                continue

            print()
            answer = system.process(q)

            if answer.strip():
                print("\nüí¨ –û—Ç–≤–µ—Ç:")
                print_typing(answer, delay=0.015)
            else:
                print_typing("ü§î –Ø –ø–æ–ª—É—á–∏–ª –≤–∞—à –≤–æ–ø—Ä–æ—Å, –Ω–æ –Ω–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª –æ—Ç–≤–µ—Ç.", delay=0.015)

            print("\n" + "-" * 60 + "\n")

        except KeyboardInterrupt:
            print("\n\nüëã –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º. –ü–∞–º—è—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
            break
        except Exception as e:
            print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            print("\n" + "-" * 60 + "\n")


if __name__ == "__main__":
    main()